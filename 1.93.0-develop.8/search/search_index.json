{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Splunk Connect for Syslog! \u00b6 Splunk Connect for Syslog is an open source packaged solution for getting data in to Splunk. It is based on the syslog-ng Open Source Edition (Syslog-NG OSE) and transports data to Splunk via the Splunk HTTP event Collector (HEC) rather than writing events to disk for collection by a Universal Forwarder. Product Goals \u00b6 Bring a tested configuration and build of syslog-ng OSE to the market that will function consistently regardless of the underlying host\u2019s linux distribution Provide a container with the tested configuration for Docker/K8s that can be more easily deployed than upstream packages directly on a customer OS Provide validated (testable and tested) implementations of filter and parse functions for common vendor products Reduce latency and improve scale by balancing event distribution across Splunk Indexers Support \u00b6 UPDATE! Splunk Connect for Syslog is now officially supported by Splunk. That said, it is still very much an open-source product and the notes below outlining community support are still highly relevant. Splunk Connect for Syslog is an open source product developed by Splunkers with contributions from the community of partners and customers. This unique product will be enhanced, maintained and supported by the community, led by Splunkers with deep subject matter expertise. The primary reason why Splunk is taking this approach is to push product development closer to those that use and depend upon it. This direct connection will help us all be more successful and move at a rapid pace. Post a question to Splunk Answers using the tag \u201cSplunk Connect For Syslog\u201d Join the #splunk-connect-for-syslog room in the splunk-usergroups Slack Workspace. If you don\u2019t yet have an account sign up Please use the GitHub issue tracker to submit bugs or request enhancements: https://github.com/splunk/splunk-connect-for-syslog/issues Get involved, try it out, ask questions, contribute filters, and make new friends! Contributing \u00b6 We welcome feedback and contributions from the community! Please see our contribution guidelines for more information on how to get involved. License \u00b6 Configuration and documentation licensed subject to CC0 Code and scripts licensed subject to BSD-2-Clause Third Party Red Hat Universal Base Image see License Third Party Syslog-NG (OSE) License","title":"Home"},{"location":"#welcome-to-splunk-connect-for-syslog","text":"Splunk Connect for Syslog is an open source packaged solution for getting data in to Splunk. It is based on the syslog-ng Open Source Edition (Syslog-NG OSE) and transports data to Splunk via the Splunk HTTP event Collector (HEC) rather than writing events to disk for collection by a Universal Forwarder.","title":"Welcome to Splunk Connect for Syslog!"},{"location":"#product-goals","text":"Bring a tested configuration and build of syslog-ng OSE to the market that will function consistently regardless of the underlying host\u2019s linux distribution Provide a container with the tested configuration for Docker/K8s that can be more easily deployed than upstream packages directly on a customer OS Provide validated (testable and tested) implementations of filter and parse functions for common vendor products Reduce latency and improve scale by balancing event distribution across Splunk Indexers","title":"Product Goals"},{"location":"#support","text":"UPDATE! Splunk Connect for Syslog is now officially supported by Splunk. That said, it is still very much an open-source product and the notes below outlining community support are still highly relevant. Splunk Connect for Syslog is an open source product developed by Splunkers with contributions from the community of partners and customers. This unique product will be enhanced, maintained and supported by the community, led by Splunkers with deep subject matter expertise. The primary reason why Splunk is taking this approach is to push product development closer to those that use and depend upon it. This direct connection will help us all be more successful and move at a rapid pace. Post a question to Splunk Answers using the tag \u201cSplunk Connect For Syslog\u201d Join the #splunk-connect-for-syslog room in the splunk-usergroups Slack Workspace. If you don\u2019t yet have an account sign up Please use the GitHub issue tracker to submit bugs or request enhancements: https://github.com/splunk/splunk-connect-for-syslog/issues Get involved, try it out, ask questions, contribute filters, and make new friends!","title":"Support"},{"location":"#contributing","text":"We welcome feedback and contributions from the community! Please see our contribution guidelines for more information on how to get involved.","title":"Contributing"},{"location":"#license","text":"Configuration and documentation licensed subject to CC0 Code and scripts licensed subject to BSD-2-Clause Third Party Red Hat Universal Base Image see License Third Party Syslog-NG (OSE) License","title":"License"},{"location":"CONTRIBUTING/","text":"CONTRIBUTING \u00b6 Splunk welcomes contribution from the SC4S community, and your feedback and enhancements are appreciated. There\u2019s always code that can be clarified, functionality that can be extended, and new data filters to develop, and documentation to refine. If you see something you think should be fixed or added, go for it! Data Safety \u00b6 Splunk Connect for Syslog is a community built and maintained product. Anyone with internet access can get a Splunk GitHub account and participate. As with any publicly available repository, care must be taken to never share private data via Issues, Pull Requests or any other mechanisms. Any data that is shared in the Splunk Connect for Syslog GitHub repository is made available to the entire Community without limits. Members of the Community and/or their employers (including Splunk) assume no responsibility or liability for any damages resulting from the sharing of private data via the Splunk GitHub. Any data samples shared in the Splunk GitHub repository must be free of private data. * Working locally, identify potentially sensitive field values in data samples (Public IP address, URL, Hostname, Etc.) * Replace all potentially sensitive field values with synthetic values * Manually review data samples to re-confirm they are free of private data before sharing in the Splunk GitHub Prerequisites \u00b6 When contributing to this repository, please first discuss the change you wish to make via a GitHub issue or Slack message with the owners of this repository. Setup Development Environment \u00b6 For a basic development environment docker and a bash shell is all that is required. For a more complete IDE experience see our wiki (Setup PyCharm)[https://github.com/splunk/splunk-connect-for-syslog/wiki/SC4S-Development-Setup-Using-PyCharm] Feature Requests and Bug Reports \u00b6 Have ideas on improvements or found a problem? While the community encourages everyone to contribute code, it is also appreciated when someone reports an issue. Please report any issues or bugs you find through GitHub\u2019s issue tracker. If you are reporting a bug, please include the following details: Your operating system name and version Any details about your local setup that might be helpful in troubleshooting (ex. container runtime you use, etc.) Data sample (in raw, \u201con the wire\u201d format) Detailed steps to reproduce the bug We want to hear about you enhancements as well. Feel free to submit them as issues: Explain in detail how they should work Keep the scope as narrow as possible. This will make it easier to implement Fixing Issues \u00b6 Look through our issue tracker to find problems to fix! Feel free to comment and tag community members of this project with any questions or concerns. Pull Requests \u00b6 What is a \u201cpull request\u201d? It informs the project\u2019s core developers about the changes you want to review and merge. Once you submit a pull request, it enters a stage of code review where you and others can discuss its potential modifications and even add more commits to it later on. If you want to learn more, please consult this tutorial on how pull requests work in the GitHub Help Center. Here\u2019s an overview of how you can make a pull request against this project: Fork the Splunk-connect-for-syslog GitHub repository Clone your fork using git and create a branch off develop git clone git @github . com : YOUR_GITHUB_USERNAME / splunk - connect - for - syslog . git cd splunk - connect - for - syslog This project uses \u2018develop\u2019 for all development activity, so create your branch off that git checkout -b your-bugfix-branch-name develop Run all the tests to verify your environment cd splunk - connect - for - syslog . / test - with - compose . sh Make your changes, commit and push once your tests have passed git commit -m \"\" git push Submit a pull request through the GitHub website using the changes from your forked codebase Code Review \u00b6 There are two aspects of code review: giving and receiving. To make it easier for your PR to receive reviews, consider the reviewers will need you to: Follow the project coding conventions Write good commit messages Break large changes into a logical series of smaller patches which individually make easily understandable changes, and in aggregate solve a broader issue Reviewers are highly encouraged to revisit the Code of Conduct and must go above and beyond to promote a collaborative, respectful community. When reviewing PRs from others, \u201cThe Gentle Art of Patch Review\u201d suggests an iterative series of focuses which is designed to lead new contributors to positive collaboration without inundating them initially with nuances: Is the idea behind the contribution sound? Is the contribution architected correctly? Is the contribution polished? For this project, we require that at least 2 approvals are given and a build from our continuous integration system is successful off of your branch. Please note that any new changes made with your existing pull request during review will automatically unapprove and retrigger another build/round of tests. Testing \u00b6 Testing is the responsibility of all contributors. In general, we try to adhere to TDD, writing the test first. There are multiple types of tests. The location of the test code varies with type, as do the specifics of the environment needed to successfully run the test. Review existing tests in the tests folder of the repo We could always use improvements to our documentation! Anyone can contribute to these docs - whether you\u2019re new to the project, you\u2019ve been around a long time, and whether you self-identify as a developer, an end user, or someone who just can\u2019t stand seeing typos. What exactly is needed? More complementary documentation. Have you perhaps found something unclear? More examples or generic templates that others can use. Blog posts, articles and such \u2013 they\u2019re all very much appreciated. You can also edit documentation files directly in the GitHub web interface, without creating a local copy. This can be convenient for small typos or grammar fixes. Release Notes \u00b6 To add commit messages to release notes, tag the message in following format [ TYPE ] < commit message > [TYPE] can be among the following * FEATURE * FIX * DOC * TEST * CI * REVERT * FILTERADD * FILTERMOD Sample commit : git commit - m \"[TEST] test-message\"","title":"CONTRIBUTING"},{"location":"CONTRIBUTING/#contributing","text":"Splunk welcomes contribution from the SC4S community, and your feedback and enhancements are appreciated. There\u2019s always code that can be clarified, functionality that can be extended, and new data filters to develop, and documentation to refine. If you see something you think should be fixed or added, go for it!","title":"CONTRIBUTING"},{"location":"CONTRIBUTING/#data-safety","text":"Splunk Connect for Syslog is a community built and maintained product. Anyone with internet access can get a Splunk GitHub account and participate. As with any publicly available repository, care must be taken to never share private data via Issues, Pull Requests or any other mechanisms. Any data that is shared in the Splunk Connect for Syslog GitHub repository is made available to the entire Community without limits. Members of the Community and/or their employers (including Splunk) assume no responsibility or liability for any damages resulting from the sharing of private data via the Splunk GitHub. Any data samples shared in the Splunk GitHub repository must be free of private data. * Working locally, identify potentially sensitive field values in data samples (Public IP address, URL, Hostname, Etc.) * Replace all potentially sensitive field values with synthetic values * Manually review data samples to re-confirm they are free of private data before sharing in the Splunk GitHub","title":"Data Safety"},{"location":"CONTRIBUTING/#prerequisites","text":"When contributing to this repository, please first discuss the change you wish to make via a GitHub issue or Slack message with the owners of this repository.","title":"Prerequisites"},{"location":"CONTRIBUTING/#setup-development-environment","text":"For a basic development environment docker and a bash shell is all that is required. For a more complete IDE experience see our wiki (Setup PyCharm)[https://github.com/splunk/splunk-connect-for-syslog/wiki/SC4S-Development-Setup-Using-PyCharm]","title":"Setup Development Environment"},{"location":"CONTRIBUTING/#feature-requests-and-bug-reports","text":"Have ideas on improvements or found a problem? While the community encourages everyone to contribute code, it is also appreciated when someone reports an issue. Please report any issues or bugs you find through GitHub\u2019s issue tracker. If you are reporting a bug, please include the following details: Your operating system name and version Any details about your local setup that might be helpful in troubleshooting (ex. container runtime you use, etc.) Data sample (in raw, \u201con the wire\u201d format) Detailed steps to reproduce the bug We want to hear about you enhancements as well. Feel free to submit them as issues: Explain in detail how they should work Keep the scope as narrow as possible. This will make it easier to implement","title":"Feature Requests and Bug Reports"},{"location":"CONTRIBUTING/#fixing-issues","text":"Look through our issue tracker to find problems to fix! Feel free to comment and tag community members of this project with any questions or concerns.","title":"Fixing Issues"},{"location":"CONTRIBUTING/#pull-requests","text":"What is a \u201cpull request\u201d? It informs the project\u2019s core developers about the changes you want to review and merge. Once you submit a pull request, it enters a stage of code review where you and others can discuss its potential modifications and even add more commits to it later on. If you want to learn more, please consult this tutorial on how pull requests work in the GitHub Help Center. Here\u2019s an overview of how you can make a pull request against this project: Fork the Splunk-connect-for-syslog GitHub repository Clone your fork using git and create a branch off develop git clone git @github . com : YOUR_GITHUB_USERNAME / splunk - connect - for - syslog . git cd splunk - connect - for - syslog This project uses \u2018develop\u2019 for all development activity, so create your branch off that git checkout -b your-bugfix-branch-name develop Run all the tests to verify your environment cd splunk - connect - for - syslog . / test - with - compose . sh Make your changes, commit and push once your tests have passed git commit -m \"\" git push Submit a pull request through the GitHub website using the changes from your forked codebase","title":"Pull Requests"},{"location":"CONTRIBUTING/#code-review","text":"There are two aspects of code review: giving and receiving. To make it easier for your PR to receive reviews, consider the reviewers will need you to: Follow the project coding conventions Write good commit messages Break large changes into a logical series of smaller patches which individually make easily understandable changes, and in aggregate solve a broader issue Reviewers are highly encouraged to revisit the Code of Conduct and must go above and beyond to promote a collaborative, respectful community. When reviewing PRs from others, \u201cThe Gentle Art of Patch Review\u201d suggests an iterative series of focuses which is designed to lead new contributors to positive collaboration without inundating them initially with nuances: Is the idea behind the contribution sound? Is the contribution architected correctly? Is the contribution polished? For this project, we require that at least 2 approvals are given and a build from our continuous integration system is successful off of your branch. Please note that any new changes made with your existing pull request during review will automatically unapprove and retrigger another build/round of tests.","title":"Code Review"},{"location":"CONTRIBUTING/#testing","text":"Testing is the responsibility of all contributors. In general, we try to adhere to TDD, writing the test first. There are multiple types of tests. The location of the test code varies with type, as do the specifics of the environment needed to successfully run the test. Review existing tests in the tests folder of the repo We could always use improvements to our documentation! Anyone can contribute to these docs - whether you\u2019re new to the project, you\u2019ve been around a long time, and whether you self-identify as a developer, an end user, or someone who just can\u2019t stand seeing typos. What exactly is needed? More complementary documentation. Have you perhaps found something unclear? More examples or generic templates that others can use. Blog posts, articles and such \u2013 they\u2019re all very much appreciated. You can also edit documentation files directly in the GitHub web interface, without creating a local copy. This can be convenient for small typos or grammar fixes.","title":"Testing"},{"location":"CONTRIBUTING/#release-notes","text":"To add commit messages to release notes, tag the message in following format [ TYPE ] < commit message > [TYPE] can be among the following * FEATURE * FIX * DOC * TEST * CI * REVERT * FILTERADD * FILTERMOD Sample commit : git commit - m \"[TEST] test-message\"","title":"Release Notes"},{"location":"architecture/","text":"SC4S Architectural Considerations \u00b6 There are some key architectural considerations and recommendations that will yield extremely performant and reliable syslog data collection while minimizing the \u201cover-engineering\u201d that is common in many syslog data collection designs. These recommendatations are not specific to Splunk Connect for Syslog, but rather stem from the syslog protocol itself \u2013 and its age. The syslog Protocol \u00b6 The syslog protocol was designed in the mid 1980s to offer very high-speed, network-based logging for network and security devices that were (especially at the time) starved for CPU and I/O resources. For this reason, the protocol was designed for speed and efficiency at the expense of resiliencey/reliability. UDP was chosen due to its ability to \u201csend and forget\u201d the events over the network without regard (or acknowledgment) of receipt. In later years, TCP was added as a transport, as well as TLS/SSL. In spite of these additions, UDP still retains favor as a syslog transport for most data centers, and for the same reasons as originally designed. Becuase of these tradeoffs selected by the original designers (and retained to this day), traditional methods used to provide scale and resiliency do not necessarily transfer to the syslog world. We will discuss (and reference) some of the salient points below. Collector Location \u00b6 Due to syslog being a \u201csend and forget\u201d protcol, it does not perform well when routed through substantial (and especially WAN) network infrastructure. This includes front-side load balancers. The most reliable way to collect syslog traffic is to provide for edge (not centralized) collection. Resist the urge to centrally locate any syslog server (sc4s included) and expect the UDP and (stateless) TCP traffic to \u201cmake it\u201d. Data loss will undoubtedly occur. syslog Data Collection at Scale \u00b6 In concert with attempts to centralize syslog, many admins will co-locate several syslog-ng servers for horizontal scale, and load balance to them with a front-side load balancer. For many reasons (that go beyond this short discussion) this is not a best practice. Briefly: The attempt to load balance for scale (and HA \u2013 see below) will actually cause more data loss due to normal device operations and and attendant buffer loss than would be the case if a simple, robust single server (or shared-IP cluster) were used. Front-side load balancing will also cause inadequate data distribution on the upstream side, leading to data unevenness on the indexers. HA Considerations and Challenges \u00b6 In addtion to scale, many opt to load balance for high availabilty. While a sound approach for stateful, application-level protocols such as http, it does not work well for stateless, unacknowldged syslog traffic. Again, in the attempt to design for HA, more data ends up being lost vs. more simple designs such as vMotioned VMs. With syslog, always remember that the protocol itself is lossy, and there will be data loss (think CD-quality (lossless) vs. MP3). Syslog data collection can be made, at best, \u201cMostly Available\u201d. UDP vs. TCP \u00b6 Paradoxically, UDP for syslog actually ends up being a better choice for resliency for syslog. For an excellent discussion on this topic (as well as the \u201cmyth\u201d of load balancers for HA), see Performant AND Reliable Syslog: UDP is best .","title":"Architectural Considerations"},{"location":"architecture/#sc4s-architectural-considerations","text":"There are some key architectural considerations and recommendations that will yield extremely performant and reliable syslog data collection while minimizing the \u201cover-engineering\u201d that is common in many syslog data collection designs. These recommendatations are not specific to Splunk Connect for Syslog, but rather stem from the syslog protocol itself \u2013 and its age.","title":"SC4S Architectural Considerations"},{"location":"architecture/#the-syslog-protocol","text":"The syslog protocol was designed in the mid 1980s to offer very high-speed, network-based logging for network and security devices that were (especially at the time) starved for CPU and I/O resources. For this reason, the protocol was designed for speed and efficiency at the expense of resiliencey/reliability. UDP was chosen due to its ability to \u201csend and forget\u201d the events over the network without regard (or acknowledgment) of receipt. In later years, TCP was added as a transport, as well as TLS/SSL. In spite of these additions, UDP still retains favor as a syslog transport for most data centers, and for the same reasons as originally designed. Becuase of these tradeoffs selected by the original designers (and retained to this day), traditional methods used to provide scale and resiliency do not necessarily transfer to the syslog world. We will discuss (and reference) some of the salient points below.","title":"The syslog Protocol"},{"location":"architecture/#collector-location","text":"Due to syslog being a \u201csend and forget\u201d protcol, it does not perform well when routed through substantial (and especially WAN) network infrastructure. This includes front-side load balancers. The most reliable way to collect syslog traffic is to provide for edge (not centralized) collection. Resist the urge to centrally locate any syslog server (sc4s included) and expect the UDP and (stateless) TCP traffic to \u201cmake it\u201d. Data loss will undoubtedly occur.","title":"Collector Location"},{"location":"architecture/#syslog-data-collection-at-scale","text":"In concert with attempts to centralize syslog, many admins will co-locate several syslog-ng servers for horizontal scale, and load balance to them with a front-side load balancer. For many reasons (that go beyond this short discussion) this is not a best practice. Briefly: The attempt to load balance for scale (and HA \u2013 see below) will actually cause more data loss due to normal device operations and and attendant buffer loss than would be the case if a simple, robust single server (or shared-IP cluster) were used. Front-side load balancing will also cause inadequate data distribution on the upstream side, leading to data unevenness on the indexers.","title":"syslog Data Collection at Scale"},{"location":"architecture/#ha-considerations-and-challenges","text":"In addtion to scale, many opt to load balance for high availabilty. While a sound approach for stateful, application-level protocols such as http, it does not work well for stateless, unacknowldged syslog traffic. Again, in the attempt to design for HA, more data ends up being lost vs. more simple designs such as vMotioned VMs. With syslog, always remember that the protocol itself is lossy, and there will be data loss (think CD-quality (lossless) vs. MP3). Syslog data collection can be made, at best, \u201cMostly Available\u201d.","title":"HA Considerations and Challenges"},{"location":"architecture/#udp-vs-tcp","text":"Paradoxically, UDP for syslog actually ends up being a better choice for resliency for syslog. For an excellent discussion on this topic (as well as the \u201cmyth\u201d of load balancers for HA), see Performant AND Reliable Syslog: UDP is best .","title":"UDP vs. TCP"},{"location":"configuration/","text":"SC4S Configuration Variables \u00b6 Other than device filter creation, SC4S is almost entirely controlled by environment variables. Here are the categories and variables needed to properly configure SC4S for your environment. Global Configuration \u00b6 Variable Values Description SC4S_DEST_SPLUNK_HEC_DEFAULT_URL url URL(s) of the Splunk endpoint, can be a single URL space seperated list SC4S_DEST_SPLUNK_HEC_DEFAULT_TOKEN string Splunk HTTP Event Collector Token SC4S_USE_REVERSE_DNS yes or no(default) use reverse DNS to identify hosts when HOST is not valid in the syslog header SC4S_CONTAINER_HOST string variable passed to the container to identify the actual log host for container implementations NOTE: Do not configure HEC Acknowledgement when deploying the HEC token on the Splunk side; the underlying syslog-ng http destination does not support this feature. Moreover, HEC Ack would significantly degrade performance for streaming data such as syslog. NOTE: Use of the SC4S_USE_REVERSE_DNS variable can have a significant impact on performance if the reverse DNS facility (typically a caching nameserver) is not performant. If you notice events being indexed far later than their actual timestamp in the event (latency between _indextime and _time ), this is the first place to check. Configure use of external http proxy \u00b6 Warning: Many http proxies are not provisioned with application traffic in mind. Ensure adequate capacity is available to avoid data loss and or proxy outages. Note: the follow vairables are lower case Variable Values Description http_proxy undefined Use libcurl format proxy string \u201chttp://username:password@proxy.server:port\u201d https_proxy undefined Use libcurl format proxy string \u201chttp://username:password@proxy.server:port\u201d Splunk HEC Destination Configuration \u00b6 Variable Values Description SC4S_DEST_SPLUNK_HEC_GLOBAL yes Send events to Splunk using HEC. This applies only to the primary HEC destination. SC4S_DEST_SPLUNK_HEC_CIPHER_SUITE comma separated list Open SSL cipher suite list SC4S_DEST_SPLUNK_HEC_SSL_VERSION comma separated list Open SSL version list SC4S_DEST_SPLUNK_HEC_DEFAULT_TLS_VERIFY yes(default) or no verify HTTP(s) certificate SC4S_DEST_SPLUNK_HEC_WORKERS numeric Number of destination workers (default: 10 threads). This should rarely need to be changed; consult sc4s community for advice on appropriate setting in extreme high- or low-volume environments. SC4S_DEST_SPLUNK_INDEXED_FIELDS facility, severity, container, loghost, destport, fromhostip, proto none List of sc4s indexed fields that will be included with each event in Splunk (default is the entire list except \u201cnone\u201d). Two other indexed fields, sc4s_vendor_product and sc4s_syslog_format , will also appear along with the fields selected via the list and cannot be turned on or off individually. If no indexed fields are desired (including the two internal ones), set the value to the single value of \u201cnone\u201d. When setting this variable, separate multiple entries with commas and do not include extra spaces. This list maps to the following indexed fields that will appear in all Splunk events: facility: sc4s_syslog_facility severity: sc4s_syslog_severity container: sc4s_container loghost: sc4s_loghost dport: sc4s_destport fromhostip: sc4s_fromhostip proto: sc4s_proto NOTE: When using alternate HEC destinations, the destination operating paramaters outlined above ( CIPHER_SUITE , SSL_VERSION , etc.) can be individually controlled per DESTID (see \u201cConfiguration of Additional Splunk HEC Destinations\u201d immediately below). For example, to set the number of workers for the alternate HEC destination d_hec_FOO to 24, set SC4S_DEST_SPLUNK_HEC_FOO_WORKERS=24 . NOTE2: Configuration files for destinations must have a .conf extension Configure additional PKI Trust Anchors \u00b6 Additional trusted (private) Certificate authorities may be trusted by appending each PEM formated certificate to /opt/sc4s/tls/trusted.pem Configuration of Alternate Destinations \u00b6 In addition to the standard HEC destination that is used to send events to Splunk, alternate distinations can be created and configured in SC4S. All alternate destinations (including alternate HEC destinations discussed below) are configured using the environment variables below. Global and/or source-specific forms of the variables below can be used to send data to additional and/or alternate destinations. NOTE: The administrator is responsible for ensuring that any non-HEC alternate destinations are configured in the local mount tree, and that the underlying syslog-ng process in SC4S properly parses them. NOTE: Do not include the primary HEC destination ( d_hec ) in any list of alternate destinations. The configuration of the primary HEC destination is configured separately from that of the alternates below. However, alternate HEC destinations (e.g. d_hec_FOO ) should be configured below, just like any other user-supplied destination. Variable Values Description SC4S_DEST_GLOBAL_ALTERNATES Comma or space-separated list of destinations Send all sources to alternate destinations SC4S_DEST_<VENDOR_PRODUCT>_ALTERNATES Comma or space-separated list of syslog-ng destinations Send specific sources to alternate syslog-ng destinations using the VENDOR_PRODUCT syntax, e.g. SC4S_DEST_CISCO_ASA_ALTERNATES Configuration of Filtered Alternate Destinations (Advanced) \u00b6 Though source-specific forms of the variables configured above will limit configured alternate destinations to a specifc data source, there are cases where even more granularity is desired within a specific data source (e.g. to send all Cisco ASA \u201cdebug\u201d traffic to Cisco Prime for analysis). This extra traffic may or may not be needed in Splunk. To accomudate this use case, Filtered Alternate Destinations allow a filter to be supplied to redirect a portion of a given source\u2019s traffic to a list of altnerate destinations (and, optionally, to prevent matching events from being sent to Splunk). Again, these are configured through environment variables similar to the ones above: Variable Values Description SC4S_DEST_<VENDOR_PRODUCT>_ALT_FILTER syslog-ng filter Filter to determine which events are sent to alternate destination(s) SC4S_DEST_<VENDOR_PRODUCT>_FILTERED_ALTERNATES Comma or space-separated list of syslog-ng destinations Send filtered events to alternate syslog-ng destinations using the VENDOR_PRODUCT syntax, e.g. SC4S_DEST_CISCO_ASA_FILTERED_ALTERNATES NOTE: This is an advanced capability, and filters and destinations using proper syslog-ng syntax must be constructed prior to utilizing this feature. NOTE: Unlike the standard alternate destinations configured above, the regular \u201cmainline\u201d destinations (including the primary HEC destination or configured archive destination ( d_hec or d_archive )) are not included for events matching the configured alternate destination filter. If an event matches the filter, the list of filtered alternate destinations completely replaces any mainline destinations including defaults and global or source-based standard alternate destinations. Be sure to include them in the filtered destination list if desired. HINT: Since the filtered alternate destinations completely replace the mainline destinations (including HEC to Splunk), a filter that matches all traffic can be used with a destination list that does not include the standard HEC destination to effectively turn off HEC for a given data source. Creation of Additional Splunk HEC Destinations \u00b6 Additional Splunk HEC destinations can be dynamically created through environment variables. When set, the destinations will be created with the DESTID appended, for example: d_hec_fmt_FOO . These destinations can then be specified for use (along with any other destinations created locally) either globally or per source. See the \u201cAlternate Destination Use\u201d in the next section for details. Variable Values Description SPLUNK_HEC_ALT_DESTS Comma or space-separated UPPER case list of destination IDs Destination IDs are UPPER case, single-word friendly strings used to identify the new destinations which will be named with the DESTID appended, for example d_hec_FOO SPLUNK_HEC_<DESTID>_URL url Example: SPLUNK_HEC_FOO_URL=https://splunk:8088 DESTID must be a member of the list specified in SPLUNK_HEC_ALT_DESTS configured above SPLUNK_HEC_<DESTID>_TOKEN string Example: SPLUNK_HEC_BAR_TOKEN=<token> DESTID must be a member of the list specified in SPLUNK_HEC_ALT_DESTS configured above NOTE: The DESTID specified in the URL and TOKEN variables above must match the DESTID entries enumerated in the SPLUNK_HEC_ALT_DESTS list. For each DESTID value specified in SPLUNK_HEC_ALT_DESTS there must be a corresponding URL and TOKEN variable set as well. Failure to do so will cause destinations to be created without proper HEC parameters which will result in connection failure. NOTE: Additional Splunk HEC destinations will not be tested at startup. It is the responsiblity of the admin to ensure that additional destinations are provisioned with the correct URL(s) and tokens to ensure proper connectivity. NOTE: The disk and CPU requirements will increase proportionally depending on the number of additional HEC destinations in use (e.g. each HEC destination will have its own disk buffer by default). Configuration of timezone for legacy sources \u00b6 Legacy sources (those that remain non compliant with RFC5424) often leave the recipient to guess at the actual time zone offset. SC4S uses an advanced feature of syslog-ng to \u201cguess\u201d the correct time zone for real time sources. However, this feature requires the source (device) clock to be synchronized to within +/- 30s of the SC4S system clock. Industry accepted best practice is to set such legacy systems to GMT (sometimes inaccurately called UTC). However, this is not always possible and in such cases two additional methods are available. For a list of time zones see . Only the \u201cTZ Database name\u201d OR \u201coffset\u201d format may be used. Change Global default time zone \u00b6 Set the SC4S_DEFAULT_TIMEZONE variable to a recognized \u201czone info\u201d (Region/City) time zone format such as America/New_York . Setting this value will force SC4S to use the specified timezone (and honor its associated Daylight Savings/Summer Time rules) for all events without a timezone offset in the header or message payload. Change by host or subnet match \u00b6 Using the following example \u201cvendor_product_by_source\u201d configuration as a guide, create a matching host wildcard pattern (glob) to identify all devices in the \u201ceast\u201d datacenter located in the Eastern US time zone. Though not shown in the example, IP/CIDR blocks and other more complex filters can also be used, but be aware of the performance implications of complex filtering. #vendor_product_by_source.conf #Note that all filter syntax options of syslog-ng are available here, but be aware that complex filtering #can have a negative impact on performance. filter f_tzfif_dc_us_eastxny { host(\"*-D001-*\" type(glob)) }; #vendor_product_by_source.csv #Add the following line f_dc_us_east,sc4s_time_zone,\"America/New_York\" SC4S Disk Buffer Configuration \u00b6 Disk buffers in SC4S are allocated per destination . Keep this in mind when using additional destinations that have disk buffering configured. By default, when alternate HEC destinations are configured as outlined above disk buffering will be configured identically to that of the main HEC destination (unless overriden individually). Important Notes Regarding Disk Buffering: \u00b6 \u201cReliable\u201d disk buffering offers little advantage over \u201cnormal\u201d disk buffering, at a significant performance penalty. For this reason, normal disk buffering is recommended. If you add destinations locally in your configuration, pay attention to the cumulative buffer requirements when allocating local disk. Disk buffer storage is configured via container volumes and is persistent between restarts of the conatiner. Be sure to account for disk space requirements on the local sc4s host when creating the container volumes in your respective runtime environment (outlined in the \u201cgetting started\u201d runtime docs). These volumes can grow significantly if there is an extended outage to the SC4S destinations (HEC endpoints). See the \u201cSC4S Disk Buffer Configuration\u201d section on the Configruation page for more info. The values for the variables below represent the total sizes of the buffers for the destination. These sizes are divded by the number of workers (threads) when setting the actual syslog-ng buffer options, because the buffer options apply to each worker rather than the entire destination. Pay careful attention to this when using the \u201cBYOE\u201d version of SC4S, where direct access to the syslog-ng config files may hide this nuance. Lastly, be sure to factor in the syslog-ng data structure overhead (approx. 2x raw message size) when calculating the total buffer size needed. To determine the proper size of the disk buffer, consult the \u201cData Resilience\u201d section below. When changing the disk buffering directory, the new directory must exist. If it doesn\u2019t, then syslog-ng will fail to start. When changing the disk buffering directory, if buffering has previously occurd on that instance, a persist file may exist which will prevent syslog-ng from changing the directory. Disk Buffer Variables \u00b6 Variable Values/Default Description SC4S_DEST_SPLUNK_HEC_DISKBUFF_ENABLE yes(default) or no Enable local disk buffering SC4S_DEST_SPLUNK_HEC_DISKBUFF_RELIABLE yes or no(default) Enable reliable/normal disk buffering (normal recommended) SC4S_DEST_SPLUNK_HEC_DISKBUFF_MEMBUFSIZE bytes (10241024) Memory buffer size in bytes (used with reliable disk buffering) SC4S_DEST_SPLUNK_HEC_DISKBUFF_MEMBUFLENGTH messages (15000) Memory buffer size in message count (used with normal disk buffering) SC4S_DEST_SPLUNK_HEC_DISKBUFF_DISKBUFSIZE bytes (53687091200) Size of local disk buffer in bytes (default 50 GB) SC4S_DEST_SPLUNK_HEC_DEFAULT_DISKBUFF_DIR path Location to store the disk buffer files. This variable should only be set when using BYOE; this location is fixed when using the Container. Archive File Configuration \u00b6 This feature is designed to support compliance or \u201cdiode mode\u201d archival of all messages. Instructions for mounting the appropriate local directory to use this feature are included in each \u201cgetting started\u201d runtime document. The files will be stored in a folder structure at the mount point using the pattern shown in the table below depending on the value of the SC4S_GLOBAL_ARCHIVE_MODE variable. All events for both modes are formatted using syslog-ng\u2019s EWMM template. Variable Value/Default Location/Pattern SC4S_GLOBAL_ARCHIVE_MODE compliance(default) <archive mount>/${.splunk.sourcetype}/${HOST}/$YEAR-$MONTH-$DAY-archive.log SC4S_GLOBAL_ARCHIVE_MODE diode <archive mount>/${YEAR}/${MONTH}/${DAY}/${fields.sc4s_vendor_product}_${YEAR}${MONTH}${DAY}${HOUR}${MIN}.log\" WARNING POTENTIAL OUTAGE CAUSING CONSEQUENCE Use the following variables to select global archiving or per-source archiving. C4S does not prune the files that are created; therefore the administrator must provide a means of log rotation to prune files and/or move them to an archival system to avoid exhaustion of disk space. Variable Values Description SC4S_ARCHIVE_GLOBAL yes or undefined Enable archive of all vendor_products SC4S_ARCHIVE_<VENDOR_PRODUCT> yes(default) or undefined See sources section of documentation enables selective archival Syslog Source Configuration \u00b6 Variable Values/Default Description SC4S_SOURCE_TLS_ENABLE yes or no(default) Enable TLS globally. Be sure to configure the cert as shown immediately below. SC4S_LISTEN_DEFAULT_TLS_PORT undefined or 6514 Enable a TLS listener on port 6514 SC4S_LISTEN_DEFAULT_RFC6425_PORT undefined or 5425 Enable a TLS listener on port 5425 SC4S_SOURCE_TLS_OPTIONS no-sslv2 Comma-separated list of the following options: no-sslv2, no-sslv3, no-tlsv1, no-tlsv11, no-tlsv12, none . See syslog-ng docs for the latest list and defaults SC4S_SOURCE_TLS_CIPHER_SUITE See openssl Colon-delimited list of ciphers to support, e.g. ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384 . See openssl docs for the latest list and defaults SC4S_SOURCE_TCP_MAX_CONNECTIONS 2000 Max number of TCP Connections SC4S_SOURCE_TCP_IW_SIZE 20000000 Initial Window size SC4S_SOURCE_TCP_FETCH_LIMIT 2000 Number of events to fetch from server buffer at once SC4S_SOURCE_UDP_SO_RCVBUFF 17039360 UDP server buffer size in bytes. Make sure that the host OS kernel is configured similarly . SC4S_SOURCE_LISTEN_UDP_SOCKETS 1 Number of kernel sockets per active UDP port, which configures multi-threading of the UDP input buffer in the kernel to prevent packet loss. Total UDP input buffer is the multiple of SC4S_SOURCE_LISTEN_UDP_SOCKETS * SC4S_SOURCE_UDP_SO_RCVBUFF SC4S_SOURCE_STORE_RAWMSG undefined or \u201cno\u201d Store unprocessed \u201con the wire\u201d raw message in the RAWMSG macro for use with the \u201cfallback\u201d sourcetype. Do not set this in production; substantial memory and disk overhead will result. Use for log path/filter development only. SC4S_IPV6_ENABLE yes or no(default) enable (dual-stack)IPv6 listeners and health checks Syslog Source TLS Certificate Configuration \u00b6 Create a folder /opt/sc4s/tls if not already done as part of the \u201cgetting started\u201d process. Uncomment the appropriate mount line in the unit or yaml file (again, documented in the \u201cgetting started\u201d runtime documents). Save the server private key in PEM format with NO PASSWORD to /opt/sc4s/tls/server.key Save the server certificate in PEM format to /opt/sc4s/tls/server.pem Ensure the entry SC4S_SOURCE_TLS_ENABLE=yes exists in /opt/sc4s/env_file SC4S metadata configuration \u00b6 Log Path overrides of index or metadata \u00b6 A key aspect of SC4S is to properly set Splunk metadata prior to the data arriving in Splunk (and before any TA processing takes place). The filters will apply the proper index, source, sourcetype, host, and timestamp metadata automatically by individual data source. Proper values for this metadata, including a recommended index and output format (template), are included with all \u201cout-of-the-box\u201d log paths included with SC4S and are chosen to properly interface with the corresponding TA in Splunk. The administrator will need to ensure all recommneded indexes be created to accept this data if the defaults are not changed. It will be common to override default values in many installations. To accomodate this, each log path consults an internal lookup file that maps Splunk metadata to the specific data source being processed. This file contains the defaults that are used by SC4S to set the appropriate Splunk metadata ( index , host , source , and sourcetype ) for each data source. This file is not directly available to the administrator, but a copy of the file is deposited in the local mouunted directory (by default /opt/sc4s/local/context/splunk_metadata.csv.example ) for reference. It is important to note that this copy is not used directly, but is provided solely for reference. To add to the list, or to override default entries, simply create an override file without the example extension (e.g. /opt/sc4s/local/context/splunk_metadata.csv ) and modify it according to the instructions below. splunk_metadata.csv is a CSV file containing a \u201ckey\u201d that is referenced in the log path for each data source. These keys are documented in the individual source files in this section, and allow one to override Splunk metadata either in whole or part. The use of this file is best shown by example. Here is the Netscreen \u201cSourcetype and Index Configuration\u201d table from the Juniper source documentation : key sourcetype index notes juniper_netscreen netscreen:firewall netfw none Here is a line from a typical splunk_metadata.csv override file: juniper_netscreen,index,ns_index The columns in this file are key , metadata , and value . To make a change via the override file, consult the example file (or the source documentation) for the proper key when overrdiing an existing source and modify and/or add rows in the table, specifying one or more of the following metadata/value pairs for a given key : key which refers to the vendor and product name of the data source, using the vendor_product convention. For overrides, these keys will be listed in the example file. For new (custom) sources, be sure to choose a key that accurately reflects the vendor and product being configured, and that matches what is specified in the log path. index to specify an alternate value for index source to specify an alternate value for source host to specify an alternate value for host sourcetype to specify an alternate value for sourcetype (be very careful when changing this; only do so if an upstream TA is not being used, or a custom TA (built by you) is being used.) sc4s_template to specify an alternate value for the syslog-ng template that will be used to format the event that will be indexed by Splunk. Changing this carries the same warning as the sourcetype above; this will affect the upstream TA. The template choices are documented elsewhere in this Configuration section. In our example above, the juniper_netscreen key references a new index used for that data source called ns_index . In general, for most deployments the index should be the only change needed; other default metadata should almost never be overridden (particularly for the \u201cOut of the Box\u201d data sources). Even then, care should be taken when considering any alternates, as the defaults for SC4S were chosen with best practices in mind. NOTE: The splunk_metadata.csv file is a true override file and the entire example file should not be copied over to the override. In most cases, the override file is just one or two lines, unless an entire index category (e.g. netfw ) needs to be overridden. This is similar in concept to the \u201cdefault\u201d and \u201clocal\u201d conf file precedence in Splunk Enterprise. NOTE The splunk_metadata.csv file should always be appended with an appropriate new key and default for the index when building a custom SC4S log path, as the new key will not exist in the internal lookup (nor the example file). Care should be taken during log path design to choose appropriate index, sourctype and template defaults so that admins are not compelled to override them. If the custom log path is later added to the list of SC4S-supported sources, this addendum can be removed. NOTE: As noted above, the splunk_metadata.csv.example file is provided for reference only and is not used directly by SC4S. However, it is an exact copy of the internal file, and can therefore change from release to release. Be sure to check the example file first to make sure the keys for any overrides map correctly to the ones in the example file. Override index or metadata based on host, ip, or subnet (compliance overrides) \u00b6 In other cases it is appropriate to provide the same overrides but based on PCI scope, geography, or other criterion rather than globally. This is accomplished by the use of a file that uniquely identifies these source exceptions via syslog-ng filters, which maps to an associated lookup of alternate indexes, sources, or other metadata. In addition, (indexed) fields can also be added to futher classify the data. The conf and csv files referenced below will be populated into the /opt/sc4s/local/context directory when SC4S is run for the first time after being set up according to the \u201cgetting started\u201d runtime documents, in a similar fashion to splunk_metadata.csv . After this first-time population of the files takes place, they can be edited (and SC4S restarted) for the changes to take effect. To get started: Edit the file compliance_meta_by_source.conf to supply uniquely named filters to identify events subject to override. Edit the file compliance_meta_by_source.csv to supply appropriate field(s) and values. The three columns in the csv file are filter name , field name , and value . Filter names in the conf file must match one or more corresonding filter name rows in the csv file. The field name column obeys the following convention: .splunk.index to specify an alternate value for index .splunk.source to specify an alternate value for source .splunk.sourcetype to specify an alternate value for sourcetype (be very careful when changing this; only do so if a downstream TA is not being used, or a custom TA (built by you) is being used.) fields.fieldname where fieldname will become the name of an indexed field sent to Splunk with the supplied value This file construct is best shown by an example. Here is a sample compliance_meta_by_source.conf file: filter f_test_test { host(\"something-*\" type(glob)) or netmask(192.168.100.1/24) }; and the corresponding compliance_meta_by_source.csv file: f_test_test,.splunk.index,\"pciindex\" f_test_test,fields.compliance,\"pci\" First off, ensure that the filter name(s) in the conf file match one or more rows in the csv file. In this case, any incoming message with a hostname starting with something- or arriving from a netmask of 192.168.100.1/24 will match the f_test_test filter, and the corresponding entries in the csv file will be checked for overrides. In this case, the new index is pciindex , and an indexed field named compliance will be sent to Splunk, with it\u2019s value set to pci . To add additional overrides, simply add another filter foo_bar {}; stanza to the conf file, and add appropriate entries to the csv file that match the filter name(s) to the overrides you deisre. IMPORTANT: The files above are actual syslog-ng config file snippets that get parsed directly by the underlying syslog-ng process. Take care that your syntax is correct; for more information on proper syslog-ng syntax, see the syslog-ng documentation . A syntax error will cause the runtime process to abort in the \u201cpreflight\u201d phase at startup. Finally, to update your changes for the systemd-based runtimes, restart SC4S using the commands: sudo systemctl daemon - reload sudo systemctl restart sc4s For the Docker Swarm runtime, redeploy the updated service using the command: docker stack deploy --compose-file docker-compose.yml sc4s Dropping all data by ip or subnet \u00b6 In some cases rogue or port-probing data can be sent to SC4S from misconfigured devices or vulnerability scanners. Update the vendor_product_by_source.conf filter f_null_queue with one or more ip/subnet masks to drop events without logging. Note that drop metrics will be recorded. Fixing (overriding) the host field \u00b6 In some cases the host value is not present in an event (or an IP address is in its place). For administrators who require a true hostname be attached to each event, SC4S provides an optional facilty to perform a reverse IP to name lookup. If the variable SC4S_USE_REVERSE_DNS is set to \u201cyes\u201d, SC4S will first check host.csv and replace the value of host with the value specified that matches the incoming IP address. If a value is not found in host.csv then a reverse DNS lookup will be attempted against the configured nameserver. The IP address will only be used as the host value as a last resort. NOTE: Use of this variable can have a significant impact on performance if the reverse DNS facility (typically a caching nameserver) is not performant. If you notice events being indexed far later than their actual timestamp in the event (latency between _indextime and _time ), this is the first place to check. Splunk Connect for Syslog output templates (syslog-ng templates) \u00b6 Splunk Connect for Syslog utilizes the syslog-ng template mechanism to format the output payload (event) that will be sent to Splunk. These templates can format the messages in a number of ways (straight text, JSON, etc.) as well as utilize the many syslog-ng \u201cmacros\u201d (fields) to specify what gets placed in the payload that is delivered to the destination. Here is a list of the templates used in SC4S, which can be used in the metadata override section immediately above. New templates can also be added by the administrator in the \u201clocal\u201d section for local destinations; pay careful attention to the syntax as the templates are \u201clive\u201d syslog-ng config code. Template name Template contents Notes t_standard ${DATE} ${HOST} ${MSGHDR}${MESSAGE} Standard template for most RFC3164 (standard syslog) traffic t_msg_only ${MSGONLY} syslog-ng $MSG is sent, no headers (host, timestamp, etc.) t_msg_trim $(strip $MSGONLY) As above with whitespace stripped t_everything ${ISODATE} ${HOST} ${MSGHDR}${MESSAGE} Standard template with ISO date format t_hdr_msg ${MSGHDR}${MESSAGE} Useful for non-compliant syslog messages t_legacy_hdr_msg ${LEGACY_MSGHDR}${MESSAGE} Useful for non-compliant syslog messages t_hdr_sdata_msg ${MSGHDR}${MSGID} ${SDATA} ${MESSAGE} Useful for non-compliant syslog messages t_program_msg ${PROGRAM}[${PID}]: ${MESSAGE} Useful for non-compliant syslog messages t_program_nopid_msg ${PROGRAM}: ${MESSAGE} Useful for non-compliant syslog messages t_JSON_3164 $(format-json \u2013scope rfc3164 \u2013pair PRI=\u201d<$PRI>\u201d \u2013key LEGACY_MSGHDR \u2013exclude FACILITY \u2013exclude PRIORITY) JSON output of all RFC3164-based syslog-ng macros. Useful with the \u201cfallback\u201d sourcetype to aid in new filter development. t_JSON_5424 $(format-json \u2013scope rfc5424 \u2013pair PRI=\u201d<$PRI>\u201d \u2013key ISODATE \u2013exclude DATE \u2013exclude FACILITY \u2013exclude PRIORITY) JSON output of all RFC5424-based syslog-ng macros; for use with RFC5424-compliant traffic. t_JSON_5424_SDATA $(format-json \u2013scope rfc5424 \u2013pair PRI=\u201d<$PRI>\u201d \u2013key ISODATE \u2013exclude DATE \u2013exclude FACILITY \u2013exclude PRIORITY) \u2013exclude MESSAGE JSON output of all RFC5424-based syslog-ng macros except for MESSAGE; for use with RFC5424-compliant traffic. Data Resilience - Local Disk Buffer Configuration \u00b6 SC4S provides capability to minimize the number of lost events if the connection to all the Splunk Indexers goes down. This capability utilizes the disk buffering feature of Syslog-ng. SC4S receives a response from the Splunk HTTP Event Collector (HEC) when a message is received successfully. If a confirmation message from the HEC endpoint is not received (or a \u201cserver busy\u201d reply, such as a \u201c503\u201d is sent), the load balancer will try the next HEC endpoint in the pool. If all pool members are exhausted (such as would occur if there were a full network outage to the HEC endpoints), events will queue to the local disk buffer on the SC4S Linux host. SC4S will continue attempting to send the failed events while it buffers all new incoming events to disk. If the disk space allocated to disk buffering fills up then SC4S will stop accepting new events and subsequent events will be lost. Once SC4S gets confirmation that events are again being received by one or more indexers, events will then stream from the buffer using FIFO queueing. The number of events in the disk buffer will reduce as long as the incoming event volume is less than the maximum SC4S (with the disk buffer in the path) can handle. When all events have been emptied from the disk buffer, SC4S will resume streaming events directly to Splunk. For more detail on the Syslog-ng behavior the documentation can be found here: https://www.syslog-ng.com/technical-documents/doc/syslog-ng-open-source-edition/3.22/administration-guide/55#TOPIC-1209280 SC4S has disk buffering enabled by default and it is strongly recommended that you keep it on, however this feature does have a performance cost. Without disk buffering enabled SC4S can handle up to 345K EPS (800 bytes/event avg) With \u201cNormal\u201d disk buffering enabled SC4S can handle up to 60K EPS (800 bytes/event avg) \u2013 This is still a lot of data! To guard against data loss it is important to configure the appropriate type and amount of storage for SC4S disk buffering. To estimate the storage allocation, follow these steps: Start with your estimated maximum events per second that each SC4S server will experience. Based on the maximum throughput of SC4S with disk buffering enabled, the conservative estimate for maximum events per second would be 60K (however, you should use the maximum rate in your environment for this calculation, not the max rate SC4S can handle). Next is your average estimated event size based on your data sources. It is common industry practice to estimate log events as 800 bytes on average. Then, factor in the maximum length of connectivity downtime you want disk buffering to be able to handle. This measure is very much dependent on your risk tolerance. Lastly, syslog-ng imposes significant overhead to maintain its internal data structures (primarily macros) so that the data can be properly \u201cplayed back\u201d upon network restoration. This overhead currently runs at about 1.7x above the total storage size for the raw messages themselves, and can be higher for \u201cfallback\u201d data sources due to the overlap of syslog-ng macros (data fields) containing some or all of the original message. For example, to protect against a full day of lost connectivity from SC4S to all your indexers at maximum throughput the calculation would look like the following: 60,000 EPS * 86400 seconds * 800 bytes * 1.7 = 6.4 TB of storage To configure storage allocation for the SC4S disk buffering, do the following: Edit the file /opt/sc4s/default/env_file Add the SC4S_DEST_SPLUNK_HEC_DISKBUFF_DISKBUFSIZE variable to the file and set the value to the number of bytes based on your estimation (e.g. 7050240000000 in the example above) Splunk does not recommend reducing the disk allocation below 500 GB Restart SC4S Given that in a connectivity outage to the Indexers events will be saved and read from disk until the buffer is emptied, it is ideal to use the fastest type of storage available. For this reason, NVMe storage is recommended for SC4S disk buffering. It is best to design your deployment so that the disk buffer will drain after connectivity is restored to the Splunk Indexers (while incoming data continues at the same general rate). Since \u201cyour mileage may vary\u201d with different combinations of data load, instance type, and disk subsystem performance, it is good practice to provision a box that performs twice as well as is required for your max EPS. This headroom will allow for rapid recovery after a connectivity outage.","title":"Configuration"},{"location":"configuration/#sc4s-configuration-variables","text":"Other than device filter creation, SC4S is almost entirely controlled by environment variables. Here are the categories and variables needed to properly configure SC4S for your environment.","title":"SC4S Configuration Variables"},{"location":"configuration/#global-configuration","text":"Variable Values Description SC4S_DEST_SPLUNK_HEC_DEFAULT_URL url URL(s) of the Splunk endpoint, can be a single URL space seperated list SC4S_DEST_SPLUNK_HEC_DEFAULT_TOKEN string Splunk HTTP Event Collector Token SC4S_USE_REVERSE_DNS yes or no(default) use reverse DNS to identify hosts when HOST is not valid in the syslog header SC4S_CONTAINER_HOST string variable passed to the container to identify the actual log host for container implementations NOTE: Do not configure HEC Acknowledgement when deploying the HEC token on the Splunk side; the underlying syslog-ng http destination does not support this feature. Moreover, HEC Ack would significantly degrade performance for streaming data such as syslog. NOTE: Use of the SC4S_USE_REVERSE_DNS variable can have a significant impact on performance if the reverse DNS facility (typically a caching nameserver) is not performant. If you notice events being indexed far later than their actual timestamp in the event (latency between _indextime and _time ), this is the first place to check.","title":"Global Configuration"},{"location":"configuration/#configure-use-of-external-http-proxy","text":"Warning: Many http proxies are not provisioned with application traffic in mind. Ensure adequate capacity is available to avoid data loss and or proxy outages. Note: the follow vairables are lower case Variable Values Description http_proxy undefined Use libcurl format proxy string \u201chttp://username:password@proxy.server:port\u201d https_proxy undefined Use libcurl format proxy string \u201chttp://username:password@proxy.server:port\u201d","title":"Configure use of external http proxy"},{"location":"configuration/#splunk-hec-destination-configuration","text":"Variable Values Description SC4S_DEST_SPLUNK_HEC_GLOBAL yes Send events to Splunk using HEC. This applies only to the primary HEC destination. SC4S_DEST_SPLUNK_HEC_CIPHER_SUITE comma separated list Open SSL cipher suite list SC4S_DEST_SPLUNK_HEC_SSL_VERSION comma separated list Open SSL version list SC4S_DEST_SPLUNK_HEC_DEFAULT_TLS_VERIFY yes(default) or no verify HTTP(s) certificate SC4S_DEST_SPLUNK_HEC_WORKERS numeric Number of destination workers (default: 10 threads). This should rarely need to be changed; consult sc4s community for advice on appropriate setting in extreme high- or low-volume environments. SC4S_DEST_SPLUNK_INDEXED_FIELDS facility, severity, container, loghost, destport, fromhostip, proto none List of sc4s indexed fields that will be included with each event in Splunk (default is the entire list except \u201cnone\u201d). Two other indexed fields, sc4s_vendor_product and sc4s_syslog_format , will also appear along with the fields selected via the list and cannot be turned on or off individually. If no indexed fields are desired (including the two internal ones), set the value to the single value of \u201cnone\u201d. When setting this variable, separate multiple entries with commas and do not include extra spaces. This list maps to the following indexed fields that will appear in all Splunk events: facility: sc4s_syslog_facility severity: sc4s_syslog_severity container: sc4s_container loghost: sc4s_loghost dport: sc4s_destport fromhostip: sc4s_fromhostip proto: sc4s_proto NOTE: When using alternate HEC destinations, the destination operating paramaters outlined above ( CIPHER_SUITE , SSL_VERSION , etc.) can be individually controlled per DESTID (see \u201cConfiguration of Additional Splunk HEC Destinations\u201d immediately below). For example, to set the number of workers for the alternate HEC destination d_hec_FOO to 24, set SC4S_DEST_SPLUNK_HEC_FOO_WORKERS=24 . NOTE2: Configuration files for destinations must have a .conf extension","title":"Splunk HEC Destination Configuration"},{"location":"configuration/#configure-additional-pki-trust-anchors","text":"Additional trusted (private) Certificate authorities may be trusted by appending each PEM formated certificate to /opt/sc4s/tls/trusted.pem","title":"Configure additional PKI Trust Anchors"},{"location":"configuration/#configuration-of-alternate-destinations","text":"In addition to the standard HEC destination that is used to send events to Splunk, alternate distinations can be created and configured in SC4S. All alternate destinations (including alternate HEC destinations discussed below) are configured using the environment variables below. Global and/or source-specific forms of the variables below can be used to send data to additional and/or alternate destinations. NOTE: The administrator is responsible for ensuring that any non-HEC alternate destinations are configured in the local mount tree, and that the underlying syslog-ng process in SC4S properly parses them. NOTE: Do not include the primary HEC destination ( d_hec ) in any list of alternate destinations. The configuration of the primary HEC destination is configured separately from that of the alternates below. However, alternate HEC destinations (e.g. d_hec_FOO ) should be configured below, just like any other user-supplied destination. Variable Values Description SC4S_DEST_GLOBAL_ALTERNATES Comma or space-separated list of destinations Send all sources to alternate destinations SC4S_DEST_<VENDOR_PRODUCT>_ALTERNATES Comma or space-separated list of syslog-ng destinations Send specific sources to alternate syslog-ng destinations using the VENDOR_PRODUCT syntax, e.g. SC4S_DEST_CISCO_ASA_ALTERNATES","title":"Configuration of Alternate Destinations"},{"location":"configuration/#configuration-of-filtered-alternate-destinations-advanced","text":"Though source-specific forms of the variables configured above will limit configured alternate destinations to a specifc data source, there are cases where even more granularity is desired within a specific data source (e.g. to send all Cisco ASA \u201cdebug\u201d traffic to Cisco Prime for analysis). This extra traffic may or may not be needed in Splunk. To accomudate this use case, Filtered Alternate Destinations allow a filter to be supplied to redirect a portion of a given source\u2019s traffic to a list of altnerate destinations (and, optionally, to prevent matching events from being sent to Splunk). Again, these are configured through environment variables similar to the ones above: Variable Values Description SC4S_DEST_<VENDOR_PRODUCT>_ALT_FILTER syslog-ng filter Filter to determine which events are sent to alternate destination(s) SC4S_DEST_<VENDOR_PRODUCT>_FILTERED_ALTERNATES Comma or space-separated list of syslog-ng destinations Send filtered events to alternate syslog-ng destinations using the VENDOR_PRODUCT syntax, e.g. SC4S_DEST_CISCO_ASA_FILTERED_ALTERNATES NOTE: This is an advanced capability, and filters and destinations using proper syslog-ng syntax must be constructed prior to utilizing this feature. NOTE: Unlike the standard alternate destinations configured above, the regular \u201cmainline\u201d destinations (including the primary HEC destination or configured archive destination ( d_hec or d_archive )) are not included for events matching the configured alternate destination filter. If an event matches the filter, the list of filtered alternate destinations completely replaces any mainline destinations including defaults and global or source-based standard alternate destinations. Be sure to include them in the filtered destination list if desired. HINT: Since the filtered alternate destinations completely replace the mainline destinations (including HEC to Splunk), a filter that matches all traffic can be used with a destination list that does not include the standard HEC destination to effectively turn off HEC for a given data source.","title":"Configuration of Filtered Alternate Destinations (Advanced)"},{"location":"configuration/#creation-of-additional-splunk-hec-destinations","text":"Additional Splunk HEC destinations can be dynamically created through environment variables. When set, the destinations will be created with the DESTID appended, for example: d_hec_fmt_FOO . These destinations can then be specified for use (along with any other destinations created locally) either globally or per source. See the \u201cAlternate Destination Use\u201d in the next section for details. Variable Values Description SPLUNK_HEC_ALT_DESTS Comma or space-separated UPPER case list of destination IDs Destination IDs are UPPER case, single-word friendly strings used to identify the new destinations which will be named with the DESTID appended, for example d_hec_FOO SPLUNK_HEC_<DESTID>_URL url Example: SPLUNK_HEC_FOO_URL=https://splunk:8088 DESTID must be a member of the list specified in SPLUNK_HEC_ALT_DESTS configured above SPLUNK_HEC_<DESTID>_TOKEN string Example: SPLUNK_HEC_BAR_TOKEN=<token> DESTID must be a member of the list specified in SPLUNK_HEC_ALT_DESTS configured above NOTE: The DESTID specified in the URL and TOKEN variables above must match the DESTID entries enumerated in the SPLUNK_HEC_ALT_DESTS list. For each DESTID value specified in SPLUNK_HEC_ALT_DESTS there must be a corresponding URL and TOKEN variable set as well. Failure to do so will cause destinations to be created without proper HEC parameters which will result in connection failure. NOTE: Additional Splunk HEC destinations will not be tested at startup. It is the responsiblity of the admin to ensure that additional destinations are provisioned with the correct URL(s) and tokens to ensure proper connectivity. NOTE: The disk and CPU requirements will increase proportionally depending on the number of additional HEC destinations in use (e.g. each HEC destination will have its own disk buffer by default).","title":"Creation of Additional Splunk HEC Destinations"},{"location":"configuration/#configuration-of-timezone-for-legacy-sources","text":"Legacy sources (those that remain non compliant with RFC5424) often leave the recipient to guess at the actual time zone offset. SC4S uses an advanced feature of syslog-ng to \u201cguess\u201d the correct time zone for real time sources. However, this feature requires the source (device) clock to be synchronized to within +/- 30s of the SC4S system clock. Industry accepted best practice is to set such legacy systems to GMT (sometimes inaccurately called UTC). However, this is not always possible and in such cases two additional methods are available. For a list of time zones see . Only the \u201cTZ Database name\u201d OR \u201coffset\u201d format may be used.","title":"Configuration of timezone for legacy sources"},{"location":"configuration/#change-global-default-time-zone","text":"Set the SC4S_DEFAULT_TIMEZONE variable to a recognized \u201czone info\u201d (Region/City) time zone format such as America/New_York . Setting this value will force SC4S to use the specified timezone (and honor its associated Daylight Savings/Summer Time rules) for all events without a timezone offset in the header or message payload.","title":"Change Global default time zone"},{"location":"configuration/#change-by-host-or-subnet-match","text":"Using the following example \u201cvendor_product_by_source\u201d configuration as a guide, create a matching host wildcard pattern (glob) to identify all devices in the \u201ceast\u201d datacenter located in the Eastern US time zone. Though not shown in the example, IP/CIDR blocks and other more complex filters can also be used, but be aware of the performance implications of complex filtering. #vendor_product_by_source.conf #Note that all filter syntax options of syslog-ng are available here, but be aware that complex filtering #can have a negative impact on performance. filter f_tzfif_dc_us_eastxny { host(\"*-D001-*\" type(glob)) }; #vendor_product_by_source.csv #Add the following line f_dc_us_east,sc4s_time_zone,\"America/New_York\"","title":"Change by host or subnet match"},{"location":"configuration/#sc4s-disk-buffer-configuration","text":"Disk buffers in SC4S are allocated per destination . Keep this in mind when using additional destinations that have disk buffering configured. By default, when alternate HEC destinations are configured as outlined above disk buffering will be configured identically to that of the main HEC destination (unless overriden individually).","title":"SC4S Disk Buffer Configuration"},{"location":"configuration/#important-notes-regarding-disk-buffering","text":"\u201cReliable\u201d disk buffering offers little advantage over \u201cnormal\u201d disk buffering, at a significant performance penalty. For this reason, normal disk buffering is recommended. If you add destinations locally in your configuration, pay attention to the cumulative buffer requirements when allocating local disk. Disk buffer storage is configured via container volumes and is persistent between restarts of the conatiner. Be sure to account for disk space requirements on the local sc4s host when creating the container volumes in your respective runtime environment (outlined in the \u201cgetting started\u201d runtime docs). These volumes can grow significantly if there is an extended outage to the SC4S destinations (HEC endpoints). See the \u201cSC4S Disk Buffer Configuration\u201d section on the Configruation page for more info. The values for the variables below represent the total sizes of the buffers for the destination. These sizes are divded by the number of workers (threads) when setting the actual syslog-ng buffer options, because the buffer options apply to each worker rather than the entire destination. Pay careful attention to this when using the \u201cBYOE\u201d version of SC4S, where direct access to the syslog-ng config files may hide this nuance. Lastly, be sure to factor in the syslog-ng data structure overhead (approx. 2x raw message size) when calculating the total buffer size needed. To determine the proper size of the disk buffer, consult the \u201cData Resilience\u201d section below. When changing the disk buffering directory, the new directory must exist. If it doesn\u2019t, then syslog-ng will fail to start. When changing the disk buffering directory, if buffering has previously occurd on that instance, a persist file may exist which will prevent syslog-ng from changing the directory.","title":"Important Notes Regarding Disk Buffering:"},{"location":"configuration/#disk-buffer-variables","text":"Variable Values/Default Description SC4S_DEST_SPLUNK_HEC_DISKBUFF_ENABLE yes(default) or no Enable local disk buffering SC4S_DEST_SPLUNK_HEC_DISKBUFF_RELIABLE yes or no(default) Enable reliable/normal disk buffering (normal recommended) SC4S_DEST_SPLUNK_HEC_DISKBUFF_MEMBUFSIZE bytes (10241024) Memory buffer size in bytes (used with reliable disk buffering) SC4S_DEST_SPLUNK_HEC_DISKBUFF_MEMBUFLENGTH messages (15000) Memory buffer size in message count (used with normal disk buffering) SC4S_DEST_SPLUNK_HEC_DISKBUFF_DISKBUFSIZE bytes (53687091200) Size of local disk buffer in bytes (default 50 GB) SC4S_DEST_SPLUNK_HEC_DEFAULT_DISKBUFF_DIR path Location to store the disk buffer files. This variable should only be set when using BYOE; this location is fixed when using the Container.","title":"Disk Buffer Variables"},{"location":"configuration/#archive-file-configuration","text":"This feature is designed to support compliance or \u201cdiode mode\u201d archival of all messages. Instructions for mounting the appropriate local directory to use this feature are included in each \u201cgetting started\u201d runtime document. The files will be stored in a folder structure at the mount point using the pattern shown in the table below depending on the value of the SC4S_GLOBAL_ARCHIVE_MODE variable. All events for both modes are formatted using syslog-ng\u2019s EWMM template. Variable Value/Default Location/Pattern SC4S_GLOBAL_ARCHIVE_MODE compliance(default) <archive mount>/${.splunk.sourcetype}/${HOST}/$YEAR-$MONTH-$DAY-archive.log SC4S_GLOBAL_ARCHIVE_MODE diode <archive mount>/${YEAR}/${MONTH}/${DAY}/${fields.sc4s_vendor_product}_${YEAR}${MONTH}${DAY}${HOUR}${MIN}.log\" WARNING POTENTIAL OUTAGE CAUSING CONSEQUENCE Use the following variables to select global archiving or per-source archiving. C4S does not prune the files that are created; therefore the administrator must provide a means of log rotation to prune files and/or move them to an archival system to avoid exhaustion of disk space. Variable Values Description SC4S_ARCHIVE_GLOBAL yes or undefined Enable archive of all vendor_products SC4S_ARCHIVE_<VENDOR_PRODUCT> yes(default) or undefined See sources section of documentation enables selective archival","title":"Archive File Configuration"},{"location":"configuration/#syslog-source-configuration","text":"Variable Values/Default Description SC4S_SOURCE_TLS_ENABLE yes or no(default) Enable TLS globally. Be sure to configure the cert as shown immediately below. SC4S_LISTEN_DEFAULT_TLS_PORT undefined or 6514 Enable a TLS listener on port 6514 SC4S_LISTEN_DEFAULT_RFC6425_PORT undefined or 5425 Enable a TLS listener on port 5425 SC4S_SOURCE_TLS_OPTIONS no-sslv2 Comma-separated list of the following options: no-sslv2, no-sslv3, no-tlsv1, no-tlsv11, no-tlsv12, none . See syslog-ng docs for the latest list and defaults SC4S_SOURCE_TLS_CIPHER_SUITE See openssl Colon-delimited list of ciphers to support, e.g. ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384 . See openssl docs for the latest list and defaults SC4S_SOURCE_TCP_MAX_CONNECTIONS 2000 Max number of TCP Connections SC4S_SOURCE_TCP_IW_SIZE 20000000 Initial Window size SC4S_SOURCE_TCP_FETCH_LIMIT 2000 Number of events to fetch from server buffer at once SC4S_SOURCE_UDP_SO_RCVBUFF 17039360 UDP server buffer size in bytes. Make sure that the host OS kernel is configured similarly . SC4S_SOURCE_LISTEN_UDP_SOCKETS 1 Number of kernel sockets per active UDP port, which configures multi-threading of the UDP input buffer in the kernel to prevent packet loss. Total UDP input buffer is the multiple of SC4S_SOURCE_LISTEN_UDP_SOCKETS * SC4S_SOURCE_UDP_SO_RCVBUFF SC4S_SOURCE_STORE_RAWMSG undefined or \u201cno\u201d Store unprocessed \u201con the wire\u201d raw message in the RAWMSG macro for use with the \u201cfallback\u201d sourcetype. Do not set this in production; substantial memory and disk overhead will result. Use for log path/filter development only. SC4S_IPV6_ENABLE yes or no(default) enable (dual-stack)IPv6 listeners and health checks","title":"Syslog Source Configuration"},{"location":"configuration/#syslog-source-tls-certificate-configuration","text":"Create a folder /opt/sc4s/tls if not already done as part of the \u201cgetting started\u201d process. Uncomment the appropriate mount line in the unit or yaml file (again, documented in the \u201cgetting started\u201d runtime documents). Save the server private key in PEM format with NO PASSWORD to /opt/sc4s/tls/server.key Save the server certificate in PEM format to /opt/sc4s/tls/server.pem Ensure the entry SC4S_SOURCE_TLS_ENABLE=yes exists in /opt/sc4s/env_file","title":"Syslog Source TLS Certificate Configuration"},{"location":"configuration/#sc4s-metadata-configuration","text":"","title":"SC4S metadata configuration"},{"location":"configuration/#log-path-overrides-of-index-or-metadata","text":"A key aspect of SC4S is to properly set Splunk metadata prior to the data arriving in Splunk (and before any TA processing takes place). The filters will apply the proper index, source, sourcetype, host, and timestamp metadata automatically by individual data source. Proper values for this metadata, including a recommended index and output format (template), are included with all \u201cout-of-the-box\u201d log paths included with SC4S and are chosen to properly interface with the corresponding TA in Splunk. The administrator will need to ensure all recommneded indexes be created to accept this data if the defaults are not changed. It will be common to override default values in many installations. To accomodate this, each log path consults an internal lookup file that maps Splunk metadata to the specific data source being processed. This file contains the defaults that are used by SC4S to set the appropriate Splunk metadata ( index , host , source , and sourcetype ) for each data source. This file is not directly available to the administrator, but a copy of the file is deposited in the local mouunted directory (by default /opt/sc4s/local/context/splunk_metadata.csv.example ) for reference. It is important to note that this copy is not used directly, but is provided solely for reference. To add to the list, or to override default entries, simply create an override file without the example extension (e.g. /opt/sc4s/local/context/splunk_metadata.csv ) and modify it according to the instructions below. splunk_metadata.csv is a CSV file containing a \u201ckey\u201d that is referenced in the log path for each data source. These keys are documented in the individual source files in this section, and allow one to override Splunk metadata either in whole or part. The use of this file is best shown by example. Here is the Netscreen \u201cSourcetype and Index Configuration\u201d table from the Juniper source documentation : key sourcetype index notes juniper_netscreen netscreen:firewall netfw none Here is a line from a typical splunk_metadata.csv override file: juniper_netscreen,index,ns_index The columns in this file are key , metadata , and value . To make a change via the override file, consult the example file (or the source documentation) for the proper key when overrdiing an existing source and modify and/or add rows in the table, specifying one or more of the following metadata/value pairs for a given key : key which refers to the vendor and product name of the data source, using the vendor_product convention. For overrides, these keys will be listed in the example file. For new (custom) sources, be sure to choose a key that accurately reflects the vendor and product being configured, and that matches what is specified in the log path. index to specify an alternate value for index source to specify an alternate value for source host to specify an alternate value for host sourcetype to specify an alternate value for sourcetype (be very careful when changing this; only do so if an upstream TA is not being used, or a custom TA (built by you) is being used.) sc4s_template to specify an alternate value for the syslog-ng template that will be used to format the event that will be indexed by Splunk. Changing this carries the same warning as the sourcetype above; this will affect the upstream TA. The template choices are documented elsewhere in this Configuration section. In our example above, the juniper_netscreen key references a new index used for that data source called ns_index . In general, for most deployments the index should be the only change needed; other default metadata should almost never be overridden (particularly for the \u201cOut of the Box\u201d data sources). Even then, care should be taken when considering any alternates, as the defaults for SC4S were chosen with best practices in mind. NOTE: The splunk_metadata.csv file is a true override file and the entire example file should not be copied over to the override. In most cases, the override file is just one or two lines, unless an entire index category (e.g. netfw ) needs to be overridden. This is similar in concept to the \u201cdefault\u201d and \u201clocal\u201d conf file precedence in Splunk Enterprise. NOTE The splunk_metadata.csv file should always be appended with an appropriate new key and default for the index when building a custom SC4S log path, as the new key will not exist in the internal lookup (nor the example file). Care should be taken during log path design to choose appropriate index, sourctype and template defaults so that admins are not compelled to override them. If the custom log path is later added to the list of SC4S-supported sources, this addendum can be removed. NOTE: As noted above, the splunk_metadata.csv.example file is provided for reference only and is not used directly by SC4S. However, it is an exact copy of the internal file, and can therefore change from release to release. Be sure to check the example file first to make sure the keys for any overrides map correctly to the ones in the example file.","title":"Log Path overrides of index or metadata"},{"location":"configuration/#override-index-or-metadata-based-on-host-ip-or-subnet-compliance-overrides","text":"In other cases it is appropriate to provide the same overrides but based on PCI scope, geography, or other criterion rather than globally. This is accomplished by the use of a file that uniquely identifies these source exceptions via syslog-ng filters, which maps to an associated lookup of alternate indexes, sources, or other metadata. In addition, (indexed) fields can also be added to futher classify the data. The conf and csv files referenced below will be populated into the /opt/sc4s/local/context directory when SC4S is run for the first time after being set up according to the \u201cgetting started\u201d runtime documents, in a similar fashion to splunk_metadata.csv . After this first-time population of the files takes place, they can be edited (and SC4S restarted) for the changes to take effect. To get started: Edit the file compliance_meta_by_source.conf to supply uniquely named filters to identify events subject to override. Edit the file compliance_meta_by_source.csv to supply appropriate field(s) and values. The three columns in the csv file are filter name , field name , and value . Filter names in the conf file must match one or more corresonding filter name rows in the csv file. The field name column obeys the following convention: .splunk.index to specify an alternate value for index .splunk.source to specify an alternate value for source .splunk.sourcetype to specify an alternate value for sourcetype (be very careful when changing this; only do so if a downstream TA is not being used, or a custom TA (built by you) is being used.) fields.fieldname where fieldname will become the name of an indexed field sent to Splunk with the supplied value This file construct is best shown by an example. Here is a sample compliance_meta_by_source.conf file: filter f_test_test { host(\"something-*\" type(glob)) or netmask(192.168.100.1/24) }; and the corresponding compliance_meta_by_source.csv file: f_test_test,.splunk.index,\"pciindex\" f_test_test,fields.compliance,\"pci\" First off, ensure that the filter name(s) in the conf file match one or more rows in the csv file. In this case, any incoming message with a hostname starting with something- or arriving from a netmask of 192.168.100.1/24 will match the f_test_test filter, and the corresponding entries in the csv file will be checked for overrides. In this case, the new index is pciindex , and an indexed field named compliance will be sent to Splunk, with it\u2019s value set to pci . To add additional overrides, simply add another filter foo_bar {}; stanza to the conf file, and add appropriate entries to the csv file that match the filter name(s) to the overrides you deisre. IMPORTANT: The files above are actual syslog-ng config file snippets that get parsed directly by the underlying syslog-ng process. Take care that your syntax is correct; for more information on proper syslog-ng syntax, see the syslog-ng documentation . A syntax error will cause the runtime process to abort in the \u201cpreflight\u201d phase at startup. Finally, to update your changes for the systemd-based runtimes, restart SC4S using the commands: sudo systemctl daemon - reload sudo systemctl restart sc4s For the Docker Swarm runtime, redeploy the updated service using the command: docker stack deploy --compose-file docker-compose.yml sc4s","title":"Override index or metadata based on host, ip, or subnet (compliance overrides)"},{"location":"configuration/#dropping-all-data-by-ip-or-subnet","text":"In some cases rogue or port-probing data can be sent to SC4S from misconfigured devices or vulnerability scanners. Update the vendor_product_by_source.conf filter f_null_queue with one or more ip/subnet masks to drop events without logging. Note that drop metrics will be recorded.","title":"Dropping all data by ip or subnet"},{"location":"configuration/#fixing-overriding-the-host-field","text":"In some cases the host value is not present in an event (or an IP address is in its place). For administrators who require a true hostname be attached to each event, SC4S provides an optional facilty to perform a reverse IP to name lookup. If the variable SC4S_USE_REVERSE_DNS is set to \u201cyes\u201d, SC4S will first check host.csv and replace the value of host with the value specified that matches the incoming IP address. If a value is not found in host.csv then a reverse DNS lookup will be attempted against the configured nameserver. The IP address will only be used as the host value as a last resort. NOTE: Use of this variable can have a significant impact on performance if the reverse DNS facility (typically a caching nameserver) is not performant. If you notice events being indexed far later than their actual timestamp in the event (latency between _indextime and _time ), this is the first place to check.","title":"Fixing (overriding) the host field"},{"location":"configuration/#splunk-connect-for-syslog-output-templates-syslog-ng-templates","text":"Splunk Connect for Syslog utilizes the syslog-ng template mechanism to format the output payload (event) that will be sent to Splunk. These templates can format the messages in a number of ways (straight text, JSON, etc.) as well as utilize the many syslog-ng \u201cmacros\u201d (fields) to specify what gets placed in the payload that is delivered to the destination. Here is a list of the templates used in SC4S, which can be used in the metadata override section immediately above. New templates can also be added by the administrator in the \u201clocal\u201d section for local destinations; pay careful attention to the syntax as the templates are \u201clive\u201d syslog-ng config code. Template name Template contents Notes t_standard ${DATE} ${HOST} ${MSGHDR}${MESSAGE} Standard template for most RFC3164 (standard syslog) traffic t_msg_only ${MSGONLY} syslog-ng $MSG is sent, no headers (host, timestamp, etc.) t_msg_trim $(strip $MSGONLY) As above with whitespace stripped t_everything ${ISODATE} ${HOST} ${MSGHDR}${MESSAGE} Standard template with ISO date format t_hdr_msg ${MSGHDR}${MESSAGE} Useful for non-compliant syslog messages t_legacy_hdr_msg ${LEGACY_MSGHDR}${MESSAGE} Useful for non-compliant syslog messages t_hdr_sdata_msg ${MSGHDR}${MSGID} ${SDATA} ${MESSAGE} Useful for non-compliant syslog messages t_program_msg ${PROGRAM}[${PID}]: ${MESSAGE} Useful for non-compliant syslog messages t_program_nopid_msg ${PROGRAM}: ${MESSAGE} Useful for non-compliant syslog messages t_JSON_3164 $(format-json \u2013scope rfc3164 \u2013pair PRI=\u201d<$PRI>\u201d \u2013key LEGACY_MSGHDR \u2013exclude FACILITY \u2013exclude PRIORITY) JSON output of all RFC3164-based syslog-ng macros. Useful with the \u201cfallback\u201d sourcetype to aid in new filter development. t_JSON_5424 $(format-json \u2013scope rfc5424 \u2013pair PRI=\u201d<$PRI>\u201d \u2013key ISODATE \u2013exclude DATE \u2013exclude FACILITY \u2013exclude PRIORITY) JSON output of all RFC5424-based syslog-ng macros; for use with RFC5424-compliant traffic. t_JSON_5424_SDATA $(format-json \u2013scope rfc5424 \u2013pair PRI=\u201d<$PRI>\u201d \u2013key ISODATE \u2013exclude DATE \u2013exclude FACILITY \u2013exclude PRIORITY) \u2013exclude MESSAGE JSON output of all RFC5424-based syslog-ng macros except for MESSAGE; for use with RFC5424-compliant traffic.","title":"Splunk Connect for Syslog output templates (syslog-ng templates)"},{"location":"configuration/#data-resilience-local-disk-buffer-configuration","text":"SC4S provides capability to minimize the number of lost events if the connection to all the Splunk Indexers goes down. This capability utilizes the disk buffering feature of Syslog-ng. SC4S receives a response from the Splunk HTTP Event Collector (HEC) when a message is received successfully. If a confirmation message from the HEC endpoint is not received (or a \u201cserver busy\u201d reply, such as a \u201c503\u201d is sent), the load balancer will try the next HEC endpoint in the pool. If all pool members are exhausted (such as would occur if there were a full network outage to the HEC endpoints), events will queue to the local disk buffer on the SC4S Linux host. SC4S will continue attempting to send the failed events while it buffers all new incoming events to disk. If the disk space allocated to disk buffering fills up then SC4S will stop accepting new events and subsequent events will be lost. Once SC4S gets confirmation that events are again being received by one or more indexers, events will then stream from the buffer using FIFO queueing. The number of events in the disk buffer will reduce as long as the incoming event volume is less than the maximum SC4S (with the disk buffer in the path) can handle. When all events have been emptied from the disk buffer, SC4S will resume streaming events directly to Splunk. For more detail on the Syslog-ng behavior the documentation can be found here: https://www.syslog-ng.com/technical-documents/doc/syslog-ng-open-source-edition/3.22/administration-guide/55#TOPIC-1209280 SC4S has disk buffering enabled by default and it is strongly recommended that you keep it on, however this feature does have a performance cost. Without disk buffering enabled SC4S can handle up to 345K EPS (800 bytes/event avg) With \u201cNormal\u201d disk buffering enabled SC4S can handle up to 60K EPS (800 bytes/event avg) \u2013 This is still a lot of data! To guard against data loss it is important to configure the appropriate type and amount of storage for SC4S disk buffering. To estimate the storage allocation, follow these steps: Start with your estimated maximum events per second that each SC4S server will experience. Based on the maximum throughput of SC4S with disk buffering enabled, the conservative estimate for maximum events per second would be 60K (however, you should use the maximum rate in your environment for this calculation, not the max rate SC4S can handle). Next is your average estimated event size based on your data sources. It is common industry practice to estimate log events as 800 bytes on average. Then, factor in the maximum length of connectivity downtime you want disk buffering to be able to handle. This measure is very much dependent on your risk tolerance. Lastly, syslog-ng imposes significant overhead to maintain its internal data structures (primarily macros) so that the data can be properly \u201cplayed back\u201d upon network restoration. This overhead currently runs at about 1.7x above the total storage size for the raw messages themselves, and can be higher for \u201cfallback\u201d data sources due to the overlap of syslog-ng macros (data fields) containing some or all of the original message. For example, to protect against a full day of lost connectivity from SC4S to all your indexers at maximum throughput the calculation would look like the following: 60,000 EPS * 86400 seconds * 800 bytes * 1.7 = 6.4 TB of storage To configure storage allocation for the SC4S disk buffering, do the following: Edit the file /opt/sc4s/default/env_file Add the SC4S_DEST_SPLUNK_HEC_DISKBUFF_DISKBUFSIZE variable to the file and set the value to the number of bytes based on your estimation (e.g. 7050240000000 in the example above) Splunk does not recommend reducing the disk allocation below 500 GB Restart SC4S Given that in a connectivity outage to the Indexers events will be saved and read from disk until the buffer is emptied, it is ideal to use the fastest type of storage available. For this reason, NVMe storage is recommended for SC4S disk buffering. It is best to design your deployment so that the disk buffer will drain after connectivity is restored to the Splunk Indexers (while incoming data continues at the same general rate). Since \u201cyour mileage may vary\u201d with different combinations of data load, instance type, and disk subsystem performance, it is good practice to provision a box that performs twice as well as is required for your max EPS. This headroom will allow for rapid recovery after a connectivity outage.","title":"Data Resilience - Local Disk Buffer Configuration"},{"location":"faq/","text":"Splunk Connect for Syslog (SC4S) Frequently Asked Questions \u00b6 Q: The Universal Forwarder/files based architecture has been the documented Splunk best practice for a long time. Why switch to a HTTP Event Collector (HEC) based architecture? A: Using HEC to stream events directly to the Indexers provides superior load balancing which has shown to produce dramatically more even data distribution across the Indexers. This even distribution results in significantly enhanced search performance. This benefit is especially valuable in large Splunk deployments. The HEC architecture designed into SC4S is also far easier to administer with newer versions of syslog-ng, which SC4S takes advantage of. There are far fewer opportunities for mis-configuration, resulting in higher overall performance and customer adoption. Lastly, HEC (and in particular, the \u201c/event\u201d endpoint) offers the opportunity for a far richer data stream to Splunk, with lower resource utilization at ingest. This rich data stream can be taken advantage of in next-generation TAs. Q: Is the Splunk HTTP Event Collector (HEC) as reliable as the Splunk Universal Forwarder? A: HEC utilizes standard HTTP mechanisms to confirm that the endpoint is responsive before sending data. The HEC architecture allows for the use of an industry standard load balancer between SC4S and the Indexer, or the included load balancing capability built into SC4S itself. Q: What if my team doesn\u2019t know how to manage containers? A: SC4S supports both container-based and \u201cbring-your-own-environment\u201d (BYOE) deployment methods. That said, using a runtime like Podman to deploy and manage SC4S containers is exceptionally easy even for those with no prior \u201ccontainer experience\u201d. Our application of container technology behaves much like a packaging system. The interaction is mostly via \u201csystemctl\u201d commands a Linux admin would use for other common administration activities. The best approach is to try it out in a lab to see what the experience is like for yourself! BYOE is intended for advanced deployments that can not use the Splunk container for some reason. One possible reason is a need to \u201cfork\u201d SC4S in order to implement heavy bespoke customization. Though many will initially gravitate toward BYOE because managing config files and syslog-ng directly is \u201cwhat they know\u201d, most enterprises will have the best experience using the container approach. Q: Can my team use SC4S if we are Windows only shop? A: You can now run Docker on Windows! Microsoft has introduced public preview technology for Linux containers on Windows. Alternatively, a minimal Centos/Ubuntu Linux VM running on Windows hyper-v is a reliable production-grade choice. Q: My company has the traditional UF/files based syslog architecture deployed and running, should I rip/replace a working installation with SC4S? A: Generally speaking, if a deployment is working and you are happy with it, it\u2019s best to leave it as is until there is need for major deployment changes such as higher scale. That said, the search performance gains realized from better data distribution is a benefit not to be overlooked. If Splunk users have complained about search performance or you are curious about the possible performance gains, we recommend doing an analysis of the data distribution across the indexers. It may make sense to upgrade to SC4S if there is a change in administration as well. Properly architecting a performant UF/files syslog-ng deployment is difficult, and an administrative personnel change offers the opportunity to \u201cmake a break\u201d to SC4S, where a new set of administrators would otherwise be tasked with understanding the existing (likely complicated) architecture. Q: What is the best way to migrate to SC4S from an existing syslog architecture? A: When exploring migration to SC4S we strongly recommend experimentation in a lab prior to deployment to production. There are a couple of approaches to consider: One option is to stand up and configure the new SC4S infrastructure for all your sources, then confirm all the sourcetypes are being indexed as expected, and finally stop the existing syslog servers. This big bang approach may result in the fewest duplicate events in Splunk vs other options. In some large or complex environments this may not be feasible however. A second option is to start with the sources currently sending events on port 514 (the default). In this case you would stand up the new SC4S infrastructure in its default configuration, confirm all the sourcetypes are being indexed as expected, then retire the old syslog servers listening on port 514. Once the 514 sources are complete you can move on to migrating any other sources one by one. To migrate these other sources you would configure SC4S filters to explicitly identify them either via unique port, hostID or CIDR block. Again, once you confirm that each sourcetype is successfully being indexed then you may disable the old syslog configurations for that source. Q: How can SC4S be deployed to provide high availability? A: It is challenging to provide HA for syslog because the syslog protocol itself was not designed with HA as a goal. See Performant AND Reliable Syslog UDP is best for an excellent overview of this topic. The gist is that the protocol itself limits the extent to which you can make any syslog collection architecture HA; at best it can be made \u201cmostly available\u201d. Think of syslog as MP3 \u2013 it is a \u201clossy\u201d protocol and there is nothing you can do to restore it to CD quality (lossless). Some have attempted to implement HA via front-side load balancers; please don\u2019t! This is the most common architectural mistake folks make when architecting large-scale syslog data collection. So \u2013 how to make it \u201cmostly available\u201d? Keep it simple, and use OS clustering (shared IP) or even just VMs with vMotion. This simple architecture will encounter far less data loss over time than more complicated schemes. Another possible option being evaluated is containerization HA schemes for SC4S (centered around microk8s) that will take some of the admin burden of clustering away \u2013 but it is still OS clustering under the hood. Q: I\u2019m worried about data loss if SC4S goes down. Could I feed syslog to redundant SC4S servers to provide HA, without creating duplicate events in Splunk? A: In many/most system design decisions there is some level of compromise. Any network protocol that doesn\u2019t have an application level ack will lose data, as speed was selected over reliability in the design, this is the case with syslog. Use of a clustered IP with an active/passive node will however offer a level of resilience while keeping complexity to a minimum. It could be possible to implement a far more complex solution utilizing an additional intermediary technology like Kafka, however the costs may outweigh the real world benefits. Q: Can the SC4S container be deployed using OpenShift or K8s? A: There are a number of reasons that OpenShift/K8s are not a good fit for syslog, SNMP or SIP. They can\u2019t use UDP and TCP on the same port which breaks multiple Bluecoat and Cisco feeds among others. Layered networking shrinks the maximum UDP message which causes data loss due to truncation and drops Long lived TCP connections cause well known problems OpenShift doesn\u2019t actually use Podman, it uses a library to wrap OCI that Podman also uses. this wrapper around the wrapper has some shortcomings that prevent the service definitions SC4S requires. Basically, K8s was built for a very different set of problems than syslog Q: If the XL reference HW can handle just under 1 TB/day how can SC4S be scaled to handle large deployments of many TB/day? A: SC4S is a distributed architecture. SC4S instances should be deployed in the same VLAN as the source devices. This means that each SC4S instance will only see a subset of the total syslog traffic in a large deployment. Even in a 100+ TB deployment the individual SC4S instances will see loads in GB/day not TB/day. Q: How are security vulnerabilities handled with SC4S? A: SC4S is comprised of several components including RHL, Syslog-ng and temporized configurations. If a vulnerability is found in the SC4S configurations, they will be given a critical priority in the Development queue. If vulnerabilities are identified in the third party components (RHL, Syslog-ng, etc.) the fixed versions will be pulled in upon the next SC4S release. Fixed security issues are identified by \u201c[security]\u201d in SC4S release notes.","title":"SC4S FAQ"},{"location":"faq/#splunk-connect-for-syslog-sc4s-frequently-asked-questions","text":"Q: The Universal Forwarder/files based architecture has been the documented Splunk best practice for a long time. Why switch to a HTTP Event Collector (HEC) based architecture? A: Using HEC to stream events directly to the Indexers provides superior load balancing which has shown to produce dramatically more even data distribution across the Indexers. This even distribution results in significantly enhanced search performance. This benefit is especially valuable in large Splunk deployments. The HEC architecture designed into SC4S is also far easier to administer with newer versions of syslog-ng, which SC4S takes advantage of. There are far fewer opportunities for mis-configuration, resulting in higher overall performance and customer adoption. Lastly, HEC (and in particular, the \u201c/event\u201d endpoint) offers the opportunity for a far richer data stream to Splunk, with lower resource utilization at ingest. This rich data stream can be taken advantage of in next-generation TAs. Q: Is the Splunk HTTP Event Collector (HEC) as reliable as the Splunk Universal Forwarder? A: HEC utilizes standard HTTP mechanisms to confirm that the endpoint is responsive before sending data. The HEC architecture allows for the use of an industry standard load balancer between SC4S and the Indexer, or the included load balancing capability built into SC4S itself. Q: What if my team doesn\u2019t know how to manage containers? A: SC4S supports both container-based and \u201cbring-your-own-environment\u201d (BYOE) deployment methods. That said, using a runtime like Podman to deploy and manage SC4S containers is exceptionally easy even for those with no prior \u201ccontainer experience\u201d. Our application of container technology behaves much like a packaging system. The interaction is mostly via \u201csystemctl\u201d commands a Linux admin would use for other common administration activities. The best approach is to try it out in a lab to see what the experience is like for yourself! BYOE is intended for advanced deployments that can not use the Splunk container for some reason. One possible reason is a need to \u201cfork\u201d SC4S in order to implement heavy bespoke customization. Though many will initially gravitate toward BYOE because managing config files and syslog-ng directly is \u201cwhat they know\u201d, most enterprises will have the best experience using the container approach. Q: Can my team use SC4S if we are Windows only shop? A: You can now run Docker on Windows! Microsoft has introduced public preview technology for Linux containers on Windows. Alternatively, a minimal Centos/Ubuntu Linux VM running on Windows hyper-v is a reliable production-grade choice. Q: My company has the traditional UF/files based syslog architecture deployed and running, should I rip/replace a working installation with SC4S? A: Generally speaking, if a deployment is working and you are happy with it, it\u2019s best to leave it as is until there is need for major deployment changes such as higher scale. That said, the search performance gains realized from better data distribution is a benefit not to be overlooked. If Splunk users have complained about search performance or you are curious about the possible performance gains, we recommend doing an analysis of the data distribution across the indexers. It may make sense to upgrade to SC4S if there is a change in administration as well. Properly architecting a performant UF/files syslog-ng deployment is difficult, and an administrative personnel change offers the opportunity to \u201cmake a break\u201d to SC4S, where a new set of administrators would otherwise be tasked with understanding the existing (likely complicated) architecture. Q: What is the best way to migrate to SC4S from an existing syslog architecture? A: When exploring migration to SC4S we strongly recommend experimentation in a lab prior to deployment to production. There are a couple of approaches to consider: One option is to stand up and configure the new SC4S infrastructure for all your sources, then confirm all the sourcetypes are being indexed as expected, and finally stop the existing syslog servers. This big bang approach may result in the fewest duplicate events in Splunk vs other options. In some large or complex environments this may not be feasible however. A second option is to start with the sources currently sending events on port 514 (the default). In this case you would stand up the new SC4S infrastructure in its default configuration, confirm all the sourcetypes are being indexed as expected, then retire the old syslog servers listening on port 514. Once the 514 sources are complete you can move on to migrating any other sources one by one. To migrate these other sources you would configure SC4S filters to explicitly identify them either via unique port, hostID or CIDR block. Again, once you confirm that each sourcetype is successfully being indexed then you may disable the old syslog configurations for that source. Q: How can SC4S be deployed to provide high availability? A: It is challenging to provide HA for syslog because the syslog protocol itself was not designed with HA as a goal. See Performant AND Reliable Syslog UDP is best for an excellent overview of this topic. The gist is that the protocol itself limits the extent to which you can make any syslog collection architecture HA; at best it can be made \u201cmostly available\u201d. Think of syslog as MP3 \u2013 it is a \u201clossy\u201d protocol and there is nothing you can do to restore it to CD quality (lossless). Some have attempted to implement HA via front-side load balancers; please don\u2019t! This is the most common architectural mistake folks make when architecting large-scale syslog data collection. So \u2013 how to make it \u201cmostly available\u201d? Keep it simple, and use OS clustering (shared IP) or even just VMs with vMotion. This simple architecture will encounter far less data loss over time than more complicated schemes. Another possible option being evaluated is containerization HA schemes for SC4S (centered around microk8s) that will take some of the admin burden of clustering away \u2013 but it is still OS clustering under the hood. Q: I\u2019m worried about data loss if SC4S goes down. Could I feed syslog to redundant SC4S servers to provide HA, without creating duplicate events in Splunk? A: In many/most system design decisions there is some level of compromise. Any network protocol that doesn\u2019t have an application level ack will lose data, as speed was selected over reliability in the design, this is the case with syslog. Use of a clustered IP with an active/passive node will however offer a level of resilience while keeping complexity to a minimum. It could be possible to implement a far more complex solution utilizing an additional intermediary technology like Kafka, however the costs may outweigh the real world benefits. Q: Can the SC4S container be deployed using OpenShift or K8s? A: There are a number of reasons that OpenShift/K8s are not a good fit for syslog, SNMP or SIP. They can\u2019t use UDP and TCP on the same port which breaks multiple Bluecoat and Cisco feeds among others. Layered networking shrinks the maximum UDP message which causes data loss due to truncation and drops Long lived TCP connections cause well known problems OpenShift doesn\u2019t actually use Podman, it uses a library to wrap OCI that Podman also uses. this wrapper around the wrapper has some shortcomings that prevent the service definitions SC4S requires. Basically, K8s was built for a very different set of problems than syslog Q: If the XL reference HW can handle just under 1 TB/day how can SC4S be scaled to handle large deployments of many TB/day? A: SC4S is a distributed architecture. SC4S instances should be deployed in the same VLAN as the source devices. This means that each SC4S instance will only see a subset of the total syslog traffic in a large deployment. Even in a 100+ TB deployment the individual SC4S instances will see loads in GB/day not TB/day. Q: How are security vulnerabilities handled with SC4S? A: SC4S is comprised of several components including RHL, Syslog-ng and temporized configurations. If a vulnerability is found in the SC4S configurations, they will be given a critical priority in the Development queue. If vulnerabilities are identified in the third party components (RHL, Syslog-ng, etc.) the fixed versions will be pulled in upon the next SC4S release. Fixed security issues are identified by \u201c[security]\u201d in SC4S release notes.","title":"Splunk Connect for Syslog (SC4S) Frequently Asked Questions"},{"location":"performance/","text":"Performance and Sizing \u00b6 Performance testing against our lab configuration produces the following results and limitations. Tested Configuration \u00b6 SC4S instance with 2,4,8,12 vCPU using M5zn instances Loggen instance m5zn.large Single instance Splunk using m5zn.3xlarge Result \u00b6 /opt/syslog-ng/bin/loggen -i --rate=100000 --interval=180 -P -F --sdata=\"[test name=\\\"stress17\\\"]\" -s 800 --active-connections=10 hostname 514 # m5zn.large 2 8 GiB average rate = 24077.33 msg/sec, count=4375116, time=181.711, (average) msg size=800, bandwidth=18810.42 kB/sec # m5zn.xlarge 4 16 GiB average rate = 38797.44 msg/sec, count=7028962, time=181.171, (average) msg size=800, bandwidth=30310.50 kB/sec # m5zn.2xlarge 8 32 GiB average rate = 67252.84 msg/sec, count=12153327, time=180.711, (average) msg size=800, bandwidth=52541.28 kB/sec # m5zn.3xlarge 12 48 GiB average rate = 98664.75 msg/sec, count=17834427, time=180.758, (average) msg size=800, bandwidth=77081.84 kB/sec Guidance on sizing hardware \u00b6 Though vCPU (hyper threading) was used, syslog processing is a CPU intensive task and obersubscription (sharing) of resources is not advised The size of the instance must be larger than the absolute peek to prevent data loss; most sources can not buffer during times of congestion CPU Speed is critical; slower or faster CPUs will impact througput Not all sources are equal in resource utilization. Well-formed \u201clegacy BSD\u201d syslog messages were used in this test, but many sources are not syslog compliant and will require additional resources to process.","title":"Performance"},{"location":"performance/#performance-and-sizing","text":"Performance testing against our lab configuration produces the following results and limitations.","title":"Performance and Sizing"},{"location":"performance/#tested-configuration","text":"SC4S instance with 2,4,8,12 vCPU using M5zn instances Loggen instance m5zn.large Single instance Splunk using m5zn.3xlarge","title":"Tested Configuration"},{"location":"performance/#result","text":"/opt/syslog-ng/bin/loggen -i --rate=100000 --interval=180 -P -F --sdata=\"[test name=\\\"stress17\\\"]\" -s 800 --active-connections=10 hostname 514 # m5zn.large 2 8 GiB average rate = 24077.33 msg/sec, count=4375116, time=181.711, (average) msg size=800, bandwidth=18810.42 kB/sec # m5zn.xlarge 4 16 GiB average rate = 38797.44 msg/sec, count=7028962, time=181.171, (average) msg size=800, bandwidth=30310.50 kB/sec # m5zn.2xlarge 8 32 GiB average rate = 67252.84 msg/sec, count=12153327, time=180.711, (average) msg size=800, bandwidth=52541.28 kB/sec # m5zn.3xlarge 12 48 GiB average rate = 98664.75 msg/sec, count=17834427, time=180.758, (average) msg size=800, bandwidth=77081.84 kB/sec","title":"Result"},{"location":"performance/#guidance-on-sizing-hardware","text":"Though vCPU (hyper threading) was used, syslog processing is a CPU intensive task and obersubscription (sharing) of resources is not advised The size of the instance must be larger than the absolute peek to prevent data loss; most sources can not buffer during times of congestion CPU Speed is critical; slower or faster CPUs will impact througput Not all sources are equal in resource utilization. Well-formed \u201clegacy BSD\u201d syslog messages were used in this test, but many sources are not syslog compliant and will require additional resources to process.","title":"Guidance on sizing hardware"},{"location":"upgrade/","text":"Upgrading Splunk Connect for Syslog \u00b6 Splunk Connect for Syslog is updated regularly using a CI/CD development process. The notes below outline significant changes that must be taken into account prior and after an upgrade. Ensure to follow specific instructions below to ensure a smooth transition to a new version of SC4S in production. Upgrade process \u00b6 Check the current version of SC4S by running sudo <docker or podman> logs SC4S . For the latest version, use the latest tag for the SC4S image in the sc4s.service unit file: [Service] Environment = \"SC4S_IMAGE=ghcr.io/splunk/splunk-connect-for-syslog/container:latest\" Restart the service sudo systemctl restart sc4s Using the latest version is recommended, but a specific version can be specified in the unit file if desired: [Service] Environment = \"SC4S_IMAGE=ghcr.io/splunk/splunk-connect-for-syslog/container:1.91.0\" See the release information for more detail.","title":"Upgrading SC4S"},{"location":"upgrade/#upgrading-splunk-connect-for-syslog","text":"Splunk Connect for Syslog is updated regularly using a CI/CD development process. The notes below outline significant changes that must be taken into account prior and after an upgrade. Ensure to follow specific instructions below to ensure a smooth transition to a new version of SC4S in production.","title":"Upgrading Splunk Connect for Syslog"},{"location":"upgrade/#upgrade-process","text":"Check the current version of SC4S by running sudo <docker or podman> logs SC4S . For the latest version, use the latest tag for the SC4S image in the sc4s.service unit file: [Service] Environment = \"SC4S_IMAGE=ghcr.io/splunk/splunk-connect-for-syslog/container:latest\" Restart the service sudo systemctl restart sc4s Using the latest version is recommended, but a specific version can be specified in the unit file if desired: [Service] Environment = \"SC4S_IMAGE=ghcr.io/splunk/splunk-connect-for-syslog/container:1.91.0\" See the release information for more detail.","title":"Upgrade process"},{"location":"developing/","text":"Development setup (BETA) \u00b6 Get Docker \u00b6 Development requires Docker desktop available for windows + and mac or Docker CE available for Linux. Visit (Docker)[https://www.docker.com/get-started] for download instructions Setup VS Code IDE \u00b6 VS Code provides a free IDE experience that is effective for daily development with SC4S. Visit (Microsoft)[https://code.visualstudio.com/docs/introvideos/basics] to download and install for your plaform (windows/mac/linux) Fork and Clone the github repository \u00b6 Visit our repository at (Github)[https://github.com/splunk/splunk-connect-for-syslog] and \u201cfork\u201d our repository. This will allow you to make changes and submit pull requests. Click the clone icon and select the location Setup the project and install requirements \u00b6 The following steps are required only on the first time run. Install VS Code Extensions S Python Test Explorer \u201cPython Test Explorer\u201d From the terminal menu select \u201cRun Task\u201d Select \u201cSetup step 1: python venv\u201d then \u201cgo without scanning output\u201d From the terminal menu select \u201cRun Task\u201d Select \u201cSetup step 2: python requirements\u201d then \u201cgo without scanning output\u201d Click the test lab icon \u00b6 Run all tests. Icons on each test will turn green or red to indicate pass or fail. Though VS Code does not show the status of any given test until all tests complete in the test tree, you can select \u201cShow test output\u201d near the top of the test directory tree to see the terminal output of each test as it runs in the \u201cOutput\u201d pane.","title":"Development"},{"location":"developing/#development-setup-beta","text":"","title":"Development setup (BETA)"},{"location":"developing/#get-docker","text":"Development requires Docker desktop available for windows + and mac or Docker CE available for Linux. Visit (Docker)[https://www.docker.com/get-started] for download instructions","title":"Get Docker"},{"location":"developing/#setup-vs-code-ide","text":"VS Code provides a free IDE experience that is effective for daily development with SC4S. Visit (Microsoft)[https://code.visualstudio.com/docs/introvideos/basics] to download and install for your plaform (windows/mac/linux)","title":"Setup VS Code IDE"},{"location":"developing/#fork-and-clone-the-github-repository","text":"Visit our repository at (Github)[https://github.com/splunk/splunk-connect-for-syslog] and \u201cfork\u201d our repository. This will allow you to make changes and submit pull requests. Click the clone icon and select the location","title":"Fork and Clone the github repository"},{"location":"developing/#setup-the-project-and-install-requirements","text":"The following steps are required only on the first time run. Install VS Code Extensions S Python Test Explorer \u201cPython Test Explorer\u201d From the terminal menu select \u201cRun Task\u201d Select \u201cSetup step 1: python venv\u201d then \u201cgo without scanning output\u201d From the terminal menu select \u201cRun Task\u201d Select \u201cSetup step 2: python requirements\u201d then \u201cgo without scanning output\u201d","title":"Setup the project and install requirements"},{"location":"developing/#click-the-test-lab-icon","text":"Run all tests. Icons on each test will turn green or red to indicate pass or fail. Though VS Code does not show the status of any given test until all tests complete in the test tree, you can select \u201cShow test output\u201d near the top of the test directory tree to see the terminal output of each test as it runs in the \u201cOutput\u201d pane.","title":"Click the test lab icon"},{"location":"gettingstarted/","text":"Before you start \u00b6 Getting Started \u00b6 Splunk Connect for Syslog is a containerized distribution of syslog-ng with a configuration framework designed to simplify getting syslog data into Splunk Enterprise and Splunk Cloud. Our approach is to provide a runtime-agnostic solution allowing customers to deploy using the container runtime environment of choice. Planning Deployment \u00b6 Syslog is an overloaded term that refers to multiple message formats AND optionally a wire protocol for transmission of events between computer systems over UDP, TCP, or TLS. The protocol is designed to minimize overhead on the sender favoring performance over reliability. This fundamental choice means any instability or resource constraint will cause data to be lost in transmission. When practical and cost effective (considering the importance of completeness as a requirement), place the sc4s instance in the same VLAN as the source device. Avoid crossing a Wireless network, WAN, Firewall, Load Balancer, or inline IDS. When High Availability of a single instance of SC4S is required, implement multi node clustering of the container environment. Avoid TCP except where the source is unable to contain the event to a single UDP packet. Avoid TLS except where the event may cross a untrusted network. Plan for appropriately sized hardware Implementation \u00b6 Splunk Setup \u00b6 Create Indexes \u00b6 SC4S is pre-configured to map each sourcetype to a typical index. For new installations, it is best practice to create them in Splunk when using the SC4S defaults. SC4S can be easily customized to use different indexes if desired. email epav epintel infraops netauth netdlp netdns netfw netids netlb netops netwaf netproxy netipam oswin oswinsec osnix print em_metrics (Optional opt-in for SC4S operational metrics; ensure this is created as a metrics index) Install Related Splunk Apps \u00b6 Install the following: IT Essentials Work Configure the Splunk HTTP Event Collector \u00b6 Set up the Splunk HTTP Event Collector with the HEC endpoints behind a load balancer (VIP) configured for https round robin WITHOUT sticky session. Alternatively, a list of HEC endpoint URLs can be configured in SC4S (native syslog-ng load balancing) if no load balancer is in place. In most scenarios the recommendation is to use an external load balancer, as that makes longer term maintenance simpler by eliminating the need to manually keep the list of HEC URLs specified in sc4s current. However, if a LB is not available, native load balancing can be used with 10 or fewer Indexers where HEC is used exclusively for syslog. In either case, it is strongly recommended that SC4S traffic be sent to HEC endpoints configured directly on the indexers rather than an intermediate tier of HWFs. - Create a HEC token that will be used by SC4S and ensure the token has access to place events in main, em_metrics, and all indexes used as event destinations. NOTE: It is recommended that the \u201cSelected Indexes\u201d on the token configuration page be left blank so that the token has access to all indexes, including the lastChanceIndex . If this list is populated, extreme care must be taken to keep it up to date, as an attempt to send data to an index not in this list will result in a 400 error from the HEC endpoint. Furthermore, the lastChanceIndex will not be consulted in the event the index specified in the event is not configured on Splunk. Keep in mind just one bad message will \u201ctaint\u201d the whole batch (by default 1000 events) and prevent the entire batch from being sent to Splunk. Refer to Splunk Cloud or Splunk Enterprise for specific HEC configuration instructions based on your Splunk type. Implement a Container Runtime and SC4S \u00b6 Prerequisites \u00b6 Linux host with Docker (CE 19.x or greater with Docker Swarm) or Podman enabled, depending on runtime choice (below). A network load balancer (NLB) configured for round robin. Note: Special consideration may be required when more advanced products are used. The optimal configuration of the load balancer will round robin each http POST request (not each connection). The host linux OS receive buffer size should be tuned to match the sc4s default to avoid dropping events (packets) at the network level. The default receive buffer for sc4s is set to 16 MB for UDP traffic, which should be OK for most environments. To set the host OS kernel to match this, edit /etc/sysctl.conf using the following whole-byte values corresponding to 16 MB: net.core.rmem_default = 17039360 net.core.rmem_max = 17039360 and apply to the kernel: sysctl -p Ensure the kernel is not dropping packets by periodically monitoring the buffer with the command netstat -su | grep \"receive errors\" . NOTE: Failure to account for high-volume traffic (especially UDP) by tuning the kernel will result in message loss, which can be very unpredictable and difficult to detect. See this helpful discusion in the syslog-ng Professional Edition documentation regarding tuning syslog-ng in particular (via the SC4S_SOURCE_UDP_SO_RCVBUFF environment variable in sc4s) as well as overall host kernel tuning. The default values for receive kernel buffers in most distros is 2 MB, which has proven inadequate for many. IPv4 Forwarding \u00b6 In many distributions (e.g. CentOS provisioned in AWS), IPV4 forwarding is not enabled by default. This needs to be enabled for container networking to function properly. The following is an example to set this up; as usual this needs to be vetted with your enterprise security policy: sudo sysctl net.ipv4.ip_forward=1 To ensure the change survives a reboot edit /etc/sysctl.conf, find (or add) the text below, and uncomment as shown: # Uncomment the next line to enable packet forwarding for IPv4 net . ipv4 . ip_forward = 1 Select a Container Runtime and SC4S Configuration \u00b6 Container Runtime and Orchestration Operating Systems MicroK8s Ubuntu with Microk8s Podman 1.7 & 1.9 + systemd RHEL 8.x or CentOS 8.x (best option), Debian or Ubuntu 18.04LTS Docker CE 18 & 19 + systemd RHEL or CentOS >7.7 (best option), Debian or Ubuntu 18.04LTS Docker CE 18 & 19 + Swarm CentOS >7.7 (best option), Debian or Ubuntu 18.04LTS Docker CE 18 & 19 + Swarm RHEL 7.7 Deprecated Docker Desktop + Compose MacOS Bring your own Envionment RHEL or CentOS 8.1 & 8.2 (best option) Offline Container Installation \u00b6 Follow these instructions to \u201cstage\u201d SC4S by downloading the container so that it can be loaded \u201cout of band\u201d on a host machine, such as an airgapped system, without internet connectivity. Download container image \u201coci_container.tgz\u201d from our Github Page . The following example downloads v1.12; replace the URL with the latest release or pre-release version as desired. sudo wget https : // github . com / splunk / splunk - connect - for - syslog / releases / download / v1 . 12.0 / oci_container . tar . gz Distribute the container to the airgapped host machine using an appropriate file transfer utility. Execute the following command, using docker or podman as appropriate < podman or docker > load < oci_container . tar . gz Note the container ID of the resultant load Loaded image : docker . pkg . github . com / splunk / splunk - connect - for - syslog / ci : 90196 f77f7525bc55b3b966b5fa1ce74861c0250 Use the container ID to create a local label < podman or docker > tag docker . pkg . github . com / splunk / splunk - connect - for - syslog / ci : 90196 f77f7525bc55b3b966b5fa1ce74861c0250 sc4slocal : latest Use this local label sc4slocal:latest in the relevant unit or yaml file to launch SC4S (see the runtime options above) by setting the SC4S_IMAGE environment variable in the unit file (example below), or the relevant image: tag if using Docker Compose/Swarm. Using this label will cause the runtime to select the locally loaded image, and will not attempt to obtain the container image via the internet. Environment=\"SC4S_IMAGE=sc4slocal:latest\" Remove the entry ExecStartPre=/usr/bin/docker pull $SC4S_IMAGE from the relevant unit file when using systemd, as an external connection to pull the container is no longer needed (or available).","title":"Read First"},{"location":"gettingstarted/#before-you-start","text":"","title":"Before you start"},{"location":"gettingstarted/#getting-started","text":"Splunk Connect for Syslog is a containerized distribution of syslog-ng with a configuration framework designed to simplify getting syslog data into Splunk Enterprise and Splunk Cloud. Our approach is to provide a runtime-agnostic solution allowing customers to deploy using the container runtime environment of choice.","title":"Getting Started"},{"location":"gettingstarted/#planning-deployment","text":"Syslog is an overloaded term that refers to multiple message formats AND optionally a wire protocol for transmission of events between computer systems over UDP, TCP, or TLS. The protocol is designed to minimize overhead on the sender favoring performance over reliability. This fundamental choice means any instability or resource constraint will cause data to be lost in transmission. When practical and cost effective (considering the importance of completeness as a requirement), place the sc4s instance in the same VLAN as the source device. Avoid crossing a Wireless network, WAN, Firewall, Load Balancer, or inline IDS. When High Availability of a single instance of SC4S is required, implement multi node clustering of the container environment. Avoid TCP except where the source is unable to contain the event to a single UDP packet. Avoid TLS except where the event may cross a untrusted network. Plan for appropriately sized hardware","title":"Planning Deployment"},{"location":"gettingstarted/#implementation","text":"","title":"Implementation"},{"location":"gettingstarted/#splunk-setup","text":"","title":"Splunk Setup"},{"location":"gettingstarted/#create-indexes","text":"SC4S is pre-configured to map each sourcetype to a typical index. For new installations, it is best practice to create them in Splunk when using the SC4S defaults. SC4S can be easily customized to use different indexes if desired. email epav epintel infraops netauth netdlp netdns netfw netids netlb netops netwaf netproxy netipam oswin oswinsec osnix print em_metrics (Optional opt-in for SC4S operational metrics; ensure this is created as a metrics index)","title":"Create Indexes"},{"location":"gettingstarted/#install-related-splunk-apps","text":"Install the following: IT Essentials Work","title":"Install Related Splunk Apps"},{"location":"gettingstarted/#configure-the-splunk-http-event-collector","text":"Set up the Splunk HTTP Event Collector with the HEC endpoints behind a load balancer (VIP) configured for https round robin WITHOUT sticky session. Alternatively, a list of HEC endpoint URLs can be configured in SC4S (native syslog-ng load balancing) if no load balancer is in place. In most scenarios the recommendation is to use an external load balancer, as that makes longer term maintenance simpler by eliminating the need to manually keep the list of HEC URLs specified in sc4s current. However, if a LB is not available, native load balancing can be used with 10 or fewer Indexers where HEC is used exclusively for syslog. In either case, it is strongly recommended that SC4S traffic be sent to HEC endpoints configured directly on the indexers rather than an intermediate tier of HWFs. - Create a HEC token that will be used by SC4S and ensure the token has access to place events in main, em_metrics, and all indexes used as event destinations. NOTE: It is recommended that the \u201cSelected Indexes\u201d on the token configuration page be left blank so that the token has access to all indexes, including the lastChanceIndex . If this list is populated, extreme care must be taken to keep it up to date, as an attempt to send data to an index not in this list will result in a 400 error from the HEC endpoint. Furthermore, the lastChanceIndex will not be consulted in the event the index specified in the event is not configured on Splunk. Keep in mind just one bad message will \u201ctaint\u201d the whole batch (by default 1000 events) and prevent the entire batch from being sent to Splunk. Refer to Splunk Cloud or Splunk Enterprise for specific HEC configuration instructions based on your Splunk type.","title":"Configure the Splunk HTTP Event Collector"},{"location":"gettingstarted/#implement-a-container-runtime-and-sc4s","text":"","title":"Implement a Container Runtime and SC4S"},{"location":"gettingstarted/#prerequisites","text":"Linux host with Docker (CE 19.x or greater with Docker Swarm) or Podman enabled, depending on runtime choice (below). A network load balancer (NLB) configured for round robin. Note: Special consideration may be required when more advanced products are used. The optimal configuration of the load balancer will round robin each http POST request (not each connection). The host linux OS receive buffer size should be tuned to match the sc4s default to avoid dropping events (packets) at the network level. The default receive buffer for sc4s is set to 16 MB for UDP traffic, which should be OK for most environments. To set the host OS kernel to match this, edit /etc/sysctl.conf using the following whole-byte values corresponding to 16 MB: net.core.rmem_default = 17039360 net.core.rmem_max = 17039360 and apply to the kernel: sysctl -p Ensure the kernel is not dropping packets by periodically monitoring the buffer with the command netstat -su | grep \"receive errors\" . NOTE: Failure to account for high-volume traffic (especially UDP) by tuning the kernel will result in message loss, which can be very unpredictable and difficult to detect. See this helpful discusion in the syslog-ng Professional Edition documentation regarding tuning syslog-ng in particular (via the SC4S_SOURCE_UDP_SO_RCVBUFF environment variable in sc4s) as well as overall host kernel tuning. The default values for receive kernel buffers in most distros is 2 MB, which has proven inadequate for many.","title":"Prerequisites"},{"location":"gettingstarted/#ipv4-forwarding","text":"In many distributions (e.g. CentOS provisioned in AWS), IPV4 forwarding is not enabled by default. This needs to be enabled for container networking to function properly. The following is an example to set this up; as usual this needs to be vetted with your enterprise security policy: sudo sysctl net.ipv4.ip_forward=1 To ensure the change survives a reboot edit /etc/sysctl.conf, find (or add) the text below, and uncomment as shown: # Uncomment the next line to enable packet forwarding for IPv4 net . ipv4 . ip_forward = 1","title":"IPv4 Forwarding"},{"location":"gettingstarted/#select-a-container-runtime-and-sc4s-configuration","text":"Container Runtime and Orchestration Operating Systems MicroK8s Ubuntu with Microk8s Podman 1.7 & 1.9 + systemd RHEL 8.x or CentOS 8.x (best option), Debian or Ubuntu 18.04LTS Docker CE 18 & 19 + systemd RHEL or CentOS >7.7 (best option), Debian or Ubuntu 18.04LTS Docker CE 18 & 19 + Swarm CentOS >7.7 (best option), Debian or Ubuntu 18.04LTS Docker CE 18 & 19 + Swarm RHEL 7.7 Deprecated Docker Desktop + Compose MacOS Bring your own Envionment RHEL or CentOS 8.1 & 8.2 (best option)","title":"Select a Container Runtime and SC4S Configuration"},{"location":"gettingstarted/#offline-container-installation","text":"Follow these instructions to \u201cstage\u201d SC4S by downloading the container so that it can be loaded \u201cout of band\u201d on a host machine, such as an airgapped system, without internet connectivity. Download container image \u201coci_container.tgz\u201d from our Github Page . The following example downloads v1.12; replace the URL with the latest release or pre-release version as desired. sudo wget https : // github . com / splunk / splunk - connect - for - syslog / releases / download / v1 . 12.0 / oci_container . tar . gz Distribute the container to the airgapped host machine using an appropriate file transfer utility. Execute the following command, using docker or podman as appropriate < podman or docker > load < oci_container . tar . gz Note the container ID of the resultant load Loaded image : docker . pkg . github . com / splunk / splunk - connect - for - syslog / ci : 90196 f77f7525bc55b3b966b5fa1ce74861c0250 Use the container ID to create a local label < podman or docker > tag docker . pkg . github . com / splunk / splunk - connect - for - syslog / ci : 90196 f77f7525bc55b3b966b5fa1ce74861c0250 sc4slocal : latest Use this local label sc4slocal:latest in the relevant unit or yaml file to launch SC4S (see the runtime options above) by setting the SC4S_IMAGE environment variable in the unit file (example below), or the relevant image: tag if using Docker Compose/Swarm. Using this label will cause the runtime to select the locally loaded image, and will not attempt to obtain the container image via the internet. Environment=\"SC4S_IMAGE=sc4slocal:latest\" Remove the entry ExecStartPre=/usr/bin/docker pull $SC4S_IMAGE from the relevant unit file when using systemd, as an external connection to pull the container is no longer needed (or available).","title":"Offline Container Installation"},{"location":"gettingstarted/byoe-rhel8/","text":"SC4S \u201cBring Your Own Environment\u201d \u00b6 FOREWORD: The BYOE SC4S deliverable should be considered as a self/community supported option for SC4S deployment, and should be considered only by those with specific needs based on advanced understanding of syslog-ng architectures and linux/syslog-ng system administration and the ability to develop and automate testing in non-production environments. The container deliverable is the most often correct deliverable of SC4S for almost all enterprises. If you are simply trying to \u201cget syslog working\u201d, the turnkey, container approach described in the other runtime documents will be the fastest route to success. The \u201cBring Your Own Environment\u201d instructions that follow allow expert administrators to utilize the SC4S syslog-ng config files directly on the host OS running on a hardware server or virtual machine. Administrators must provide an appropriate host OS (RHEL 8 used in this document) as well as an up-to-date syslog-ng installation either built from source (not documented here) or installed from community-built RPMs. Modification of the base configuration will be required for most customer environments due to enterprise infrastructure variations. Once installed preparing an upgrade requires evaluation of the current environment compared to this reference then developing and testing a installation specific install plan. This activity is the responsibility of the administrator. NOTE: Installing or modifying system configurations can have unexpected consequences, and advanced linux system administration and syslog-ng configuration experience is assumed when using the BYOE version of SC4S. NOTE: Do not depend on the distribution-supplied version of syslog-ng, as it will likely be far too old. Read this explanation for the reason why syslog-ng builds are so dated in almost all RHEL/Debian distributions. BYOE Installation Instructions \u00b6 These installation instructions assume a recent RHEL or CentOS-based release. Minor adjustments may have to be made for Debian/Ubuntu. In addition, almost all pre-compiled binaries for syslog-ng assume installation in /etc/syslog-ng ; these instructions will reflect that. The following installation instructions are summarized from a blog maintained by a developer at One Identity (formerly Balabit), who is the owner of the syslog-ng Open Source project. It is always adivisable to review the blog for the latest changes to the repo(s), as changes here are quite dynamic. Install CentOS or RHEL 8.0 Enable EPEL (Centos 8) dnf install 'dnf-command(copr)' -y dnf install epel-release -y dnf copr enable czanik/syslog-ng334 -y dnf install syslog-ng syslog-ng-python syslog-ng-http syslog-ng-afsnmp net-snmp python3-pip gcc python3-devel -y Disable the distro-supplied syslog-ng unit file, as the syslog-ng process configured here will run as the sc4s service. rsyslog will continue to be the system logger, but should be left enabled only if it is configured to not listen on the same ports as sc4s. sc4s BYOE can be configured to provide local logging as well if desired. sudo systemctl stop syslog-ng sudo systemctl disable syslog-ng Download the latest bare_metal.tar from releases on github and untar the package in /etc/syslog-ng using the command example below. NOTE: The wget process below will unpack a tarball with the sc4s version of the syslog-ng config files in the standard /etc/syslog-ng location, and will overwrite existing content. Ensure that any previous configurations of syslog-ng are saved if needed prior to executing the download step. NOTE: At the time of writing, the latest major release is v1.33 . The latest release is typically listed first on the page above, unless there is an -alpha , -beta , or -rc release that is newer (which will be clearly indicated). For production use, select the latest that does not have an -rc , -alpha , or -beta suffix. sudo wget -c https://github.com/splunk/splunk-connect-for-syslog/releases/download/<latest release>/baremetal.tar -O - | sudo tar -x -C /etc/syslog-ng Install python requirements sudo pip3 install -r /etc/syslog-ng/requirements.txt (Optional, for monitoring): Install goss and confirm that the version is v0.3.16 or newer. goss installs in /usr/local/bin by default, so ensure that 1) entrypoint.sh is modified to include /usr/local/bin in the full path, or 2) move the goss binary to /bin or /usr/bin . curl - L https : // github . com / aelsabbahy / goss / releases / latest / download / goss - linux - amd64 - o / usr / local / bin / goss chmod + rx / usr / local / bin / goss curl - L https : // github . com / aelsabbahy / goss / releases / latest / download / dgoss - o / usr / local / bin / dgoss # Alternatively, using the latest # curl -L https://raw.githubusercontent.com/aelsabbahy/goss/latest/extras/dgoss/dgoss -o /usr/local/bin/dgoss chmod + rx / usr / local / bin / dgoss There are two main options for running SC4S via systemd, the choice of which largely depends on administrator preference and orchestration methodology: 1) the entrypoint.sh script (identical to that used in the container) can be run directly via systemd, or 2) the script can be altered to preconfigure SC4S (after which only the syslog-ng and snmp executables are run via systemd). These are by no means the only ways to run BYOE \u2013 as the name implies, the method you choose will be based on your custom needs. To run the entrypoint.sh script directly in systemd, create the sc4s unit file /lib/systemd/system/sc4s.service and add the following content: [Unit] Description = SC4S Syslog Daemon Documentation = https://splunk-connect-for-syslog.readthedocs.io/en/latest/ Wants = network.target network-online.target After = network.target network-online.target [Service] Type = simple ExecStart = /etc/syslog-ng/entrypoint.sh ExecReload = /bin/kill -HUP $MAINPID EnvironmentFile = /etc/syslog-ng/env_file StandardOutput = journal StandardError = journal Restart = on-abnormal [Install] WantedBy = multi-user.target To run entrypoint.sh as a \u201cpreconfigure\u201d script, modify the script by commenting out or removing the stanzas following the OPTIONAL for BYOE comments in the script. This will prevent syslog-ng (and optionally snmptrapd) from being launched by the script. Then create the sc4s unit file /lib/systemd/system/syslog-ng.service and add the following content: [Unit] Description = System Logger Daemon Documentation = man:syslog-ng(8) After = network.target [Service] Type = notify ExecStart = /usr/sbin/syslog-ng -F $SYSLOGNG_OPTS -p /var/run/syslogd.pid ExecReload = /bin/kill -HUP $MAINPID EnvironmentFile = -/etc/default/syslog-ng EnvironmentFile = -/etc/sysconfig/syslog-ng StandardOutput = journal StandardError = journal Restart = on-failure [Install] WantedBy = multi-user.target Create the file /etc/syslog-ng/env_file and add the following environment variables (adjusting the URL/TOKEN appropriately): # The following \"path\" variables can differ from the container defaults specified in the entrypoint.sh script. # These are *optional* for most BYOE installations, which do noot differ from the install location used. # in the container version of SC4S. Failure to properly set these will cause startup failure. #SC4S_ETC=/etc/syslog-ng #SC4S_VAR=/etc/syslog-ng/var #SC4S_BIN=/bin #SC4S_SBIN=/usr/sbin #SC4S_TLS=/etc/syslog-ng/tls # General Options SC4S_DEST_SPLUNK_HEC_DEFAULT_URL = https : // splunk . smg . aws : 8088 SC4S_DEST_SPLUNK_HEC_DEFAULT_TOKEN = a778f63a - 5 dff - 4e3 c - a72c - a03183659e94 # Uncomment the following line if using untrusted (self-signed) SSL certificates # SC4S_DEST_SPLUNK_HEC_DEFAULT_TLS_VERIFY=no Reload systemctl and restart syslog-ng (example here is shown for systemd option (1) above) sudo systemctl daemon-reload sudo systemctl enable sc4s sudo systemctl start sc4s Configure SC4S Listening Ports \u00b6 Most enterprises use UDP/TCP port 514 as the default as their main listening port for syslog \u201csoup\u201d traffic, and TCP port 6514 for TLS. The standard SC4S configuration reflect these defaults. These defaults can be changed by adding the following additional environment variables with appropriate values to the env_file above: SC4S_LISTEN_DEFAULT_TCP_PORT=514 SC4S_LISTEN_DEFAULT_UDP_PORT=514 SC4S_LISTEN_DEFAULT_RFC6587_PORT=601 SC4S_LISTEN_DEFAULT_RFC5426_PORT=601 SC4S_LISTEN_DEFAULT_RFC5425_PORT=5425 SC4S_LISTEN_DEFAULT_TLS_PORT=6514 Dedicated (Unique) Listening Ports \u00b6 For certain source technologies, categorization by message content is impossible due to the lack of a unique \u201cfingerprint\u201d in the data. In other cases, a unique listening port is required for certain devices due to network requirements in the enterprise. For collection of such sources we provide a means of dedicating a unique listening port to a specific source. Refer to the \u201cSources\u201d documentation to identify the specific environment variables used to enable unique listening ports for the technology in use.","title":"Bring your own Envionment"},{"location":"gettingstarted/byoe-rhel8/#sc4s-bring-your-own-environment","text":"FOREWORD: The BYOE SC4S deliverable should be considered as a self/community supported option for SC4S deployment, and should be considered only by those with specific needs based on advanced understanding of syslog-ng architectures and linux/syslog-ng system administration and the ability to develop and automate testing in non-production environments. The container deliverable is the most often correct deliverable of SC4S for almost all enterprises. If you are simply trying to \u201cget syslog working\u201d, the turnkey, container approach described in the other runtime documents will be the fastest route to success. The \u201cBring Your Own Environment\u201d instructions that follow allow expert administrators to utilize the SC4S syslog-ng config files directly on the host OS running on a hardware server or virtual machine. Administrators must provide an appropriate host OS (RHEL 8 used in this document) as well as an up-to-date syslog-ng installation either built from source (not documented here) or installed from community-built RPMs. Modification of the base configuration will be required for most customer environments due to enterprise infrastructure variations. Once installed preparing an upgrade requires evaluation of the current environment compared to this reference then developing and testing a installation specific install plan. This activity is the responsibility of the administrator. NOTE: Installing or modifying system configurations can have unexpected consequences, and advanced linux system administration and syslog-ng configuration experience is assumed when using the BYOE version of SC4S. NOTE: Do not depend on the distribution-supplied version of syslog-ng, as it will likely be far too old. Read this explanation for the reason why syslog-ng builds are so dated in almost all RHEL/Debian distributions.","title":"SC4S \"Bring Your Own Environment\""},{"location":"gettingstarted/byoe-rhel8/#byoe-installation-instructions","text":"These installation instructions assume a recent RHEL or CentOS-based release. Minor adjustments may have to be made for Debian/Ubuntu. In addition, almost all pre-compiled binaries for syslog-ng assume installation in /etc/syslog-ng ; these instructions will reflect that. The following installation instructions are summarized from a blog maintained by a developer at One Identity (formerly Balabit), who is the owner of the syslog-ng Open Source project. It is always adivisable to review the blog for the latest changes to the repo(s), as changes here are quite dynamic. Install CentOS or RHEL 8.0 Enable EPEL (Centos 8) dnf install 'dnf-command(copr)' -y dnf install epel-release -y dnf copr enable czanik/syslog-ng334 -y dnf install syslog-ng syslog-ng-python syslog-ng-http syslog-ng-afsnmp net-snmp python3-pip gcc python3-devel -y Disable the distro-supplied syslog-ng unit file, as the syslog-ng process configured here will run as the sc4s service. rsyslog will continue to be the system logger, but should be left enabled only if it is configured to not listen on the same ports as sc4s. sc4s BYOE can be configured to provide local logging as well if desired. sudo systemctl stop syslog-ng sudo systemctl disable syslog-ng Download the latest bare_metal.tar from releases on github and untar the package in /etc/syslog-ng using the command example below. NOTE: The wget process below will unpack a tarball with the sc4s version of the syslog-ng config files in the standard /etc/syslog-ng location, and will overwrite existing content. Ensure that any previous configurations of syslog-ng are saved if needed prior to executing the download step. NOTE: At the time of writing, the latest major release is v1.33 . The latest release is typically listed first on the page above, unless there is an -alpha , -beta , or -rc release that is newer (which will be clearly indicated). For production use, select the latest that does not have an -rc , -alpha , or -beta suffix. sudo wget -c https://github.com/splunk/splunk-connect-for-syslog/releases/download/<latest release>/baremetal.tar -O - | sudo tar -x -C /etc/syslog-ng Install python requirements sudo pip3 install -r /etc/syslog-ng/requirements.txt (Optional, for monitoring): Install goss and confirm that the version is v0.3.16 or newer. goss installs in /usr/local/bin by default, so ensure that 1) entrypoint.sh is modified to include /usr/local/bin in the full path, or 2) move the goss binary to /bin or /usr/bin . curl - L https : // github . com / aelsabbahy / goss / releases / latest / download / goss - linux - amd64 - o / usr / local / bin / goss chmod + rx / usr / local / bin / goss curl - L https : // github . com / aelsabbahy / goss / releases / latest / download / dgoss - o / usr / local / bin / dgoss # Alternatively, using the latest # curl -L https://raw.githubusercontent.com/aelsabbahy/goss/latest/extras/dgoss/dgoss -o /usr/local/bin/dgoss chmod + rx / usr / local / bin / dgoss There are two main options for running SC4S via systemd, the choice of which largely depends on administrator preference and orchestration methodology: 1) the entrypoint.sh script (identical to that used in the container) can be run directly via systemd, or 2) the script can be altered to preconfigure SC4S (after which only the syslog-ng and snmp executables are run via systemd). These are by no means the only ways to run BYOE \u2013 as the name implies, the method you choose will be based on your custom needs. To run the entrypoint.sh script directly in systemd, create the sc4s unit file /lib/systemd/system/sc4s.service and add the following content: [Unit] Description = SC4S Syslog Daemon Documentation = https://splunk-connect-for-syslog.readthedocs.io/en/latest/ Wants = network.target network-online.target After = network.target network-online.target [Service] Type = simple ExecStart = /etc/syslog-ng/entrypoint.sh ExecReload = /bin/kill -HUP $MAINPID EnvironmentFile = /etc/syslog-ng/env_file StandardOutput = journal StandardError = journal Restart = on-abnormal [Install] WantedBy = multi-user.target To run entrypoint.sh as a \u201cpreconfigure\u201d script, modify the script by commenting out or removing the stanzas following the OPTIONAL for BYOE comments in the script. This will prevent syslog-ng (and optionally snmptrapd) from being launched by the script. Then create the sc4s unit file /lib/systemd/system/syslog-ng.service and add the following content: [Unit] Description = System Logger Daemon Documentation = man:syslog-ng(8) After = network.target [Service] Type = notify ExecStart = /usr/sbin/syslog-ng -F $SYSLOGNG_OPTS -p /var/run/syslogd.pid ExecReload = /bin/kill -HUP $MAINPID EnvironmentFile = -/etc/default/syslog-ng EnvironmentFile = -/etc/sysconfig/syslog-ng StandardOutput = journal StandardError = journal Restart = on-failure [Install] WantedBy = multi-user.target Create the file /etc/syslog-ng/env_file and add the following environment variables (adjusting the URL/TOKEN appropriately): # The following \"path\" variables can differ from the container defaults specified in the entrypoint.sh script. # These are *optional* for most BYOE installations, which do noot differ from the install location used. # in the container version of SC4S. Failure to properly set these will cause startup failure. #SC4S_ETC=/etc/syslog-ng #SC4S_VAR=/etc/syslog-ng/var #SC4S_BIN=/bin #SC4S_SBIN=/usr/sbin #SC4S_TLS=/etc/syslog-ng/tls # General Options SC4S_DEST_SPLUNK_HEC_DEFAULT_URL = https : // splunk . smg . aws : 8088 SC4S_DEST_SPLUNK_HEC_DEFAULT_TOKEN = a778f63a - 5 dff - 4e3 c - a72c - a03183659e94 # Uncomment the following line if using untrusted (self-signed) SSL certificates # SC4S_DEST_SPLUNK_HEC_DEFAULT_TLS_VERIFY=no Reload systemctl and restart syslog-ng (example here is shown for systemd option (1) above) sudo systemctl daemon-reload sudo systemctl enable sc4s sudo systemctl start sc4s","title":"BYOE Installation Instructions"},{"location":"gettingstarted/byoe-rhel8/#configure-sc4s-listening-ports","text":"Most enterprises use UDP/TCP port 514 as the default as their main listening port for syslog \u201csoup\u201d traffic, and TCP port 6514 for TLS. The standard SC4S configuration reflect these defaults. These defaults can be changed by adding the following additional environment variables with appropriate values to the env_file above: SC4S_LISTEN_DEFAULT_TCP_PORT=514 SC4S_LISTEN_DEFAULT_UDP_PORT=514 SC4S_LISTEN_DEFAULT_RFC6587_PORT=601 SC4S_LISTEN_DEFAULT_RFC5426_PORT=601 SC4S_LISTEN_DEFAULT_RFC5425_PORT=5425 SC4S_LISTEN_DEFAULT_TLS_PORT=6514","title":"Configure SC4S Listening Ports"},{"location":"gettingstarted/byoe-rhel8/#dedicated-unique-listening-ports","text":"For certain source technologies, categorization by message content is impossible due to the lack of a unique \u201cfingerprint\u201d in the data. In other cases, a unique listening port is required for certain devices due to network requirements in the enterprise. For collection of such sources we provide a means of dedicating a unique listening port to a specific source. Refer to the \u201cSources\u201d documentation to identify the specific environment variables used to enable unique listening ports for the technology in use.","title":"Dedicated (Unique) Listening Ports"},{"location":"gettingstarted/docker-compose-MacOS/","text":"Install Docker Desktop for MacOS \u00b6 Refer to Installation SC4S Initial Configuration \u00b6 SC4S can be run with docker-compose or directly from the CLI with the simple docker run command. Both options are outlined below. Create a directory on the server for local configurations and disk buffering. This should be available to all administrators, for example: /opt/sc4s/ (Optional for docker-compose ) Create a docker-compose.yml file in the directory created above, based on the template below: IMPORTANT: Always use the latest compose file (below) with the current release. By default, the latest container is automatically downloaded at each restart. Therefore, make it a habit to check back here regularly to be sure any changes that may have been made to the compose template file below (e.g. suggested mount points) are incoproprated in production prior to relaunching via compose. version : \"3.7\" services : sc4s : image : ghcr.io/splunk/splunk-connect-for-syslog/container:1 ports : - target : 514 published : 514 protocol : tcp - target : 514 published : 514 protocol : udp - target : 601 published : 601 protocol : tcp - target : 6514 published : 6514 protocol : tcp env_file : - /opt/sc4s/env_file volumes : - /opt/sc4s/local:/etc/syslog-ng/conf.d/local:z - splunk-sc4s-var:/var/lib/syslog-ng # Uncomment the following line if local disk archiving is desired # - /opt/sc4s/archive:/var/lib/syslog-ng/archive:z # Map location of TLS custom TLS # - /opt/sc4s/tls:/etc/syslog-ng/tls:z volumes : splunk-sc4s-var : Execute the following command to create a local volume that will contain the disk buffer files in the event of a communication failure to the upstream destination(s). This will also be used to keep track of the state of syslog-ng between restarts, and in particular the state of the disk buffer. This is a required step. sudo docker volume create splunk - sc4s - var NOTE: Be sure to account for disk space requirements for the docker volume created above. This volume is located in /var/lib/docker/volumes/ and could grow significantly if there is an extended outage to the SC4S destinations (typically HEC endpoints). See the \u201cSC4S Disk Buffer Configuration\u201d section on the Configruation page for more info. Create the subdirectory /opt/sc4s/local . This will be used as a mount point for local overrides and configurations. The empty local directory created above will populate with defaults and examples at the first invocation of SC4S for local configurations and context overrides. Do not change the directory structure of the files that are laid down; change (or add) only individual files if desired. SC4S depends on the directory layout to read the local configurations properly. See the notes below for which files will be preserved on restarts. In the local/config/ directory there are four subdirectories that allow you to provide support for device types that are not provided out of the box in SC4S. To get you started, there is an example log path template ( lp-example.conf.tmpl ) and a filter ( example.conf ) in the log_paths and filters subdirectories, respectively. These should not be used directly, but copied as templates for your own log path development. They will get overwritten at each SC4S start. In the local/context directory, if you change the \u201cnon-example\u201d version of a file (e.g. splunk_metadata.csv ) the changes will be preserved on a restart. Create the subdirectory /opt/sc4s/archive . This will be used as a mount point for local storage of syslog events (if the optional mount is uncommented above). The events will be written in the syslog-ng EWMM format. See the \u201cconfiguration\u201d document for details on the directory structure the archive uses. Create the subdirectory /opt/sc4s/tls . This will be used as a mount point for custom TLS certificates (if the optional mount is uncommented above). IMPORTANT: When creating the directories above, ensure the directories created match the volume mounts specified in the docker-compose.yml file (if used). Failure to do this will cause SC4S to abort at startup. Configure the SC4S environment \u00b6 SC4S is almost entirely controlled through environment variables, which are read from a file at starteup. Create a file named /opt/sc4s/env_file and add the following environment variables and values: SC4S_DEST_SPLUNK_HEC_DEFAULT_URL = https : // splunk . smg . aws : 8088 SC4S_DEST_SPLUNK_HEC_DEFAULT_TOKEN = a778f63a - 5 dff - 4 e3c - a72c - a03183659e94 # Uncomment the following line if using untrusted SSL certificates # SC4S_DEST_SPLUNK_HEC_DEFAULT_TLS_VERIFY = no Update SC4S_DEST_SPLUNK_HEC_DEFAULT_URL and SC4S_DEST_SPLUNK_HEC_DEFAULT_TOKEN to reflect the correct values for your environment. Do not configure HEC Acknowledgement when deploying the HEC token on the Splunk side; the underlying syslog-ng http destination does not support this feature. Moreover, HEC Ack would significantly degrade performance for streaming data such as syslog. The default number of SC4S_DEST_SPLUNK_HEC_WORKERS is 10. Consult the community if you feel the number of workers (threads) should deviate from this. NOTE: Splunk Connect for Syslog defaults to secure configurations. If you are not using trusted SSL certificates, be sure to uncomment the last line in the example above. Dedicated (Unique) Listening Ports \u00b6 For certain source technologies, categorization by message content is impossible due to the lack of a unique \u201cfingerprint\u201d in the data. In other cases, a unique listening port is required for certain devices due to network requirements in the enterprise. For collection of such sources, we provide a means of dedicating a unique listening port to a specific source. NOTE: Container networking differs on MacOS compared to that for linux. On Docker Desktop, there is no \u201chost\u201d networking driver, so NAT networking must be used. For this reason, each listening port on the container must be mapped to a listenting port on the host. These port mappings are configured in the docker-compose.yml file or directly as a runtime option when run out of the CLI. Be sure to update the docker-compose.yml file or CLI arguments when adding listenting ports for new data sources. Follow these steps to configure unique ports: Modify the /opt/sc4s/env_file file to include the port-specific environment variable(s). Refer to the \u201cSources\u201d documentation to identify the specific environment variables that are mapped to each data source vendor/technology. (Optional for docker-compose ) The docker compose file used to start the SC4S container needs to be modified as well to reflect the additional listening ports configured by the environment variable(s) added above. The docker compose file can be ammended with additional target stanzas in the ports section of the file (after the default ports). For example, the following additional target and published lines provide for 21 additional technology-specific UDP and TCP ports: - target: 5000-5020 published: 5000-5020 protocol: tcp - target: 5000-5020 published: 5000-5020 protocol: udp Restart SC4S using the command in the \u201cStart/Restart SC4S\u201d section below. Modify index destinations for Splunk \u00b6 Log paths are preconfigured to utilize a convention of index destinations that are suitable for most customers. If changes need to be made to index destinations, navigate to the /opt/sc4s/local/context directory to start. Edit splunk_metadata.csv to review or change the index configuration as required for the data sources utilized in your environment. The key (1st column) in this file uses the syntax vendor_product . Simply replace the index value (the 3rd column) in the desired row with the index appropriate for your Splunk installation. The \u201cSources\u201d document details the specific vendor_product keys (rows) in this table that pertain to the individual data source filters that are included with SC4S. Other Splunk metadata (e.g. source and sourcetype) can be overriden via this file as well. This is an advanced topic, and further information is covered in the \u201cLog Path overrides\u201d section of the Configuration document. Configure source filtering by source IP or host name \u00b6 Legacy sources and non-standard-compliant sources require configuration by source IP or hostname as included in the event. The following steps apply to support such sources. To identify sources that require this step, refer to the \u201csources\u201d section of this documentation. If changes need to be made to source filtering, navigate to the /opt/sc4s/local/context directory to start. Navigate to vendor_product_by_source.conf and find the appropriate filter that matches your legacy device type. Edit the file to properly identify these products by hostname glob or network mask using syslog-ng filter syntax. Configuration by hostname or source IP is needed only for those devices that cannot be determined via normal syslog-ng parsing or message contents. The vendor_product_by_source.csv file should not need to be changed unless a local log path is created that is specific to the environment. In this case, a matching filter will also need to be provided in vendor_product_by_source.conf . Configure compliance index/metadata overrides \u00b6 In some cases, devices that have been properly sourcetyped need to be further categorized by compliance, geography, or other criterion. The two files compliance_meta_by_source.conf and compliance_meta_by_source.csv can be used for this purpose. These operate similarly to the files above, where the conf file specifies a filter to uniquely identify the messages that should be overridden, and the csv file lists one or more metadata items that can be overridden based on the filter name. This is an advanced topic, and further information is covered in the \u201cOverride index or metadata based on host, ip, or subnet\u201d section of the Configuration document. Start/Restart SC4S \u00b6 You can use the following command to directly start SC4S if you are not using docker-compose . Be sure to map the listening ports ( -p arguments) according to your needs: / usr / bin / podman run - p 514 : 514 - p 514 : 514 / udp - p 6514 : 6514 - p 5000 - 5020 : 5000 - 5020 - p 5000 - 5020 : 5000 - 5020 / udp \\ -- env - file =/ opt / sc4s / env_file \\ - v splunk - sc4s - var : / var / lib / syslog - ng \\ - v / opt / sc4s / local : / etc / syslog - ng / conf . d / local : z \\ - v / opt / sc4s / archive : / var / lib / syslog - ng / archive : z \\ -- name SC4S \\ -- rm splunk / scs : latest If you are using docker-compose , from the /opt/sc4s directory execute: docker-compose up --compose-file docker-compose.yml Stop SC4S \u00b6 If the container is run directly from the CLI, simply stop the container using the docker stop <containerID> command. If using docker-compose , execute: docker-compose down --compose-file docker-compose.yml Verify Proper Operation \u00b6 SC4S has a number of \u201cpreflight\u201d checks to ensure that the container starts properly and that the syntax of the underlying syslog-ng configuration is correct. After this step completes, to verify SC4S is properly communicating with Splunk, execute the following search in Splunk: index = * sourcetype=sc4s:events \"starting up\" This should yield an event similar to the following: syslog-ng starting up; version = '3.28.1' when the startup process proceeds normally (without syntax errors). If you do not see this, follow the steps below before proceeding to deeper-level troubleshooting: Check to see that the URL, token, and TLS/SSL settings are correct, and that the appropriate firewall ports are open (8088 or 443). Check to see that the proper indexes are created in Splunk, and that the token has access to them. Ensure the proper operation of the load balancer if used. Lastly, execute the following command to check the sc4s startup process running in the container. docker logs SC4S You should see events similar to those below in the output: syslog-ng checking config sc4s version = v1.36.0 starting goss starting syslog-ng If you do not see the output above, proceed to the \u201cTroubleshooting\u201d section for more detailed information.","title":"Docker Desktop + Compose (MacOS)"},{"location":"gettingstarted/docker-compose-MacOS/#install-docker-desktop-for-macos","text":"Refer to Installation","title":"Install Docker Desktop for MacOS"},{"location":"gettingstarted/docker-compose-MacOS/#sc4s-initial-configuration","text":"SC4S can be run with docker-compose or directly from the CLI with the simple docker run command. Both options are outlined below. Create a directory on the server for local configurations and disk buffering. This should be available to all administrators, for example: /opt/sc4s/ (Optional for docker-compose ) Create a docker-compose.yml file in the directory created above, based on the template below: IMPORTANT: Always use the latest compose file (below) with the current release. By default, the latest container is automatically downloaded at each restart. Therefore, make it a habit to check back here regularly to be sure any changes that may have been made to the compose template file below (e.g. suggested mount points) are incoproprated in production prior to relaunching via compose. version : \"3.7\" services : sc4s : image : ghcr.io/splunk/splunk-connect-for-syslog/container:1 ports : - target : 514 published : 514 protocol : tcp - target : 514 published : 514 protocol : udp - target : 601 published : 601 protocol : tcp - target : 6514 published : 6514 protocol : tcp env_file : - /opt/sc4s/env_file volumes : - /opt/sc4s/local:/etc/syslog-ng/conf.d/local:z - splunk-sc4s-var:/var/lib/syslog-ng # Uncomment the following line if local disk archiving is desired # - /opt/sc4s/archive:/var/lib/syslog-ng/archive:z # Map location of TLS custom TLS # - /opt/sc4s/tls:/etc/syslog-ng/tls:z volumes : splunk-sc4s-var : Execute the following command to create a local volume that will contain the disk buffer files in the event of a communication failure to the upstream destination(s). This will also be used to keep track of the state of syslog-ng between restarts, and in particular the state of the disk buffer. This is a required step. sudo docker volume create splunk - sc4s - var NOTE: Be sure to account for disk space requirements for the docker volume created above. This volume is located in /var/lib/docker/volumes/ and could grow significantly if there is an extended outage to the SC4S destinations (typically HEC endpoints). See the \u201cSC4S Disk Buffer Configuration\u201d section on the Configruation page for more info. Create the subdirectory /opt/sc4s/local . This will be used as a mount point for local overrides and configurations. The empty local directory created above will populate with defaults and examples at the first invocation of SC4S for local configurations and context overrides. Do not change the directory structure of the files that are laid down; change (or add) only individual files if desired. SC4S depends on the directory layout to read the local configurations properly. See the notes below for which files will be preserved on restarts. In the local/config/ directory there are four subdirectories that allow you to provide support for device types that are not provided out of the box in SC4S. To get you started, there is an example log path template ( lp-example.conf.tmpl ) and a filter ( example.conf ) in the log_paths and filters subdirectories, respectively. These should not be used directly, but copied as templates for your own log path development. They will get overwritten at each SC4S start. In the local/context directory, if you change the \u201cnon-example\u201d version of a file (e.g. splunk_metadata.csv ) the changes will be preserved on a restart. Create the subdirectory /opt/sc4s/archive . This will be used as a mount point for local storage of syslog events (if the optional mount is uncommented above). The events will be written in the syslog-ng EWMM format. See the \u201cconfiguration\u201d document for details on the directory structure the archive uses. Create the subdirectory /opt/sc4s/tls . This will be used as a mount point for custom TLS certificates (if the optional mount is uncommented above). IMPORTANT: When creating the directories above, ensure the directories created match the volume mounts specified in the docker-compose.yml file (if used). Failure to do this will cause SC4S to abort at startup.","title":"SC4S Initial Configuration"},{"location":"gettingstarted/docker-compose-MacOS/#configure-the-sc4s-environment","text":"SC4S is almost entirely controlled through environment variables, which are read from a file at starteup. Create a file named /opt/sc4s/env_file and add the following environment variables and values: SC4S_DEST_SPLUNK_HEC_DEFAULT_URL = https : // splunk . smg . aws : 8088 SC4S_DEST_SPLUNK_HEC_DEFAULT_TOKEN = a778f63a - 5 dff - 4 e3c - a72c - a03183659e94 # Uncomment the following line if using untrusted SSL certificates # SC4S_DEST_SPLUNK_HEC_DEFAULT_TLS_VERIFY = no Update SC4S_DEST_SPLUNK_HEC_DEFAULT_URL and SC4S_DEST_SPLUNK_HEC_DEFAULT_TOKEN to reflect the correct values for your environment. Do not configure HEC Acknowledgement when deploying the HEC token on the Splunk side; the underlying syslog-ng http destination does not support this feature. Moreover, HEC Ack would significantly degrade performance for streaming data such as syslog. The default number of SC4S_DEST_SPLUNK_HEC_WORKERS is 10. Consult the community if you feel the number of workers (threads) should deviate from this. NOTE: Splunk Connect for Syslog defaults to secure configurations. If you are not using trusted SSL certificates, be sure to uncomment the last line in the example above.","title":"Configure the SC4S environment"},{"location":"gettingstarted/docker-compose-MacOS/#dedicated-unique-listening-ports","text":"For certain source technologies, categorization by message content is impossible due to the lack of a unique \u201cfingerprint\u201d in the data. In other cases, a unique listening port is required for certain devices due to network requirements in the enterprise. For collection of such sources, we provide a means of dedicating a unique listening port to a specific source. NOTE: Container networking differs on MacOS compared to that for linux. On Docker Desktop, there is no \u201chost\u201d networking driver, so NAT networking must be used. For this reason, each listening port on the container must be mapped to a listenting port on the host. These port mappings are configured in the docker-compose.yml file or directly as a runtime option when run out of the CLI. Be sure to update the docker-compose.yml file or CLI arguments when adding listenting ports for new data sources. Follow these steps to configure unique ports: Modify the /opt/sc4s/env_file file to include the port-specific environment variable(s). Refer to the \u201cSources\u201d documentation to identify the specific environment variables that are mapped to each data source vendor/technology. (Optional for docker-compose ) The docker compose file used to start the SC4S container needs to be modified as well to reflect the additional listening ports configured by the environment variable(s) added above. The docker compose file can be ammended with additional target stanzas in the ports section of the file (after the default ports). For example, the following additional target and published lines provide for 21 additional technology-specific UDP and TCP ports: - target: 5000-5020 published: 5000-5020 protocol: tcp - target: 5000-5020 published: 5000-5020 protocol: udp Restart SC4S using the command in the \u201cStart/Restart SC4S\u201d section below.","title":"Dedicated (Unique) Listening Ports"},{"location":"gettingstarted/docker-compose-MacOS/#modify-index-destinations-for-splunk","text":"Log paths are preconfigured to utilize a convention of index destinations that are suitable for most customers. If changes need to be made to index destinations, navigate to the /opt/sc4s/local/context directory to start. Edit splunk_metadata.csv to review or change the index configuration as required for the data sources utilized in your environment. The key (1st column) in this file uses the syntax vendor_product . Simply replace the index value (the 3rd column) in the desired row with the index appropriate for your Splunk installation. The \u201cSources\u201d document details the specific vendor_product keys (rows) in this table that pertain to the individual data source filters that are included with SC4S. Other Splunk metadata (e.g. source and sourcetype) can be overriden via this file as well. This is an advanced topic, and further information is covered in the \u201cLog Path overrides\u201d section of the Configuration document.","title":"Modify index destinations for Splunk"},{"location":"gettingstarted/docker-compose-MacOS/#configure-source-filtering-by-source-ip-or-host-name","text":"Legacy sources and non-standard-compliant sources require configuration by source IP or hostname as included in the event. The following steps apply to support such sources. To identify sources that require this step, refer to the \u201csources\u201d section of this documentation. If changes need to be made to source filtering, navigate to the /opt/sc4s/local/context directory to start. Navigate to vendor_product_by_source.conf and find the appropriate filter that matches your legacy device type. Edit the file to properly identify these products by hostname glob or network mask using syslog-ng filter syntax. Configuration by hostname or source IP is needed only for those devices that cannot be determined via normal syslog-ng parsing or message contents. The vendor_product_by_source.csv file should not need to be changed unless a local log path is created that is specific to the environment. In this case, a matching filter will also need to be provided in vendor_product_by_source.conf .","title":"Configure source filtering by source IP or host name"},{"location":"gettingstarted/docker-compose-MacOS/#configure-compliance-indexmetadata-overrides","text":"In some cases, devices that have been properly sourcetyped need to be further categorized by compliance, geography, or other criterion. The two files compliance_meta_by_source.conf and compliance_meta_by_source.csv can be used for this purpose. These operate similarly to the files above, where the conf file specifies a filter to uniquely identify the messages that should be overridden, and the csv file lists one or more metadata items that can be overridden based on the filter name. This is an advanced topic, and further information is covered in the \u201cOverride index or metadata based on host, ip, or subnet\u201d section of the Configuration document.","title":"Configure compliance index/metadata overrides"},{"location":"gettingstarted/docker-compose-MacOS/#startrestart-sc4s","text":"You can use the following command to directly start SC4S if you are not using docker-compose . Be sure to map the listening ports ( -p arguments) according to your needs: / usr / bin / podman run - p 514 : 514 - p 514 : 514 / udp - p 6514 : 6514 - p 5000 - 5020 : 5000 - 5020 - p 5000 - 5020 : 5000 - 5020 / udp \\ -- env - file =/ opt / sc4s / env_file \\ - v splunk - sc4s - var : / var / lib / syslog - ng \\ - v / opt / sc4s / local : / etc / syslog - ng / conf . d / local : z \\ - v / opt / sc4s / archive : / var / lib / syslog - ng / archive : z \\ -- name SC4S \\ -- rm splunk / scs : latest If you are using docker-compose , from the /opt/sc4s directory execute: docker-compose up --compose-file docker-compose.yml","title":"Start/Restart SC4S"},{"location":"gettingstarted/docker-compose-MacOS/#stop-sc4s","text":"If the container is run directly from the CLI, simply stop the container using the docker stop <containerID> command. If using docker-compose , execute: docker-compose down --compose-file docker-compose.yml","title":"Stop SC4S"},{"location":"gettingstarted/docker-compose-MacOS/#verify-proper-operation","text":"SC4S has a number of \u201cpreflight\u201d checks to ensure that the container starts properly and that the syntax of the underlying syslog-ng configuration is correct. After this step completes, to verify SC4S is properly communicating with Splunk, execute the following search in Splunk: index = * sourcetype=sc4s:events \"starting up\" This should yield an event similar to the following: syslog-ng starting up; version = '3.28.1' when the startup process proceeds normally (without syntax errors). If you do not see this, follow the steps below before proceeding to deeper-level troubleshooting: Check to see that the URL, token, and TLS/SSL settings are correct, and that the appropriate firewall ports are open (8088 or 443). Check to see that the proper indexes are created in Splunk, and that the token has access to them. Ensure the proper operation of the load balancer if used. Lastly, execute the following command to check the sc4s startup process running in the container. docker logs SC4S You should see events similar to those below in the output: syslog-ng checking config sc4s version = v1.36.0 starting goss starting syslog-ng If you do not see the output above, proceed to the \u201cTroubleshooting\u201d section for more detailed information.","title":"Verify Proper Operation"},{"location":"gettingstarted/docker-swarm-general/","text":"NOTE (version 1.40+): Docker compose is no longer recommended for production use \u00b6 Install Docker CE and Swarm \u00b6 Refer to relevant installation guides: CentOS Ubuntu Debian Desktop NOTE: If using a CentOS image provisioned in AWS, IPV4 forwarding is not enabled by default. This needs to be enabled for container networking to function properly. The following is an example to set this up; as usual this needs to be vetted with your enterprise security policy: sudo sysctl net.ipv4.ip_forward=1 Then, edit /etc/sysctl.conf, find the text below, and uncomment as shown so that the change made above will survive a reboot: # Uncomment the next line to enable packet forwarding for IPv4 net . ipv4 . ip_forward = 1 SC4S Initial Configuration \u00b6 Create a directory on the server for local configurations and disk buffering. This should be available to all administrators, for example: /opt/sc4s/ Create a docker-compose.yml file in the directory created above, based on the template below: IMPORTANT: Always use the latest compose file (below) with the current release. By default, the latest container is automatically downloaded at each restart. Therefore, make it a habit to check back here regularly to be sure any changes that may have been made to the compose template file below (e.g. suggested mount points) are incoproprated in production prior to relaunching via compose. version : \"3.7\" services : sc4s : image : ghcr.io/splunk/splunk-connect-for-syslog/container:1 networks : - host env_file : - /opt/sc4s/env_file volumes : - /opt/sc4s/local:/etc/syslog-ng/conf.d/local:z - splunk-sc4s-var:/var/lib/syslog-ng # Uncomment the following line if local disk archiving is desired # - /opt/sc4s/archive:/var/lib/syslog-ng/archive:z # Map location of TLS custom TLS # - /opt/sc4s/tls:/etc/syslog-ng/tls:z volumes : splunk-sc4s-var : networks : host : name : host external : true Execute the following command to create a local volume that will contain the disk buffer files in the event of a communication failure to the upstream destination(s). This will also be used to keep track of the state of syslog-ng between restarts, and in particular the state of the disk buffer. This is a required step. sudo docker volume create splunk - sc4s - var NOTE: Be sure to account for disk space requirements for the docker volume created above. This volume is located in /var/lib/docker/volumes/ and could grow significantly if there is an extended outage to the SC4S destinations (typically HEC endpoints). See the \u201cSC4S Disk Buffer Configuration\u201d section on the Configruation page for more info. Create the subdirectory /opt/sc4s/local . This will be used as a mount point for local overrides and configurations. The empty local directory created above will populate with defaults and examples at the first invocation of SC4S for local configurations and context overrides. Do not change the directory structure of the files that are laid down; change (or add) only individual files if desired. SC4S depends on the directory layout to read the local configurations properly. See the notes below for which files will be preserved on restarts. In the local/config/ directory there are four subdirectories that allow you to provide support for device types that are not provided out of the box in SC4S. To get you started, there is an example log path template ( lp-example.conf.tmpl ) and a filter ( example.conf ) in the log_paths and filters subdirectories, respectively. These should not be used directly, but copied as templates for your own log path development. They will get overwritten at each SC4S start. In the local/context directory, if you change the \u201cnon-example\u201d version of a file (e.g. splunk_metadata.csv ) the changes will be preserved on a restart. Create the subdirectory /opt/sc4s/archive . This will be used as a mount point for local storage of syslog events (if the optional mount is uncommented above). The events will be written in the syslog-ng EWMM format. See the \u201cconfiguration\u201d document for details on the directory structure the archive uses. Create the subdirectory /opt/sc4s/tls . This will be used as a mount point for custom TLS certificates (if the optional mount is uncommented above). IMPORTANT: When creating the directories above, ensure the directories created match the volume mounts specified in the docker-compose.yml file. Failure to do this will cause SC4S to abort at startup. Configure the SC4S environment \u00b6 SC4S is almost entirely controlled through environment variables, which are read from a file at starteup. Create a file named /opt/sc4s/env_file and add the following environment variables and values: SC4S_DEST_SPLUNK_HEC_DEFAULT_URL = https : // splunk . smg . aws : 8088 SC4S_DEST_SPLUNK_HEC_DEFAULT_TOKEN = a778f63a - 5 dff - 4 e3c - a72c - a03183659e94 # Uncomment the following line if using untrusted SSL certificates # SC4S_DEST_SPLUNK_HEC_DEFAULT_TLS_VERIFY = no Update SC4S_DEST_SPLUNK_HEC_DEFAULT_URL and SC4S_DEST_SPLUNK_HEC_DEFAULT_TOKEN to reflect the correct values for your environment. Do not configure HEC Acknowledgement when deploying the HEC token on the Splunk side; the underlying syslog-ng http destination does not support this feature. Moreover, HEC Ack would significantly degrade performance for streaming data such as syslog. The default number of SC4S_DEST_SPLUNK_HEC_WORKERS is 10. Consult the community if you feel the number of workers (threads) should deviate from this. NOTE: Splunk Connect for Syslog defaults to secure configurations. If you are not using trusted SSL certificates, be sure to uncomment the last line in the example above. Dedicated (Unique) Listening Ports \u00b6 For certain source technologies, categorization by message content is impossible due to the lack of a unique \u201cfingerprint\u201d in the data. In other cases, a unique listening port is required for certain devices due to network requirements in the enterprise. For collection of such sources, we provide a means of dedicating a unique listening port to a specific source. Follow this step to configure unique ports for one or more sources: Modify the /opt/sc4s/env_file file to include the port-specific environment variable(s). Refer to the \u201cSources\u201d documentation to identify the specific environment variables that are mapped to each data source vendor/technology. Modify index destinations for Splunk \u00b6 Log paths are preconfigured to utilize a convention of index destinations that are suitable for most customers. If changes need to be made to index destinations, navigate to the /opt/sc4s/local/context directory to start. Edit splunk_metadata.csv to review or change the index configuration as required for the data sources utilized in your environment. The key (1st column) in this file uses the syntax vendor_product . Simply replace the index value (the 3rd column) in the desired row with the index appropriate for your Splunk installation. The \u201cSources\u201d document details the specific vendor_product keys (rows) in this table that pertain to the individual data source filters that are included with SC4S. Other Splunk metadata (e.g. source and sourcetype) can be overriden via this file as well. This is an advanced topic, and further information is covered in the \u201cLog Path overrides\u201d section of the Configuration document. Configure source filtering by source IP or host name \u00b6 Legacy sources and non-standard-compliant sources require configuration by source IP or hostname as included in the event. The following steps apply to support such sources. To identify sources that require this step, refer to the \u201csources\u201d section of this documentation. If changes need to be made to source filtering, navigate to the /opt/sc4s/local/context directory to start. Navigate to vendor_product_by_source.conf and find the appropriate filter that matches your legacy device type. Edit the file to properly identify these products by hostname glob or network mask using syslog-ng filter syntax. Configuration by hostname or source IP is needed only for those devices that cannot be determined via normal syslog-ng parsing or message contents. The vendor_product_by_source.csv file should not need to be changed unless a local log path is created that is specific to the environment. In this case, a matching filter will also need to be provided in vendor_product_by_source.conf . Configure compliance index/metadata overrides \u00b6 In some cases, devices that have been properly sourcetyped need to be further categorized by compliance, geography, or other criterion. The two files compliance_meta_by_source.conf and compliance_meta_by_source.csv can be used for this purpose. These operate similarly to the files above, where the conf file specifies a filter to uniquely identify the messages that should be overridden, and the csv file lists one or more metadata items that can be overridden based on the filter name. This is an advanced topic, and further information is covered in the \u201cOverride index or metadata based on host, ip, or subnet\u201d section of the Configuration document. Start/Restart SC4S \u00b6 docker stack deploy --compose-file docker-compose.yml sc4s Stop SC4S \u00b6 Start by obtaining the stack name (ID): docker stack ls Then, remove the stack: docker stack rm <ID> Verify Proper Operation \u00b6 SC4S has a number of \u201cpreflight\u201d checks to ensure that the container starts properly and that the syntax of the underlying syslog-ng configuration is correct. After this step completes, to verify SC4S is properly communicating with Splunk, execute the following search in Splunk: index = * sourcetype=sc4s:events \"starting up\" This should yield an event similar to the following: syslog-ng starting up; version = '3.28.1' when the startup process proceeds normally (without syntax errors). If you do not see this, follow the steps below before proceeding to deeper-level troubleshooting: Check to see that the URL, token, and TLS/SSL settings are correct, and that the appropriate firewall ports are open (8088 or 443). Check to see that the proper indexes are created in Splunk, and that the token has access to them. Ensure the proper operation of the load balancer if used. Lastly, execute the following command to check the sc4s startup process running in the container. docker logs SC4S You should see events similar to those below in the output: syslog-ng checking config sc4s version = v1.36.0 starting goss starting syslog-ng If you do not see the output above, proceed to the \u201cTroubleshooting\u201d section for more detailed information.","title":"Docker Compose"},{"location":"gettingstarted/docker-swarm-general/#note-version-140-docker-compose-is-no-longer-recommended-for-production-use","text":"","title":"NOTE (version 1.40+): Docker compose is no longer recommended for production use"},{"location":"gettingstarted/docker-swarm-general/#install-docker-ce-and-swarm","text":"Refer to relevant installation guides: CentOS Ubuntu Debian Desktop NOTE: If using a CentOS image provisioned in AWS, IPV4 forwarding is not enabled by default. This needs to be enabled for container networking to function properly. The following is an example to set this up; as usual this needs to be vetted with your enterprise security policy: sudo sysctl net.ipv4.ip_forward=1 Then, edit /etc/sysctl.conf, find the text below, and uncomment as shown so that the change made above will survive a reboot: # Uncomment the next line to enable packet forwarding for IPv4 net . ipv4 . ip_forward = 1","title":"Install Docker CE and Swarm"},{"location":"gettingstarted/docker-swarm-general/#sc4s-initial-configuration","text":"Create a directory on the server for local configurations and disk buffering. This should be available to all administrators, for example: /opt/sc4s/ Create a docker-compose.yml file in the directory created above, based on the template below: IMPORTANT: Always use the latest compose file (below) with the current release. By default, the latest container is automatically downloaded at each restart. Therefore, make it a habit to check back here regularly to be sure any changes that may have been made to the compose template file below (e.g. suggested mount points) are incoproprated in production prior to relaunching via compose. version : \"3.7\" services : sc4s : image : ghcr.io/splunk/splunk-connect-for-syslog/container:1 networks : - host env_file : - /opt/sc4s/env_file volumes : - /opt/sc4s/local:/etc/syslog-ng/conf.d/local:z - splunk-sc4s-var:/var/lib/syslog-ng # Uncomment the following line if local disk archiving is desired # - /opt/sc4s/archive:/var/lib/syslog-ng/archive:z # Map location of TLS custom TLS # - /opt/sc4s/tls:/etc/syslog-ng/tls:z volumes : splunk-sc4s-var : networks : host : name : host external : true Execute the following command to create a local volume that will contain the disk buffer files in the event of a communication failure to the upstream destination(s). This will also be used to keep track of the state of syslog-ng between restarts, and in particular the state of the disk buffer. This is a required step. sudo docker volume create splunk - sc4s - var NOTE: Be sure to account for disk space requirements for the docker volume created above. This volume is located in /var/lib/docker/volumes/ and could grow significantly if there is an extended outage to the SC4S destinations (typically HEC endpoints). See the \u201cSC4S Disk Buffer Configuration\u201d section on the Configruation page for more info. Create the subdirectory /opt/sc4s/local . This will be used as a mount point for local overrides and configurations. The empty local directory created above will populate with defaults and examples at the first invocation of SC4S for local configurations and context overrides. Do not change the directory structure of the files that are laid down; change (or add) only individual files if desired. SC4S depends on the directory layout to read the local configurations properly. See the notes below for which files will be preserved on restarts. In the local/config/ directory there are four subdirectories that allow you to provide support for device types that are not provided out of the box in SC4S. To get you started, there is an example log path template ( lp-example.conf.tmpl ) and a filter ( example.conf ) in the log_paths and filters subdirectories, respectively. These should not be used directly, but copied as templates for your own log path development. They will get overwritten at each SC4S start. In the local/context directory, if you change the \u201cnon-example\u201d version of a file (e.g. splunk_metadata.csv ) the changes will be preserved on a restart. Create the subdirectory /opt/sc4s/archive . This will be used as a mount point for local storage of syslog events (if the optional mount is uncommented above). The events will be written in the syslog-ng EWMM format. See the \u201cconfiguration\u201d document for details on the directory structure the archive uses. Create the subdirectory /opt/sc4s/tls . This will be used as a mount point for custom TLS certificates (if the optional mount is uncommented above). IMPORTANT: When creating the directories above, ensure the directories created match the volume mounts specified in the docker-compose.yml file. Failure to do this will cause SC4S to abort at startup.","title":"SC4S Initial Configuration"},{"location":"gettingstarted/docker-swarm-general/#configure-the-sc4s-environment","text":"SC4S is almost entirely controlled through environment variables, which are read from a file at starteup. Create a file named /opt/sc4s/env_file and add the following environment variables and values: SC4S_DEST_SPLUNK_HEC_DEFAULT_URL = https : // splunk . smg . aws : 8088 SC4S_DEST_SPLUNK_HEC_DEFAULT_TOKEN = a778f63a - 5 dff - 4 e3c - a72c - a03183659e94 # Uncomment the following line if using untrusted SSL certificates # SC4S_DEST_SPLUNK_HEC_DEFAULT_TLS_VERIFY = no Update SC4S_DEST_SPLUNK_HEC_DEFAULT_URL and SC4S_DEST_SPLUNK_HEC_DEFAULT_TOKEN to reflect the correct values for your environment. Do not configure HEC Acknowledgement when deploying the HEC token on the Splunk side; the underlying syslog-ng http destination does not support this feature. Moreover, HEC Ack would significantly degrade performance for streaming data such as syslog. The default number of SC4S_DEST_SPLUNK_HEC_WORKERS is 10. Consult the community if you feel the number of workers (threads) should deviate from this. NOTE: Splunk Connect for Syslog defaults to secure configurations. If you are not using trusted SSL certificates, be sure to uncomment the last line in the example above.","title":"Configure the SC4S environment"},{"location":"gettingstarted/docker-swarm-general/#dedicated-unique-listening-ports","text":"For certain source technologies, categorization by message content is impossible due to the lack of a unique \u201cfingerprint\u201d in the data. In other cases, a unique listening port is required for certain devices due to network requirements in the enterprise. For collection of such sources, we provide a means of dedicating a unique listening port to a specific source. Follow this step to configure unique ports for one or more sources: Modify the /opt/sc4s/env_file file to include the port-specific environment variable(s). Refer to the \u201cSources\u201d documentation to identify the specific environment variables that are mapped to each data source vendor/technology.","title":"Dedicated (Unique) Listening Ports"},{"location":"gettingstarted/docker-swarm-general/#modify-index-destinations-for-splunk","text":"Log paths are preconfigured to utilize a convention of index destinations that are suitable for most customers. If changes need to be made to index destinations, navigate to the /opt/sc4s/local/context directory to start. Edit splunk_metadata.csv to review or change the index configuration as required for the data sources utilized in your environment. The key (1st column) in this file uses the syntax vendor_product . Simply replace the index value (the 3rd column) in the desired row with the index appropriate for your Splunk installation. The \u201cSources\u201d document details the specific vendor_product keys (rows) in this table that pertain to the individual data source filters that are included with SC4S. Other Splunk metadata (e.g. source and sourcetype) can be overriden via this file as well. This is an advanced topic, and further information is covered in the \u201cLog Path overrides\u201d section of the Configuration document.","title":"Modify index destinations for Splunk"},{"location":"gettingstarted/docker-swarm-general/#configure-source-filtering-by-source-ip-or-host-name","text":"Legacy sources and non-standard-compliant sources require configuration by source IP or hostname as included in the event. The following steps apply to support such sources. To identify sources that require this step, refer to the \u201csources\u201d section of this documentation. If changes need to be made to source filtering, navigate to the /opt/sc4s/local/context directory to start. Navigate to vendor_product_by_source.conf and find the appropriate filter that matches your legacy device type. Edit the file to properly identify these products by hostname glob or network mask using syslog-ng filter syntax. Configuration by hostname or source IP is needed only for those devices that cannot be determined via normal syslog-ng parsing or message contents. The vendor_product_by_source.csv file should not need to be changed unless a local log path is created that is specific to the environment. In this case, a matching filter will also need to be provided in vendor_product_by_source.conf .","title":"Configure source filtering by source IP or host name"},{"location":"gettingstarted/docker-swarm-general/#configure-compliance-indexmetadata-overrides","text":"In some cases, devices that have been properly sourcetyped need to be further categorized by compliance, geography, or other criterion. The two files compliance_meta_by_source.conf and compliance_meta_by_source.csv can be used for this purpose. These operate similarly to the files above, where the conf file specifies a filter to uniquely identify the messages that should be overridden, and the csv file lists one or more metadata items that can be overridden based on the filter name. This is an advanced topic, and further information is covered in the \u201cOverride index or metadata based on host, ip, or subnet\u201d section of the Configuration document.","title":"Configure compliance index/metadata overrides"},{"location":"gettingstarted/docker-swarm-general/#startrestart-sc4s","text":"docker stack deploy --compose-file docker-compose.yml sc4s","title":"Start/Restart SC4S"},{"location":"gettingstarted/docker-swarm-general/#stop-sc4s","text":"Start by obtaining the stack name (ID): docker stack ls Then, remove the stack: docker stack rm <ID>","title":"Stop SC4S"},{"location":"gettingstarted/docker-swarm-general/#verify-proper-operation","text":"SC4S has a number of \u201cpreflight\u201d checks to ensure that the container starts properly and that the syntax of the underlying syslog-ng configuration is correct. After this step completes, to verify SC4S is properly communicating with Splunk, execute the following search in Splunk: index = * sourcetype=sc4s:events \"starting up\" This should yield an event similar to the following: syslog-ng starting up; version = '3.28.1' when the startup process proceeds normally (without syntax errors). If you do not see this, follow the steps below before proceeding to deeper-level troubleshooting: Check to see that the URL, token, and TLS/SSL settings are correct, and that the appropriate firewall ports are open (8088 or 443). Check to see that the proper indexes are created in Splunk, and that the token has access to them. Ensure the proper operation of the load balancer if used. Lastly, execute the following command to check the sc4s startup process running in the container. docker logs SC4S You should see events similar to those below in the output: syslog-ng checking config sc4s version = v1.36.0 starting goss starting syslog-ng If you do not see the output above, proceed to the \u201cTroubleshooting\u201d section for more detailed information.","title":"Verify Proper Operation"},{"location":"gettingstarted/docker-swarm-rhel7/","text":"NOTE (version 1.40+): Docker compose is no longer recommended for production use \u00b6 Install Docker CE and Swarm (RHEL 7.7) \u00b6 Warning: this method of installing docker on RHEL is not officially supported by RedHat. Consider using podman instead. Enable required repositories \u00b6 subscription-manager repos --enable = rhel-7-server-rpms subscription-manager repos --enable = rhel-7-server-extras-rpms subscription-manager repos --enable = rhel-7-server-optional-rpms yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo Enable EPEL \u00b6 yum install wget -y cd /tmp wget https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm rpm -Uvh epel-release-latest-7.noarch.rpm Install required packages and enable docker \u00b6 yum install docker-ce -y systemctl enable docker.service systemctl start docker.service Initialize Docker Swarm \u00b6 sudo docker swarm init SC4S Initial Configuration \u00b6 Create a directory on the server for local configurations and disk buffering. This should be available to all administrators, for example: /opt/sc4s/ Create a docker-compose.yml file in the directory created above, based on the template below: IMPORTANT: Always use the latest compose file (below) with the current release. By default, the latest container is automatically downloaded at each restart. Therefore, make it a habit to check back here regularly to be sure any changes that may have been made to the compose template file below (e.g. suggested mount points) are incoproprated in production prior to relaunching via compose. version : \"3.7\" services : sc4s : image : ghcr.io/splunk/splunk-connect-for-syslog/container:1 networks : - host env_file : - /opt/sc4s/env_file volumes : - /opt/sc4s/local:/etc/syslog-ng/conf.d/local:z - splunk-sc4s-var:/var/lib/syslog-ng # Uncomment the following line if local disk archiving is desired # - /opt/sc4s/archive:/var/lib/syslog-ng/archive:z # Map location of TLS custom TLS # - /opt/sc4s/tls:/etc/syslog-ng/tls:z volumes : splunk-sc4s-var : networks : host : name : host external : true Execute the following command to create a local volume that will contain the disk buffer files in the event of a communication failure to the upstream destination(s). This will also be used to keep track of the state of syslog-ng between restarts, and in particular the state of the disk buffer. This is a required step. sudo docker volume create splunk - sc4s - var NOTE: Be sure to account for disk space requirements for the docker volume created above. This volume is located in /var/lib/docker/volumes/ and could grow significantly if there is an extended outage to the SC4S destinations (typically HEC endpoints). See the \u201cSC4S Disk Buffer Configuration\u201d section on the Configruation page for more info. Create the subdirectory /opt/sc4s/local . This will be used as a mount point for local overrides and configurations. The empty local directory created above will populate with defaults and examples at the first invocation of SC4S for local configurations and context overrides. Do not change the directory structure of the files that are laid down; change (or add) only individual files if desired. SC4S depends on the directory layout to read the local configurations properly. See the notes below for which files will be preserved on restarts. In the local/config/ directory there are four subdirectories that allow you to provide support for device types that are not provided out of the box in SC4S. To get you started, there is an example log path template ( lp-example.conf.tmpl ) and a filter ( example.conf ) in the log_paths and filters subdirectories, respectively. These should not be used directly, but copied as templates for your own log path development. They will get overwritten at each SC4S start. In the local/context directory, if you change the \u201cnon-example\u201d version of a file (e.g. splunk_metadata.csv ) the changes will be preserved on a restart. Create the subdirectory /opt/sc4s/archive . This will be used as a mount point for local storage of syslog events (if the optional mount is uncommented above). The events will be written in the syslog-ng EWMM format. See the \u201cconfiguration\u201d document for details on the directory structure the archive uses. Create the subdirectory /opt/sc4s/tls . This will be used as a mount point for custom TLS certificates (if the optional mount is uncommented above). IMPORTANT: When creating the directories above, ensure the directories created match the volume mounts specified in the docker-compose.yml file. Failure to do this will cause SC4S to abort at startup. Configure the SC4S environment \u00b6 SC4S is almost entirely controlled through environment variables, which are read from a file at starteup. Create a file named /opt/sc4s/env_file and add the following environment variables and values: SC4S_DEST_SPLUNK_HEC_DEFAULT_URL = https : // splunk . smg . aws : 8088 SC4S_DEST_SPLUNK_HEC_DEFAULT_TOKEN = a778f63a - 5 dff - 4 e3c - a72c - a03183659e94 # Uncomment the following line if using untrusted SSL certificates # SC4S_DEST_SPLUNK_HEC_DEFAULT_TLS_VERIFY = no Update SC4S_DEST_SPLUNK_HEC_DEFAULT_URL and SC4S_DEST_SPLUNK_HEC_DEFAULT_TOKEN to reflect the correct values for your environment. Do not configure HEC Acknowledgement when deploying the HEC token on the Splunk side; the underlying syslog-ng http destination does not support this feature. Moreover, HEC Ack would significantly degrade performance for streaming data such as syslog. The default number of SC4S_DEST_SPLUNK_HEC_WORKERS is 10. Consult the community if you feel the number of workers (threads) should deviate from this. NOTE: Splunk Connect for Syslog defaults to secure configurations. If you are not using trusted SSL certificates, be sure to uncomment the last line in the example above. Dedicated (Unique) Listening Ports \u00b6 For certain source technologies, categorization by message content is impossible due to the lack of a unique \u201cfingerprint\u201d in the data. In other cases, a unique listening port is required for certain devices due to network requirements in the enterprise. For collection of such sources, we provide a means of dedicating a unique listening port to a specific source. Follow this step to configure unique ports for one or more sources: Modify the /opt/sc4s/env_file file to include the port-specific environment variable(s). Refer to the \u201cSources\u201d documentation to identify the specific environment variables that are mapped to each data source vendor/technology. Modify index destinations for Splunk \u00b6 Log paths are preconfigured to utilize a convention of index destinations that are suitable for most customers. If changes need to be made to index destinations, navigate to the /opt/sc4s/local/context directory to start. Edit splunk_metadata.csv to review or change the index configuration as required for the data sources utilized in your environment. The key (1st column) in this file uses the syntax vendor_product . Simply replace the index value (the 3rd column) in the desired row with the index appropriate for your Splunk installation. The \u201cSources\u201d document details the specific vendor_product keys (rows) in this table that pertain to the individual data source filters that are included with SC4S. Other Splunk metadata (e.g. source and sourcetype) can be overriden via this file as well. This is an advanced topic, and further information is covered in the \u201cLog Path overrides\u201d section of the Configuration document. Configure source filtering by source IP or host name \u00b6 Legacy sources and non-standard-compliant sources require configuration by source IP or hostname as included in the event. The following steps apply to support such sources. To identify sources that require this step, refer to the \u201csources\u201d section of this documentation. If changes need to be made to source filtering, navigate to the /opt/sc4s/local/context directory to start. Navigate to vendor_product_by_source.conf and find the appropriate filter that matches your legacy device type. Edit the file to properly identify these products by hostname glob or network mask using syslog-ng filter syntax. Configuration by hostname or source IP is needed only for those devices that cannot be determined via normal syslog-ng parsing or message contents. The vendor_product_by_source.csv file should not need to be changed unless a local log path is created that is specific to the environment. In this case, a matching filter will also need to be provided in vendor_product_by_source.conf . Configure compliance index/metadata overrides \u00b6 In some cases, devices that have been properly sourcetyped need to be further categorized by compliance, geography, or other criterion. The two files compliance_meta_by_source.conf and compliance_meta_by_source.csv can be used for this purpose. These operate similarly to the files above, where the conf file specifies a filter to uniquely identify the messages that should be overridden, and the csv file lists one or more metadata items that can be overridden based on the filter name. This is an advanced topic, and further information is covered in the \u201cOverride index or metadata based on host, ip, or subnet\u201d section of the Configuration document. Start/Restart SC4S \u00b6 docker stack deploy --compose-file docker-compose.yml sc4s Stop SC4S \u00b6 Start by obtaining the stack name (ID): docker stack ls Then, remove the stack: docker stack rm <ID> Verify Proper Operation \u00b6 SC4S has a number of \u201cpreflight\u201d checks to ensure that the container starts properly and that the syntax of the underlying syslog-ng configuration is correct. After this step completes, to verify SC4S is properly communicating with Splunk, execute the following search in Splunk: index = * sourcetype=sc4s:events \"starting up\" This should yield an event similar to the following: syslog-ng starting up; version = '3.28.1' when the startup process proceeds normally (without syntax errors). If you do not see this, follow the steps below before proceeding to deeper-level troubleshooting: Check to see that the URL, token, and TLS/SSL settings are correct, and that the appropriate firewall ports are open (8088 or 443). Check to see that the proper indexes are created in Splunk, and that the token has access to them. Ensure the proper operation of the load balancer if used. Lastly, execute the following command to check the sc4s startup process running in the container. docker logs SC4S You should see events similar to those below in the output: syslog-ng checking config sc4s version = v1.36.0 starting goss starting syslog-ng If you do not see the output above, proceed to the \u201cTroubleshooting\u201d section for more detailed information.","title":"NOTE (version 1.40+): Docker compose is no longer recommended for production use"},{"location":"gettingstarted/docker-swarm-rhel7/#note-version-140-docker-compose-is-no-longer-recommended-for-production-use","text":"","title":"NOTE (version 1.40+): Docker compose is no longer recommended for production use"},{"location":"gettingstarted/docker-swarm-rhel7/#install-docker-ce-and-swarm-rhel-77","text":"Warning: this method of installing docker on RHEL is not officially supported by RedHat. Consider using podman instead.","title":"Install Docker CE and Swarm (RHEL 7.7)"},{"location":"gettingstarted/docker-swarm-rhel7/#enable-required-repositories","text":"subscription-manager repos --enable = rhel-7-server-rpms subscription-manager repos --enable = rhel-7-server-extras-rpms subscription-manager repos --enable = rhel-7-server-optional-rpms yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo","title":"Enable required repositories"},{"location":"gettingstarted/docker-swarm-rhel7/#enable-epel","text":"yum install wget -y cd /tmp wget https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm rpm -Uvh epel-release-latest-7.noarch.rpm","title":"Enable EPEL"},{"location":"gettingstarted/docker-swarm-rhel7/#install-required-packages-and-enable-docker","text":"yum install docker-ce -y systemctl enable docker.service systemctl start docker.service","title":"Install required packages and enable docker"},{"location":"gettingstarted/docker-swarm-rhel7/#initialize-docker-swarm","text":"sudo docker swarm init","title":"Initialize Docker Swarm"},{"location":"gettingstarted/docker-swarm-rhel7/#sc4s-initial-configuration","text":"Create a directory on the server for local configurations and disk buffering. This should be available to all administrators, for example: /opt/sc4s/ Create a docker-compose.yml file in the directory created above, based on the template below: IMPORTANT: Always use the latest compose file (below) with the current release. By default, the latest container is automatically downloaded at each restart. Therefore, make it a habit to check back here regularly to be sure any changes that may have been made to the compose template file below (e.g. suggested mount points) are incoproprated in production prior to relaunching via compose. version : \"3.7\" services : sc4s : image : ghcr.io/splunk/splunk-connect-for-syslog/container:1 networks : - host env_file : - /opt/sc4s/env_file volumes : - /opt/sc4s/local:/etc/syslog-ng/conf.d/local:z - splunk-sc4s-var:/var/lib/syslog-ng # Uncomment the following line if local disk archiving is desired # - /opt/sc4s/archive:/var/lib/syslog-ng/archive:z # Map location of TLS custom TLS # - /opt/sc4s/tls:/etc/syslog-ng/tls:z volumes : splunk-sc4s-var : networks : host : name : host external : true Execute the following command to create a local volume that will contain the disk buffer files in the event of a communication failure to the upstream destination(s). This will also be used to keep track of the state of syslog-ng between restarts, and in particular the state of the disk buffer. This is a required step. sudo docker volume create splunk - sc4s - var NOTE: Be sure to account for disk space requirements for the docker volume created above. This volume is located in /var/lib/docker/volumes/ and could grow significantly if there is an extended outage to the SC4S destinations (typically HEC endpoints). See the \u201cSC4S Disk Buffer Configuration\u201d section on the Configruation page for more info. Create the subdirectory /opt/sc4s/local . This will be used as a mount point for local overrides and configurations. The empty local directory created above will populate with defaults and examples at the first invocation of SC4S for local configurations and context overrides. Do not change the directory structure of the files that are laid down; change (or add) only individual files if desired. SC4S depends on the directory layout to read the local configurations properly. See the notes below for which files will be preserved on restarts. In the local/config/ directory there are four subdirectories that allow you to provide support for device types that are not provided out of the box in SC4S. To get you started, there is an example log path template ( lp-example.conf.tmpl ) and a filter ( example.conf ) in the log_paths and filters subdirectories, respectively. These should not be used directly, but copied as templates for your own log path development. They will get overwritten at each SC4S start. In the local/context directory, if you change the \u201cnon-example\u201d version of a file (e.g. splunk_metadata.csv ) the changes will be preserved on a restart. Create the subdirectory /opt/sc4s/archive . This will be used as a mount point for local storage of syslog events (if the optional mount is uncommented above). The events will be written in the syslog-ng EWMM format. See the \u201cconfiguration\u201d document for details on the directory structure the archive uses. Create the subdirectory /opt/sc4s/tls . This will be used as a mount point for custom TLS certificates (if the optional mount is uncommented above). IMPORTANT: When creating the directories above, ensure the directories created match the volume mounts specified in the docker-compose.yml file. Failure to do this will cause SC4S to abort at startup.","title":"SC4S Initial Configuration"},{"location":"gettingstarted/docker-swarm-rhel7/#configure-the-sc4s-environment","text":"SC4S is almost entirely controlled through environment variables, which are read from a file at starteup. Create a file named /opt/sc4s/env_file and add the following environment variables and values: SC4S_DEST_SPLUNK_HEC_DEFAULT_URL = https : // splunk . smg . aws : 8088 SC4S_DEST_SPLUNK_HEC_DEFAULT_TOKEN = a778f63a - 5 dff - 4 e3c - a72c - a03183659e94 # Uncomment the following line if using untrusted SSL certificates # SC4S_DEST_SPLUNK_HEC_DEFAULT_TLS_VERIFY = no Update SC4S_DEST_SPLUNK_HEC_DEFAULT_URL and SC4S_DEST_SPLUNK_HEC_DEFAULT_TOKEN to reflect the correct values for your environment. Do not configure HEC Acknowledgement when deploying the HEC token on the Splunk side; the underlying syslog-ng http destination does not support this feature. Moreover, HEC Ack would significantly degrade performance for streaming data such as syslog. The default number of SC4S_DEST_SPLUNK_HEC_WORKERS is 10. Consult the community if you feel the number of workers (threads) should deviate from this. NOTE: Splunk Connect for Syslog defaults to secure configurations. If you are not using trusted SSL certificates, be sure to uncomment the last line in the example above.","title":"Configure the SC4S environment"},{"location":"gettingstarted/docker-swarm-rhel7/#dedicated-unique-listening-ports","text":"For certain source technologies, categorization by message content is impossible due to the lack of a unique \u201cfingerprint\u201d in the data. In other cases, a unique listening port is required for certain devices due to network requirements in the enterprise. For collection of such sources, we provide a means of dedicating a unique listening port to a specific source. Follow this step to configure unique ports for one or more sources: Modify the /opt/sc4s/env_file file to include the port-specific environment variable(s). Refer to the \u201cSources\u201d documentation to identify the specific environment variables that are mapped to each data source vendor/technology.","title":"Dedicated (Unique) Listening Ports"},{"location":"gettingstarted/docker-swarm-rhel7/#modify-index-destinations-for-splunk","text":"Log paths are preconfigured to utilize a convention of index destinations that are suitable for most customers. If changes need to be made to index destinations, navigate to the /opt/sc4s/local/context directory to start. Edit splunk_metadata.csv to review or change the index configuration as required for the data sources utilized in your environment. The key (1st column) in this file uses the syntax vendor_product . Simply replace the index value (the 3rd column) in the desired row with the index appropriate for your Splunk installation. The \u201cSources\u201d document details the specific vendor_product keys (rows) in this table that pertain to the individual data source filters that are included with SC4S. Other Splunk metadata (e.g. source and sourcetype) can be overriden via this file as well. This is an advanced topic, and further information is covered in the \u201cLog Path overrides\u201d section of the Configuration document.","title":"Modify index destinations for Splunk"},{"location":"gettingstarted/docker-swarm-rhel7/#configure-source-filtering-by-source-ip-or-host-name","text":"Legacy sources and non-standard-compliant sources require configuration by source IP or hostname as included in the event. The following steps apply to support such sources. To identify sources that require this step, refer to the \u201csources\u201d section of this documentation. If changes need to be made to source filtering, navigate to the /opt/sc4s/local/context directory to start. Navigate to vendor_product_by_source.conf and find the appropriate filter that matches your legacy device type. Edit the file to properly identify these products by hostname glob or network mask using syslog-ng filter syntax. Configuration by hostname or source IP is needed only for those devices that cannot be determined via normal syslog-ng parsing or message contents. The vendor_product_by_source.csv file should not need to be changed unless a local log path is created that is specific to the environment. In this case, a matching filter will also need to be provided in vendor_product_by_source.conf .","title":"Configure source filtering by source IP or host name"},{"location":"gettingstarted/docker-swarm-rhel7/#configure-compliance-indexmetadata-overrides","text":"In some cases, devices that have been properly sourcetyped need to be further categorized by compliance, geography, or other criterion. The two files compliance_meta_by_source.conf and compliance_meta_by_source.csv can be used for this purpose. These operate similarly to the files above, where the conf file specifies a filter to uniquely identify the messages that should be overridden, and the csv file lists one or more metadata items that can be overridden based on the filter name. This is an advanced topic, and further information is covered in the \u201cOverride index or metadata based on host, ip, or subnet\u201d section of the Configuration document.","title":"Configure compliance index/metadata overrides"},{"location":"gettingstarted/docker-swarm-rhel7/#startrestart-sc4s","text":"docker stack deploy --compose-file docker-compose.yml sc4s","title":"Start/Restart SC4S"},{"location":"gettingstarted/docker-swarm-rhel7/#stop-sc4s","text":"Start by obtaining the stack name (ID): docker stack ls Then, remove the stack: docker stack rm <ID>","title":"Stop SC4S"},{"location":"gettingstarted/docker-swarm-rhel7/#verify-proper-operation","text":"SC4S has a number of \u201cpreflight\u201d checks to ensure that the container starts properly and that the syntax of the underlying syslog-ng configuration is correct. After this step completes, to verify SC4S is properly communicating with Splunk, execute the following search in Splunk: index = * sourcetype=sc4s:events \"starting up\" This should yield an event similar to the following: syslog-ng starting up; version = '3.28.1' when the startup process proceeds normally (without syntax errors). If you do not see this, follow the steps below before proceeding to deeper-level troubleshooting: Check to see that the URL, token, and TLS/SSL settings are correct, and that the appropriate firewall ports are open (8088 or 443). Check to see that the proper indexes are created in Splunk, and that the token has access to them. Ensure the proper operation of the load balancer if used. Lastly, execute the following command to check the sc4s startup process running in the container. docker logs SC4S You should see events similar to those below in the output: syslog-ng checking config sc4s version = v1.36.0 starting goss starting syslog-ng If you do not see the output above, proceed to the \u201cTroubleshooting\u201d section for more detailed information.","title":"Verify Proper Operation"},{"location":"gettingstarted/docker-systemd-general/","text":"Install Docker CE \u00b6 Refer to relevant installation guides: CentOS Ubuntu Debian NOTE: If using a CentOS image provisioned in AWS, IPV4 forwarding is not enabled by default. This needs to be enabled for container networking to function properly. The following is an example to set this up; as usual this needs to be vetted with your enterprise security policy: sudo sysctl net.ipv4.ip_forward=1 Then, edit /etc/sysctl.conf, find the text below, and uncomment as shown so that the change made above will survive a reboot: # Uncomment the next line to enable packet forwarding for IPv4 net . ipv4 . ip_forward = 1 Initial Setup \u00b6 IMPORTANT: Always use the latest unit file (below) with the current release. By default, the latest container is automatically downloaded at each restart. Therefore, make it a habit to check back here regularly to be sure any changes that may have been made to the template unit file below (e.g. suggested mount points) are incoproprated in production prior to relaunching via systemd. Create the systemd unit file /lib/systemd/system/sc4s.service based on the following template: [Unit] Description = SC4S Container Wants = NetworkManager.service network-online.target docker.service After = NetworkManager.service network-online.target docker.service Requires = docker.service [Install] WantedBy = multi-user.target [Service] Environment = \"SC4S_IMAGE=ghcr.io/splunk/splunk-connect-for-syslog/container:1\" # Required mount point for syslog-ng persist data (including disk buffer) Environment = \"SC4S_PERSIST_MOUNT=splunk-sc4s-var:/var/lib/syslog-ng\" # Optional mount point for local overrides and configurations; see notes in docs Environment = \"SC4S_LOCAL_MOUNT=/opt/sc4s/local:/etc/syslog-ng/conf.d/local:z\" # Optional mount point for local disk archive (EWMM output) files Environment = \"SC4S_ARCHIVE_MOUNT=/opt/sc4s/archive:/var/lib/syslog-ng/archive:z\" # Map location of TLS custom TLS Environment = \"SC4S_TLS_MOUNT=/opt/sc4s/tls:/etc/syslog-ng/tls:z\" TimeoutStartSec = 0 ExecStartPre = /usr/bin/docker pull $SC4S_IMAGE ExecStartPre = /usr/bin/bash -c \"/usr/bin/systemctl set-environment SC4SHOST=$(hostname -s)\" ExecStart = /usr/bin/docker run \\ -e \"SC4S_CONTAINER_HOST = ${SC4SHOST}\" \\ -v \"$SC4S_PERSIST_MOUNT\" \\ -v \"$SC4S_LOCAL_MOUNT\" \\ -v \"$SC4S_ARCHIVE_MOUNT\" \\ -v \"$SC4S_TLS_MOUNT\" \\ --env-file = /opt/sc4s/env_file \\ --network host \\ --name SC4S \\ --rm $SC4S_IMAGE Restart = on-abnormal Execute the following command to create a local volume that will contain the disk buffer files in the event of a communication failure to the upstream destination(s). This will also be used to keep track of the state of syslog-ng between restarts, and in particular the state of the disk buffer. This is a required step. sudo docker volume create splunk - sc4s - var NOTE: Be sure to account for disk space requirements for the docker volume created above. This volume is located in /var/lib/docker/volumes/ and could grow significantly if there is an extended outage to the SC4S destinations (typically HEC endpoints). See the \u201cSC4S Disk Buffer Configuration\u201d section on the Configruation page for more info. Create the subdirectory /opt/sc4s/local . This will be used as a mount point for local overrides and configurations. The empty local directory created above will populate with defaults and examples at the first invocation of SC4S for local configurations and context overrides. Do not change the directory structure of the files that are laid down; change (or add) only individual files if desired. SC4S depends on the directory layout to read the local configurations properly. See the notes below for which files will be preserved on restarts. In the local/config/ directory there are four subdirectories that allow you to provide support for device types that are not provided out of the box in SC4S. To get you started, there is an example log path template ( lp-example.conf.tmpl ) and a filter ( example.conf ) in the log_paths and filters subdirectories, respectively. These should not be used directly, but copied as templates for your own log path development. They will get overwritten at each SC4S start. In the local/context directory, if you change the \u201cnon-example\u201d version of a file (e.g. splunk_metadata.csv ) the changes will be preserved on a restart. Create the subdirectory /opt/sc4s/archive . This will be used as a mount point for local storage of syslog events (if the optional mount is uncommented above). The events will be written in the syslog-ng EWMM format. See the \u201cconfiguration\u201d document for details on the directory structure the archive uses. Create the subdirectory /opt/sc4s/tls . This will be used as a mount point for custom TLS certificates (if the optional mount is uncommented above). IMPORTANT: When creating the directories above, ensure the directories created match the volume mounts specified in the unit file above. Failure to do this will cause SC4S to abort at startup. Configure the sc4s environment \u00b6 SC4S is almost entirely controlled through environment variables, which are read from a file at starteup. Create a file named /opt/sc4s/env_file and add the following environment variables and values: SC4S_DEST_SPLUNK_HEC_DEFAULT_URL = https : // splunk . smg . aws : 8088 SC4S_DEST_SPLUNK_HEC_DEFAULT_TOKEN = a778f63a - 5 dff - 4 e3c - a72c - a03183659e94 # Uncomment the following line if using untrusted SSL certificates # SC4S_DEST_SPLUNK_HEC_DEFAULT_TLS_VERIFY = no Update SC4S_DEST_SPLUNK_HEC_DEFAULT_URL and SC4S_DEST_SPLUNK_HEC_DEFAULT_TOKEN to reflect the correct values for your environment. Do not configure HEC Acknowledgement when deploying the HEC token on the Splunk side; the underlying syslog-ng http destination does not support this feature. Moreover, HEC Ack would significantly degrade performance for streaming data such as syslog. The default number of SC4S_DEST_SPLUNK_HEC_WORKERS is 10. Consult the community if you feel the number of workers (threads) should deviate from this. NOTE: Splunk Connect for Syslog defaults to secure configurations. If you are not using trusted SSL certificates, be sure to uncomment the last line in the example above. Dedicated (Unique) Listening Ports \u00b6 For certain source technologies, categorization by message content is impossible due to the lack of a unique \u201cfingerprint\u201d in the data. In other cases, a unique listening port is required for certain devices due to network requirements in the enterprise. For collection of such sources, we provide a means of dedicating a unique listening port to a specific source. Follow this step to configure unique ports for one or more sources: Modify the /opt/sc4s/env_file file to include the port-specific environment variable(s). Refer to the \u201cSources\u201d documentation to identify the specific environment variables that are mapped to each data source vendor/technology. Modify index destinations for Splunk \u00b6 Log paths are preconfigured to utilize a convention of index destinations that are suitable for most customers. If changes need to be made to index destinations, navigate to the /opt/sc4s/local/context directory to start. Edit splunk_metadata.csv to review or change the index configuration as required for the data sources utilized in your environment. The key (1st column) in this file uses the syntax vendor_product . Simply replace the index value (the 3rd column) in the desired row with the index appropriate for your Splunk installation. The \u201cSources\u201d document details the specific vendor_product keys (rows) in this table that pertain to the individual data source filters that are included with SC4S. Other Splunk metadata (e.g. source and sourcetype) can be overriden via this file as well. This is an advanced topic, and further information is covered in the \u201cLog Path overrides\u201d section of the Configuration document. Configure source filtering by source IP or host name \u00b6 Legacy sources and non-standard-compliant sources require configuration by source IP or hostname as included in the event. The following steps apply to support such sources. To identify sources that require this step, refer to the \u201csources\u201d section of this documentation. If changes need to be made to source filtering, navigate to the /opt/sc4s/local/context directory to start. Navigate to vendor_product_by_source.conf and find the appropriate filter that matches your legacy device type. Edit the file to properly identify these products by hostname glob or network mask using syslog-ng filter syntax. Configuration by hostname or source IP is needed only for those devices that cannot be determined via normal syslog-ng parsing or message contents. The vendor_product_by_source.csv file should not need to be changed unless a local log path is created that is specific to the environment. In this case, a matching filter will also need to be provided in vendor_product_by_source.conf . Configure compliance index/metadata overrides \u00b6 In some cases, devices that have been properly sourcetyped need to be further categorized by compliance, geography, or other criterion. The two files compliance_meta_by_source.conf and compliance_meta_by_source.csv can be used for this purpose. These operate similarly to the files above, where the conf file specifies a filter to uniquely identify the messages that should be overridden, and the csv file lists one or more metadata items that can be overridden based on the filter name. This is an advanced topic, and further information is covered in the \u201cOverride index or metadata based on host, ip, or subnet\u201d section of the Configuration document. Configure SC4S for systemd and start SC4S \u00b6 sudo systemctl daemon-reload sudo systemctl enable sc4s sudo systemctl start sc4s Start SC4S \u00b6 sudo systemctl start sc4s Restart SC4S \u00b6 sudo systemctl restart sc4s If changes were made to the configuration Unit file above (e.g. to configure with dedicated ports), you must first stop SC4S and re-run the systemd configuration commands: sudo systemctl stop sc4s sudo systemctl daemon-reload sudo systemctl enable sc4s sudo systemctl start sc4s Stop SC4S \u00b6 sudo systemctl stop sc4s Verify Proper Operation \u00b6 SC4S has a number of \u201cpreflight\u201d checks to ensure that the container starts properly and that the syntax of the underlying syslog-ng configuration is correct. After this step completes, to verify SC4S is properly communicating with Splunk, execute the following search in Splunk: index = * sourcetype=sc4s:events \"starting up\" This should yield an event similar to the following: syslog-ng starting up; version = '3.28.1' when the startup process proceeds normally (without syntax errors). If you do not see this, follow the steps below before proceeding to deeper-level troubleshooting: Check to see that the URL, token, and TLS/SSL settings are correct, and that the appropriate firewall ports are open (8088 or 443). Check to see that the proper indexes are created in Splunk, and that the token has access to them. Ensure the proper operation of the load balancer if used. Lastly, execute the following command to check the sc4s startup process running in the container. docker logs SC4S You should see events similar to those below in the output: syslog-ng checking config sc4s version = v1.36.0 starting goss starting syslog-ng If you do not see the output above, proceed to the \u201cTroubleshooting\u201d section for more detailed information.","title":"Docker CE + systemd"},{"location":"gettingstarted/docker-systemd-general/#install-docker-ce","text":"Refer to relevant installation guides: CentOS Ubuntu Debian NOTE: If using a CentOS image provisioned in AWS, IPV4 forwarding is not enabled by default. This needs to be enabled for container networking to function properly. The following is an example to set this up; as usual this needs to be vetted with your enterprise security policy: sudo sysctl net.ipv4.ip_forward=1 Then, edit /etc/sysctl.conf, find the text below, and uncomment as shown so that the change made above will survive a reboot: # Uncomment the next line to enable packet forwarding for IPv4 net . ipv4 . ip_forward = 1","title":"Install Docker CE"},{"location":"gettingstarted/docker-systemd-general/#initial-setup","text":"IMPORTANT: Always use the latest unit file (below) with the current release. By default, the latest container is automatically downloaded at each restart. Therefore, make it a habit to check back here regularly to be sure any changes that may have been made to the template unit file below (e.g. suggested mount points) are incoproprated in production prior to relaunching via systemd. Create the systemd unit file /lib/systemd/system/sc4s.service based on the following template: [Unit] Description = SC4S Container Wants = NetworkManager.service network-online.target docker.service After = NetworkManager.service network-online.target docker.service Requires = docker.service [Install] WantedBy = multi-user.target [Service] Environment = \"SC4S_IMAGE=ghcr.io/splunk/splunk-connect-for-syslog/container:1\" # Required mount point for syslog-ng persist data (including disk buffer) Environment = \"SC4S_PERSIST_MOUNT=splunk-sc4s-var:/var/lib/syslog-ng\" # Optional mount point for local overrides and configurations; see notes in docs Environment = \"SC4S_LOCAL_MOUNT=/opt/sc4s/local:/etc/syslog-ng/conf.d/local:z\" # Optional mount point for local disk archive (EWMM output) files Environment = \"SC4S_ARCHIVE_MOUNT=/opt/sc4s/archive:/var/lib/syslog-ng/archive:z\" # Map location of TLS custom TLS Environment = \"SC4S_TLS_MOUNT=/opt/sc4s/tls:/etc/syslog-ng/tls:z\" TimeoutStartSec = 0 ExecStartPre = /usr/bin/docker pull $SC4S_IMAGE ExecStartPre = /usr/bin/bash -c \"/usr/bin/systemctl set-environment SC4SHOST=$(hostname -s)\" ExecStart = /usr/bin/docker run \\ -e \"SC4S_CONTAINER_HOST = ${SC4SHOST}\" \\ -v \"$SC4S_PERSIST_MOUNT\" \\ -v \"$SC4S_LOCAL_MOUNT\" \\ -v \"$SC4S_ARCHIVE_MOUNT\" \\ -v \"$SC4S_TLS_MOUNT\" \\ --env-file = /opt/sc4s/env_file \\ --network host \\ --name SC4S \\ --rm $SC4S_IMAGE Restart = on-abnormal Execute the following command to create a local volume that will contain the disk buffer files in the event of a communication failure to the upstream destination(s). This will also be used to keep track of the state of syslog-ng between restarts, and in particular the state of the disk buffer. This is a required step. sudo docker volume create splunk - sc4s - var NOTE: Be sure to account for disk space requirements for the docker volume created above. This volume is located in /var/lib/docker/volumes/ and could grow significantly if there is an extended outage to the SC4S destinations (typically HEC endpoints). See the \u201cSC4S Disk Buffer Configuration\u201d section on the Configruation page for more info. Create the subdirectory /opt/sc4s/local . This will be used as a mount point for local overrides and configurations. The empty local directory created above will populate with defaults and examples at the first invocation of SC4S for local configurations and context overrides. Do not change the directory structure of the files that are laid down; change (or add) only individual files if desired. SC4S depends on the directory layout to read the local configurations properly. See the notes below for which files will be preserved on restarts. In the local/config/ directory there are four subdirectories that allow you to provide support for device types that are not provided out of the box in SC4S. To get you started, there is an example log path template ( lp-example.conf.tmpl ) and a filter ( example.conf ) in the log_paths and filters subdirectories, respectively. These should not be used directly, but copied as templates for your own log path development. They will get overwritten at each SC4S start. In the local/context directory, if you change the \u201cnon-example\u201d version of a file (e.g. splunk_metadata.csv ) the changes will be preserved on a restart. Create the subdirectory /opt/sc4s/archive . This will be used as a mount point for local storage of syslog events (if the optional mount is uncommented above). The events will be written in the syslog-ng EWMM format. See the \u201cconfiguration\u201d document for details on the directory structure the archive uses. Create the subdirectory /opt/sc4s/tls . This will be used as a mount point for custom TLS certificates (if the optional mount is uncommented above). IMPORTANT: When creating the directories above, ensure the directories created match the volume mounts specified in the unit file above. Failure to do this will cause SC4S to abort at startup.","title":"Initial Setup"},{"location":"gettingstarted/docker-systemd-general/#configure-the-sc4s-environment","text":"SC4S is almost entirely controlled through environment variables, which are read from a file at starteup. Create a file named /opt/sc4s/env_file and add the following environment variables and values: SC4S_DEST_SPLUNK_HEC_DEFAULT_URL = https : // splunk . smg . aws : 8088 SC4S_DEST_SPLUNK_HEC_DEFAULT_TOKEN = a778f63a - 5 dff - 4 e3c - a72c - a03183659e94 # Uncomment the following line if using untrusted SSL certificates # SC4S_DEST_SPLUNK_HEC_DEFAULT_TLS_VERIFY = no Update SC4S_DEST_SPLUNK_HEC_DEFAULT_URL and SC4S_DEST_SPLUNK_HEC_DEFAULT_TOKEN to reflect the correct values for your environment. Do not configure HEC Acknowledgement when deploying the HEC token on the Splunk side; the underlying syslog-ng http destination does not support this feature. Moreover, HEC Ack would significantly degrade performance for streaming data such as syslog. The default number of SC4S_DEST_SPLUNK_HEC_WORKERS is 10. Consult the community if you feel the number of workers (threads) should deviate from this. NOTE: Splunk Connect for Syslog defaults to secure configurations. If you are not using trusted SSL certificates, be sure to uncomment the last line in the example above.","title":"Configure the sc4s environment"},{"location":"gettingstarted/docker-systemd-general/#dedicated-unique-listening-ports","text":"For certain source technologies, categorization by message content is impossible due to the lack of a unique \u201cfingerprint\u201d in the data. In other cases, a unique listening port is required for certain devices due to network requirements in the enterprise. For collection of such sources, we provide a means of dedicating a unique listening port to a specific source. Follow this step to configure unique ports for one or more sources: Modify the /opt/sc4s/env_file file to include the port-specific environment variable(s). Refer to the \u201cSources\u201d documentation to identify the specific environment variables that are mapped to each data source vendor/technology.","title":"Dedicated (Unique) Listening Ports"},{"location":"gettingstarted/docker-systemd-general/#modify-index-destinations-for-splunk","text":"Log paths are preconfigured to utilize a convention of index destinations that are suitable for most customers. If changes need to be made to index destinations, navigate to the /opt/sc4s/local/context directory to start. Edit splunk_metadata.csv to review or change the index configuration as required for the data sources utilized in your environment. The key (1st column) in this file uses the syntax vendor_product . Simply replace the index value (the 3rd column) in the desired row with the index appropriate for your Splunk installation. The \u201cSources\u201d document details the specific vendor_product keys (rows) in this table that pertain to the individual data source filters that are included with SC4S. Other Splunk metadata (e.g. source and sourcetype) can be overriden via this file as well. This is an advanced topic, and further information is covered in the \u201cLog Path overrides\u201d section of the Configuration document.","title":"Modify index destinations for Splunk"},{"location":"gettingstarted/docker-systemd-general/#configure-source-filtering-by-source-ip-or-host-name","text":"Legacy sources and non-standard-compliant sources require configuration by source IP or hostname as included in the event. The following steps apply to support such sources. To identify sources that require this step, refer to the \u201csources\u201d section of this documentation. If changes need to be made to source filtering, navigate to the /opt/sc4s/local/context directory to start. Navigate to vendor_product_by_source.conf and find the appropriate filter that matches your legacy device type. Edit the file to properly identify these products by hostname glob or network mask using syslog-ng filter syntax. Configuration by hostname or source IP is needed only for those devices that cannot be determined via normal syslog-ng parsing or message contents. The vendor_product_by_source.csv file should not need to be changed unless a local log path is created that is specific to the environment. In this case, a matching filter will also need to be provided in vendor_product_by_source.conf .","title":"Configure source filtering by source IP or host name"},{"location":"gettingstarted/docker-systemd-general/#configure-compliance-indexmetadata-overrides","text":"In some cases, devices that have been properly sourcetyped need to be further categorized by compliance, geography, or other criterion. The two files compliance_meta_by_source.conf and compliance_meta_by_source.csv can be used for this purpose. These operate similarly to the files above, where the conf file specifies a filter to uniquely identify the messages that should be overridden, and the csv file lists one or more metadata items that can be overridden based on the filter name. This is an advanced topic, and further information is covered in the \u201cOverride index or metadata based on host, ip, or subnet\u201d section of the Configuration document.","title":"Configure compliance index/metadata overrides"},{"location":"gettingstarted/docker-systemd-general/#configure-sc4s-for-systemd-and-start-sc4s","text":"sudo systemctl daemon-reload sudo systemctl enable sc4s sudo systemctl start sc4s","title":"Configure SC4S for systemd and start SC4S"},{"location":"gettingstarted/docker-systemd-general/#start-sc4s","text":"sudo systemctl start sc4s","title":"Start SC4S"},{"location":"gettingstarted/docker-systemd-general/#restart-sc4s","text":"sudo systemctl restart sc4s If changes were made to the configuration Unit file above (e.g. to configure with dedicated ports), you must first stop SC4S and re-run the systemd configuration commands: sudo systemctl stop sc4s sudo systemctl daemon-reload sudo systemctl enable sc4s sudo systemctl start sc4s","title":"Restart SC4S"},{"location":"gettingstarted/docker-systemd-general/#stop-sc4s","text":"sudo systemctl stop sc4s","title":"Stop SC4S"},{"location":"gettingstarted/docker-systemd-general/#verify-proper-operation","text":"SC4S has a number of \u201cpreflight\u201d checks to ensure that the container starts properly and that the syntax of the underlying syslog-ng configuration is correct. After this step completes, to verify SC4S is properly communicating with Splunk, execute the following search in Splunk: index = * sourcetype=sc4s:events \"starting up\" This should yield an event similar to the following: syslog-ng starting up; version = '3.28.1' when the startup process proceeds normally (without syntax errors). If you do not see this, follow the steps below before proceeding to deeper-level troubleshooting: Check to see that the URL, token, and TLS/SSL settings are correct, and that the appropriate firewall ports are open (8088 or 443). Check to see that the proper indexes are created in Splunk, and that the token has access to them. Ensure the proper operation of the load balancer if used. Lastly, execute the following command to check the sc4s startup process running in the container. docker logs SC4S You should see events similar to those below in the output: syslog-ng checking config sc4s version = v1.36.0 starting goss starting syslog-ng If you do not see the output above, proceed to the \u201cTroubleshooting\u201d section for more detailed information.","title":"Verify Proper Operation"},{"location":"gettingstarted/k8s-microk8s/","text":"Install MicroK8s \u00b6 The SC4S deployment model with Microk8s uses specific features of this distribution of k8s. While this may be reproducable with other distributions such an undertaking requires more advanced awareness and responsibility for the administrator. (metalLB) ensure source IP is preserved Bring any operating system (window/centos/rhel/ubuntu/debian) This configuration requires as least 2 IP addressed one for host and one for the internal load balancer. We suggest allocation of 3 ip addresses for the host and 5-10 addresses for later use FAQ \u00b6 Question: How is this deployment model supported? Answer: Similar to other deployment methods, Splunk supports the container itself and the procedural guidance for implementation but does not directly support or otherwise provide resolutions for issues within the runtime environment. Question: Why is this \u201cload balancer\u201d ok but others are not? Answer: While we are using a load balancer with one instance per host, the traffic is restricted to the entry node and one instance of sc4s will run per node. This limits the function of MetalLB to the same function as a Cluster Manager. Question: Is this a recommended deployment model? Answer: Yes, the single-server microk8s model is a recommended option. The use of clustering does have additional tradeoffs and should be carefully considered on a deployment-specific basis. #we need to have a normal install of kubectl because of operator scripts sudo snap install kubectl --classic # Basic setup of k8s sudo usermod -a -G microk8s $USER sudo chown -f -R $USER ~/.kube su - $USER microk8s status --wait-ready #Note when installing metallb you will be prompted for one or more IPs to used as entry points #Into the cluster if your plan to enable clustering this IP should not be assigned to the host (floats) #If you do not plan to cluster then this IP may be the same IP as the host #Note2: a single IP in cidr format is x.x.x.x/32 use CIDR or range syntax microk8s enable dns metallb rbac storage openebs helm3 microk8s status --wait-ready # Add SC4S Helm repo \u00b6 microk8s helm3 repo add splunk-connect-for-syslog https://splunk.github.io/splunk-connect-for-syslog microk8s helm3 repo update Create a config file \u00b6 #values.yaml splunk : hec_url : \"https://10.202.32.101:8088/services/collector/event\" hec_token : \"00000000-0000-0000-0000-000000000000\" hec_verify_tls : \"yes\" Install SC4S \u00b6 microk8s helm3 install sc4s splunk-connect-for-syslog/splunk-connect-for-syslog -f values.yaml Upgrade SC4S \u00b6 microk8s helm3 upgrade sc4s splunk-connect-for-syslog/splunk-connect-for-syslog -f values.yaml Setup for HA with multiple nodes \u00b6 See https://microk8s.io/docs/high-availability Note: Three identically-sized nodes are required for HA #values.yaml replicaCount : 6 #2x node count splunk : hec_url : \"https://10.202.32.101:8088/services/collector/event\" hec_token : \"00000000-0000-0000-0000-000000000000\" hec_verify_tls : \"yes\" Upgrade sc4s to apply the new config Advanced Configuration \u00b6 Using helm based deployment precludes direct configuration of environment variables and context files but most configuration can be set via the values.yaml sc4s : # Certificate as a k8s Secret with tls.key and tls.crt fields # Ideally produced and managed by cert-manager.io existingCert : example-com-tls # vendor_product : - name : checkpoint ports : tcp : [ 9000 ] #Same as SC4S_LISTEN_CHECKPOINT_TCP_PORT=9000 udp : [ 9000 ] options : listen : old_host_rules : \"yes\" #Same as SC4S_LISTEN_CHECKPOINT_OLD_HOST_RULES=yes - name : infoblox ports : tcp : [ 9001 , 9002 ] tls : [ 9003 ] - name : fortinet ports : ietf_udp : - 9100 - 9101 context_files : splunk_metadata.csv : |- cisco_meraki,index,foo host.csv : |- 192.168.1.1,foo 192.168.1.2,moon Resource Management \u00b6 Generally two instances will be provisioned per node adjust requests and limits to allow each instance to use about 40% of each node presuming no other workload is present resources : limits : cpu : 100m memory : 128Mi requests : cpu : 100m memory : 128Mi","title":"MicroK8s + Linux"},{"location":"gettingstarted/k8s-microk8s/#install-microk8s","text":"The SC4S deployment model with Microk8s uses specific features of this distribution of k8s. While this may be reproducable with other distributions such an undertaking requires more advanced awareness and responsibility for the administrator. (metalLB) ensure source IP is preserved Bring any operating system (window/centos/rhel/ubuntu/debian) This configuration requires as least 2 IP addressed one for host and one for the internal load balancer. We suggest allocation of 3 ip addresses for the host and 5-10 addresses for later use","title":"Install MicroK8s"},{"location":"gettingstarted/k8s-microk8s/#faq","text":"Question: How is this deployment model supported? Answer: Similar to other deployment methods, Splunk supports the container itself and the procedural guidance for implementation but does not directly support or otherwise provide resolutions for issues within the runtime environment. Question: Why is this \u201cload balancer\u201d ok but others are not? Answer: While we are using a load balancer with one instance per host, the traffic is restricted to the entry node and one instance of sc4s will run per node. This limits the function of MetalLB to the same function as a Cluster Manager. Question: Is this a recommended deployment model? Answer: Yes, the single-server microk8s model is a recommended option. The use of clustering does have additional tradeoffs and should be carefully considered on a deployment-specific basis. #we need to have a normal install of kubectl because of operator scripts sudo snap install kubectl --classic # Basic setup of k8s sudo usermod -a -G microk8s $USER sudo chown -f -R $USER ~/.kube su - $USER microk8s status --wait-ready #Note when installing metallb you will be prompted for one or more IPs to used as entry points #Into the cluster if your plan to enable clustering this IP should not be assigned to the host (floats) #If you do not plan to cluster then this IP may be the same IP as the host #Note2: a single IP in cidr format is x.x.x.x/32 use CIDR or range syntax microk8s enable dns metallb rbac storage openebs helm3 microk8s status --wait-ready #","title":"FAQ"},{"location":"gettingstarted/k8s-microk8s/#add-sc4s-helm-repo","text":"microk8s helm3 repo add splunk-connect-for-syslog https://splunk.github.io/splunk-connect-for-syslog microk8s helm3 repo update","title":"Add SC4S Helm repo"},{"location":"gettingstarted/k8s-microk8s/#create-a-config-file","text":"#values.yaml splunk : hec_url : \"https://10.202.32.101:8088/services/collector/event\" hec_token : \"00000000-0000-0000-0000-000000000000\" hec_verify_tls : \"yes\"","title":"Create a config file"},{"location":"gettingstarted/k8s-microk8s/#install-sc4s","text":"microk8s helm3 install sc4s splunk-connect-for-syslog/splunk-connect-for-syslog -f values.yaml","title":"Install SC4S"},{"location":"gettingstarted/k8s-microk8s/#upgrade-sc4s","text":"microk8s helm3 upgrade sc4s splunk-connect-for-syslog/splunk-connect-for-syslog -f values.yaml","title":"Upgrade SC4S"},{"location":"gettingstarted/k8s-microk8s/#setup-for-ha-with-multiple-nodes","text":"See https://microk8s.io/docs/high-availability Note: Three identically-sized nodes are required for HA #values.yaml replicaCount : 6 #2x node count splunk : hec_url : \"https://10.202.32.101:8088/services/collector/event\" hec_token : \"00000000-0000-0000-0000-000000000000\" hec_verify_tls : \"yes\" Upgrade sc4s to apply the new config","title":"Setup for HA with multiple nodes"},{"location":"gettingstarted/k8s-microk8s/#advanced-configuration","text":"Using helm based deployment precludes direct configuration of environment variables and context files but most configuration can be set via the values.yaml sc4s : # Certificate as a k8s Secret with tls.key and tls.crt fields # Ideally produced and managed by cert-manager.io existingCert : example-com-tls # vendor_product : - name : checkpoint ports : tcp : [ 9000 ] #Same as SC4S_LISTEN_CHECKPOINT_TCP_PORT=9000 udp : [ 9000 ] options : listen : old_host_rules : \"yes\" #Same as SC4S_LISTEN_CHECKPOINT_OLD_HOST_RULES=yes - name : infoblox ports : tcp : [ 9001 , 9002 ] tls : [ 9003 ] - name : fortinet ports : ietf_udp : - 9100 - 9101 context_files : splunk_metadata.csv : |- cisco_meraki,index,foo host.csv : |- 192.168.1.1,foo 192.168.1.2,moon","title":"Advanced Configuration"},{"location":"gettingstarted/k8s-microk8s/#resource-management","text":"Generally two instances will be provisioned per node adjust requests and limits to allow each instance to use about 40% of each node presuming no other workload is present resources : limits : cpu : 100m memory : 128Mi requests : cpu : 100m memory : 128Mi","title":"Resource Management"},{"location":"gettingstarted/podman-systemd-general/","text":"Install podman \u00b6 Refer to Installation Initial Setup \u00b6 IMPORTANT: Always use the latest unit file (below) with the current release. By default, the latest container is automatically downloaded at each restart. Therefore, make it a habit to check back here regularly to be sure any changes that may have been made to the template unit file below (e.g. suggested mount points) are incoproprated in production prior to relaunching via systemd. Create the systemd unit file /lib/systemd/system/sc4s.service based on the following template: [Unit] Description = SC4S Container Wants = NetworkManager.service network-online.target After = NetworkManager.service network-online.target [Install] WantedBy = multi-user.target [Service] Environment = \"SC4S_IMAGE=ghcr.io/splunk/splunk-connect-for-syslog/container:1\" # Required mount point for syslog-ng persist data (including disk buffer) Environment = \"SC4S_PERSIST_MOUNT=splunk-sc4s-var:/var/lib/syslog-ng\" # Optional mount point for local overrides and configurations; see notes in docs Environment = \"SC4S_LOCAL_MOUNT=/opt/sc4s/local:/etc/syslog-ng/conf.d/local:z\" # Optional mount point for local disk archive (EWMM output) files Environment = \"SC4S_ARCHIVE_MOUNT=/opt/sc4s/archive:/var/lib/syslog-ng/archive:z\" # Map location of TLS custom TLS Environment = \"SC4S_TLS_MOUNT=/opt/sc4s/tls:/etc/syslog-ng/tls:z\" TimeoutStartSec = 0 ExecStartPre = /usr/bin/podman pull $SC4S_IMAGE ExecStartPre = /usr/bin/bash -c \"/usr/bin/systemctl set-environment SC4SHOST=$(hostname -s)\" ExecStart = /usr/bin/podman run \\ -e \"SC4S_CONTAINER_HOST = ${SC4SHOST}\" \\ -v \"$SC4S_PERSIST_MOUNT\" \\ -v \"$SC4S_LOCAL_MOUNT\" \\ -v \"$SC4S_ARCHIVE_MOUNT\" \\ -v \"$SC4S_TLS_MOUNT\" \\ --env-file = /opt/sc4s/env_file \\ --network host \\ --name SC4S \\ --rm $SC4S_IMAGE Restart = on-abnormal Execute the following command to create a local volume that will contain the disk buffer files in the event of a communication failure to the upstream destination(s). This will also be used to keep track of the state of syslog-ng between restarts, and in particular the state of the disk buffer. This is a required step. sudo podman volume create splunk - sc4s - var NOTE: Be sure to account for disk space requirements for the podman volume created above. This volume is located in /var/lib/containers/storage/volumes/ and could grow significantly if there is an extended outage to the SC4S destinations (typically HEC endpoints). See the \u201cSC4S Disk Buffer Configuration\u201d section on the Configruation page for more info. Create the subdirectory /opt/sc4s/local . This will be used as a mount point for local overrides and configurations. The empty local directory created above will populate with defaults and examples at the first invocation of SC4S for local configurations and context overrides. Do not change the directory structure of the files that are laid down; change (or add) only individual files if desired. SC4S depends on the directory layout to read the local configurations properly. See the notes below for which files will be preserved on restarts. In the local/config/ directory there are four subdirectories that allow you to provide support for device types that are not provided out of the box in SC4S. To get you started, there is an example log path template ( lp-example.conf.tmpl ) and a filter ( example.conf ) in the log_paths and filters subdirectories, respectively. These should not be used directly, but copied as templates for your own log path development. They will get overwritten at each SC4S start. In the local/context directory, if you change the \u201cnon-example\u201d version of a file (e.g. splunk_metadata.csv ) the changes will be preserved on a restart. Create the subdirectory /opt/sc4s/archive . This will be used as a mount point for local storage of syslog events (if the optional mount is uncommented above). The events will be written in the syslog-ng EWMM format. See the \u201cconfiguration\u201d document for details on the directory structure the archive uses. Create the subdirectory /opt/sc4s/tls . This will be used as a mount point for custom TLS certificates (if the optional mount is uncommented above). IMPORTANT: When creating the directories above, ensure the directories created match the volume mounts specified in the unit file above. Failure to do this will cause SC4S to abort at startup. Configure the sc4s environment \u00b6 SC4S is almost entirely controlled through environment variables, which are read from a file at starteup. Create a file named /opt/sc4s/env_file and add the following environment variables and values: SC4S_DEST_SPLUNK_HEC_DEFAULT_URL = https : // splunk . smg . aws : 8088 SC4S_DEST_SPLUNK_HEC_DEFAULT_TOKEN = a778f63a - 5 dff - 4 e3c - a72c - a03183659e94 # Uncomment the following line if using untrusted SSL certificates # SC4S_DEST_SPLUNK_HEC_DEFAULT_TLS_VERIFY = no Update SC4S_DEST_SPLUNK_HEC_DEFAULT_URL and SC4S_DEST_SPLUNK_HEC_DEFAULT_TOKEN to reflect the correct values for your environment. Do not configure HEC Acknowledgement when deploying the HEC token on the Splunk side; the underlying syslog-ng http destination does not support this feature. Moreover, HEC Ack would significantly degrade performance for streaming data such as syslog. The default number of SC4S_DEST_SPLUNK_HEC_WORKERS is 10. Consult the community if you feel the number of workers (threads) should deviate from this. NOTE: Splunk Connect for Syslog defaults to secure configurations. If you are not using trusted SSL certificates, be sure to uncomment the last line in the example above. Dedicated (Unique) Listening Ports \u00b6 For certain source technologies, categorization by message content is impossible due to the lack of a unique \u201cfingerprint\u201d in the data. In other cases, a unique listening port is required for certain devices due to network requirements in the enterprise. For collection of such sources, we provide a means of dedicating a unique listening port to a specific source. Follow this step to configure unique ports for one or more sources: Modify the /opt/sc4s/env_file file to include the port-specific environment variable(s). Refer to the \u201cSources\u201d documentation to identify the specific environment variables that are mapped to each data source vendor/technology. Modify index destinations for Splunk \u00b6 Log paths are preconfigured to utilize a convention of index destinations that are suitable for most customers. If changes need to be made to index destinations, navigate to the /opt/sc4s/local/context directory to start. Edit splunk_metadata.csv to review or change the index configuration as required for the data sources utilized in your environment. The key (1st column) in this file uses the syntax vendor_product . Simply replace the index value (the 3rd column) in the desired row with the index appropriate for your Splunk installation. The \u201cSources\u201d document details the specific vendor_product keys (rows) in this table that pertain to the individual data source filters that are included with SC4S. Other Splunk metadata (e.g. source and sourcetype) can be overriden via this file as well. This is an advanced topic, and further information is covered in the \u201cLog Path overrides\u201d section of the Configuration document. Configure source filtering by source IP or host name \u00b6 Legacy sources and non-standard-compliant sources require configuration by source IP or hostname as included in the event. The following steps apply to support such sources. To identify sources that require this step, refer to the \u201csources\u201d section of this documentation. If changes need to be made to source filtering, navigate to the /opt/sc4s/local/context directory to start. Navigate to vendor_product_by_source.conf and find the appropriate filter that matches your legacy device type. Edit the file to properly identify these products by hostname glob or network mask using syslog-ng filter syntax. Configuration by hostname or source IP is needed only for those devices that cannot be determined via normal syslog-ng parsing or message contents. The vendor_product_by_source.csv file should not need to be changed unless a local log path is created that is specific to the environment. In this case, a matching filter will also need to be provided in vendor_product_by_source.conf . Configure compliance index/metadata overrides \u00b6 In some cases, devices that have been properly sourcetyped need to be further categorized by compliance, geography, or other criterion. The two files compliance_meta_by_source.conf and compliance_meta_by_source.csv can be used for this purpose. These operate similarly to the files above, where the conf file specifies a filter to uniquely identify the messages that should be overridden, and the csv file lists one or more metadata items that can be overridden based on the filter name. This is an advanced topic, and further information is covered in the \u201cOverride index or metadata based on host, ip, or subnet\u201d section of the Configuration document. Configure SC4S for systemd and start SC4S \u00b6 sudo systemctl daemon-reload sudo systemctl enable sc4s sudo systemctl start sc4s Start SC4S \u00b6 sudo systemctl start sc4s Restart SC4S \u00b6 sudo systemctl restart sc4s If changes were made to the configuration Unit file above (e.g. to configure with dedicated ports), you must first stop SC4S and re-run the systemd configuration commands: sudo systemctl stop sc4s sudo systemctl daemon-reload sudo systemctl enable sc4s sudo systemctl start sc4s Stop SC4S \u00b6 sudo systemctl stop sc4s Verify Proper Operation \u00b6 SC4S has a number of \u201cpreflight\u201d checks to ensure that the container starts properly and that the syntax of the underlying syslog-ng configuration is correct. After this step completes, to verify SC4S is properly communicating with Splunk, execute the following search in Splunk: index = * sourcetype=sc4s:events \"starting up\" This should yield an event similar to the following: syslog-ng starting up; version = '3.28.1' when the startup process proceeds normally (without syntax errors). If you do not see this, follow the steps below before proceeding to deeper-level troubleshooting: Check to see that the URL, token, and TLS/SSL settings are correct, and that the appropriate firewall ports are open (8088 or 443). Check to see that the proper indexes are created in Splunk, and that the token has access to them. Ensure the proper operation of the load balancer if used. Lastly, execute the following command to check the sc4s startup process running in the container. podman logs SC4S You should see events similar to those below in the output: syslog-ng checking config sc4s version = v1.36.0 starting goss starting syslog-ng If you do not see the output above, proceed to the \u201cTroubleshooting\u201d section for more detailed information. SC4S non-root operation \u00b6 To operate SC4S as a user other than root, follow the instructions above, with these modifications: Prepare sc4s user \u00b6 Create a non-root user in which to run SC4S and prepare podman for non-root operation: sudo useradd -m -d /home/sc4s -s /bin/bash sc4s sudo su - sc4s mkdir -p /home/sc4s/local mkdir -p /home/sc4s/archive mkdir -p /home/sc4s/tls podman system migrate Initial Setup \u00b6 NOTE: Be sure to exectute all instructions below as the SC4S user created above with the exception of changes to the unit file, which requires sudo access. Make the following changes to the unit file(s) configured in the main section: Add the name of the user created above immediately after the Service declaration, as shown in the snippet below: [Service] User = sc4s Replace all references to /opt/sc4s in the \u201cEnvironment\u201d declarations with /home/sc4s . Make sure not to change the right-hand-side of the mount. For example: Environment=\"SC4S_LOCAL_CONFIG_MOUNT=-v /home/sc4s/local:/etc/syslog-ng/conf.d/local:z\" Replace all references to standard UDP/TCP outside listening ports (typically 514) on the left hand side only of the port pairs with arbirtrary high-numbered (> 1024) ports so that the container can listen without root privleges. The right hand side of the pairs (also typically 514) should remain unchanged: ExecStart=/usr/bin/podman run -p 2514:514 -p 2514:514/udp -p 6514:6514 If not done in the \u201cPrepare SC4S user\u201d above, create the three local mount directories as instructed in the main instructions, replacing the head of the directory /opt/sc4s with the sc4s service user\u2019s home directory as shown below: mkdir /home/sc4s/local mkdir /home/sc4s/archive mkdir /home/sc4s/tls Remaining Setup \u00b6 The remainder of the setup can be followed directly from the main setup instructions.","title":"Podman + systemd"},{"location":"gettingstarted/podman-systemd-general/#install-podman","text":"Refer to Installation","title":"Install podman"},{"location":"gettingstarted/podman-systemd-general/#initial-setup","text":"IMPORTANT: Always use the latest unit file (below) with the current release. By default, the latest container is automatically downloaded at each restart. Therefore, make it a habit to check back here regularly to be sure any changes that may have been made to the template unit file below (e.g. suggested mount points) are incoproprated in production prior to relaunching via systemd. Create the systemd unit file /lib/systemd/system/sc4s.service based on the following template: [Unit] Description = SC4S Container Wants = NetworkManager.service network-online.target After = NetworkManager.service network-online.target [Install] WantedBy = multi-user.target [Service] Environment = \"SC4S_IMAGE=ghcr.io/splunk/splunk-connect-for-syslog/container:1\" # Required mount point for syslog-ng persist data (including disk buffer) Environment = \"SC4S_PERSIST_MOUNT=splunk-sc4s-var:/var/lib/syslog-ng\" # Optional mount point for local overrides and configurations; see notes in docs Environment = \"SC4S_LOCAL_MOUNT=/opt/sc4s/local:/etc/syslog-ng/conf.d/local:z\" # Optional mount point for local disk archive (EWMM output) files Environment = \"SC4S_ARCHIVE_MOUNT=/opt/sc4s/archive:/var/lib/syslog-ng/archive:z\" # Map location of TLS custom TLS Environment = \"SC4S_TLS_MOUNT=/opt/sc4s/tls:/etc/syslog-ng/tls:z\" TimeoutStartSec = 0 ExecStartPre = /usr/bin/podman pull $SC4S_IMAGE ExecStartPre = /usr/bin/bash -c \"/usr/bin/systemctl set-environment SC4SHOST=$(hostname -s)\" ExecStart = /usr/bin/podman run \\ -e \"SC4S_CONTAINER_HOST = ${SC4SHOST}\" \\ -v \"$SC4S_PERSIST_MOUNT\" \\ -v \"$SC4S_LOCAL_MOUNT\" \\ -v \"$SC4S_ARCHIVE_MOUNT\" \\ -v \"$SC4S_TLS_MOUNT\" \\ --env-file = /opt/sc4s/env_file \\ --network host \\ --name SC4S \\ --rm $SC4S_IMAGE Restart = on-abnormal Execute the following command to create a local volume that will contain the disk buffer files in the event of a communication failure to the upstream destination(s). This will also be used to keep track of the state of syslog-ng between restarts, and in particular the state of the disk buffer. This is a required step. sudo podman volume create splunk - sc4s - var NOTE: Be sure to account for disk space requirements for the podman volume created above. This volume is located in /var/lib/containers/storage/volumes/ and could grow significantly if there is an extended outage to the SC4S destinations (typically HEC endpoints). See the \u201cSC4S Disk Buffer Configuration\u201d section on the Configruation page for more info. Create the subdirectory /opt/sc4s/local . This will be used as a mount point for local overrides and configurations. The empty local directory created above will populate with defaults and examples at the first invocation of SC4S for local configurations and context overrides. Do not change the directory structure of the files that are laid down; change (or add) only individual files if desired. SC4S depends on the directory layout to read the local configurations properly. See the notes below for which files will be preserved on restarts. In the local/config/ directory there are four subdirectories that allow you to provide support for device types that are not provided out of the box in SC4S. To get you started, there is an example log path template ( lp-example.conf.tmpl ) and a filter ( example.conf ) in the log_paths and filters subdirectories, respectively. These should not be used directly, but copied as templates for your own log path development. They will get overwritten at each SC4S start. In the local/context directory, if you change the \u201cnon-example\u201d version of a file (e.g. splunk_metadata.csv ) the changes will be preserved on a restart. Create the subdirectory /opt/sc4s/archive . This will be used as a mount point for local storage of syslog events (if the optional mount is uncommented above). The events will be written in the syslog-ng EWMM format. See the \u201cconfiguration\u201d document for details on the directory structure the archive uses. Create the subdirectory /opt/sc4s/tls . This will be used as a mount point for custom TLS certificates (if the optional mount is uncommented above). IMPORTANT: When creating the directories above, ensure the directories created match the volume mounts specified in the unit file above. Failure to do this will cause SC4S to abort at startup.","title":"Initial Setup"},{"location":"gettingstarted/podman-systemd-general/#configure-the-sc4s-environment","text":"SC4S is almost entirely controlled through environment variables, which are read from a file at starteup. Create a file named /opt/sc4s/env_file and add the following environment variables and values: SC4S_DEST_SPLUNK_HEC_DEFAULT_URL = https : // splunk . smg . aws : 8088 SC4S_DEST_SPLUNK_HEC_DEFAULT_TOKEN = a778f63a - 5 dff - 4 e3c - a72c - a03183659e94 # Uncomment the following line if using untrusted SSL certificates # SC4S_DEST_SPLUNK_HEC_DEFAULT_TLS_VERIFY = no Update SC4S_DEST_SPLUNK_HEC_DEFAULT_URL and SC4S_DEST_SPLUNK_HEC_DEFAULT_TOKEN to reflect the correct values for your environment. Do not configure HEC Acknowledgement when deploying the HEC token on the Splunk side; the underlying syslog-ng http destination does not support this feature. Moreover, HEC Ack would significantly degrade performance for streaming data such as syslog. The default number of SC4S_DEST_SPLUNK_HEC_WORKERS is 10. Consult the community if you feel the number of workers (threads) should deviate from this. NOTE: Splunk Connect for Syslog defaults to secure configurations. If you are not using trusted SSL certificates, be sure to uncomment the last line in the example above.","title":"Configure the sc4s environment"},{"location":"gettingstarted/podman-systemd-general/#dedicated-unique-listening-ports","text":"For certain source technologies, categorization by message content is impossible due to the lack of a unique \u201cfingerprint\u201d in the data. In other cases, a unique listening port is required for certain devices due to network requirements in the enterprise. For collection of such sources, we provide a means of dedicating a unique listening port to a specific source. Follow this step to configure unique ports for one or more sources: Modify the /opt/sc4s/env_file file to include the port-specific environment variable(s). Refer to the \u201cSources\u201d documentation to identify the specific environment variables that are mapped to each data source vendor/technology.","title":"Dedicated (Unique) Listening Ports"},{"location":"gettingstarted/podman-systemd-general/#modify-index-destinations-for-splunk","text":"Log paths are preconfigured to utilize a convention of index destinations that are suitable for most customers. If changes need to be made to index destinations, navigate to the /opt/sc4s/local/context directory to start. Edit splunk_metadata.csv to review or change the index configuration as required for the data sources utilized in your environment. The key (1st column) in this file uses the syntax vendor_product . Simply replace the index value (the 3rd column) in the desired row with the index appropriate for your Splunk installation. The \u201cSources\u201d document details the specific vendor_product keys (rows) in this table that pertain to the individual data source filters that are included with SC4S. Other Splunk metadata (e.g. source and sourcetype) can be overriden via this file as well. This is an advanced topic, and further information is covered in the \u201cLog Path overrides\u201d section of the Configuration document.","title":"Modify index destinations for Splunk"},{"location":"gettingstarted/podman-systemd-general/#configure-source-filtering-by-source-ip-or-host-name","text":"Legacy sources and non-standard-compliant sources require configuration by source IP or hostname as included in the event. The following steps apply to support such sources. To identify sources that require this step, refer to the \u201csources\u201d section of this documentation. If changes need to be made to source filtering, navigate to the /opt/sc4s/local/context directory to start. Navigate to vendor_product_by_source.conf and find the appropriate filter that matches your legacy device type. Edit the file to properly identify these products by hostname glob or network mask using syslog-ng filter syntax. Configuration by hostname or source IP is needed only for those devices that cannot be determined via normal syslog-ng parsing or message contents. The vendor_product_by_source.csv file should not need to be changed unless a local log path is created that is specific to the environment. In this case, a matching filter will also need to be provided in vendor_product_by_source.conf .","title":"Configure source filtering by source IP or host name"},{"location":"gettingstarted/podman-systemd-general/#configure-compliance-indexmetadata-overrides","text":"In some cases, devices that have been properly sourcetyped need to be further categorized by compliance, geography, or other criterion. The two files compliance_meta_by_source.conf and compliance_meta_by_source.csv can be used for this purpose. These operate similarly to the files above, where the conf file specifies a filter to uniquely identify the messages that should be overridden, and the csv file lists one or more metadata items that can be overridden based on the filter name. This is an advanced topic, and further information is covered in the \u201cOverride index or metadata based on host, ip, or subnet\u201d section of the Configuration document.","title":"Configure compliance index/metadata overrides"},{"location":"gettingstarted/podman-systemd-general/#configure-sc4s-for-systemd-and-start-sc4s","text":"sudo systemctl daemon-reload sudo systemctl enable sc4s sudo systemctl start sc4s","title":"Configure SC4S for systemd and start SC4S"},{"location":"gettingstarted/podman-systemd-general/#start-sc4s","text":"sudo systemctl start sc4s","title":"Start SC4S"},{"location":"gettingstarted/podman-systemd-general/#restart-sc4s","text":"sudo systemctl restart sc4s If changes were made to the configuration Unit file above (e.g. to configure with dedicated ports), you must first stop SC4S and re-run the systemd configuration commands: sudo systemctl stop sc4s sudo systemctl daemon-reload sudo systemctl enable sc4s sudo systemctl start sc4s","title":"Restart SC4S"},{"location":"gettingstarted/podman-systemd-general/#stop-sc4s","text":"sudo systemctl stop sc4s","title":"Stop SC4S"},{"location":"gettingstarted/podman-systemd-general/#verify-proper-operation","text":"SC4S has a number of \u201cpreflight\u201d checks to ensure that the container starts properly and that the syntax of the underlying syslog-ng configuration is correct. After this step completes, to verify SC4S is properly communicating with Splunk, execute the following search in Splunk: index = * sourcetype=sc4s:events \"starting up\" This should yield an event similar to the following: syslog-ng starting up; version = '3.28.1' when the startup process proceeds normally (without syntax errors). If you do not see this, follow the steps below before proceeding to deeper-level troubleshooting: Check to see that the URL, token, and TLS/SSL settings are correct, and that the appropriate firewall ports are open (8088 or 443). Check to see that the proper indexes are created in Splunk, and that the token has access to them. Ensure the proper operation of the load balancer if used. Lastly, execute the following command to check the sc4s startup process running in the container. podman logs SC4S You should see events similar to those below in the output: syslog-ng checking config sc4s version = v1.36.0 starting goss starting syslog-ng If you do not see the output above, proceed to the \u201cTroubleshooting\u201d section for more detailed information.","title":"Verify Proper Operation"},{"location":"gettingstarted/podman-systemd-general/#sc4s-non-root-operation","text":"To operate SC4S as a user other than root, follow the instructions above, with these modifications:","title":"SC4S non-root operation"},{"location":"gettingstarted/podman-systemd-general/#prepare-sc4s-user","text":"Create a non-root user in which to run SC4S and prepare podman for non-root operation: sudo useradd -m -d /home/sc4s -s /bin/bash sc4s sudo su - sc4s mkdir -p /home/sc4s/local mkdir -p /home/sc4s/archive mkdir -p /home/sc4s/tls podman system migrate","title":"Prepare sc4s user"},{"location":"gettingstarted/podman-systemd-general/#initial-setup_1","text":"NOTE: Be sure to exectute all instructions below as the SC4S user created above with the exception of changes to the unit file, which requires sudo access. Make the following changes to the unit file(s) configured in the main section: Add the name of the user created above immediately after the Service declaration, as shown in the snippet below: [Service] User = sc4s Replace all references to /opt/sc4s in the \u201cEnvironment\u201d declarations with /home/sc4s . Make sure not to change the right-hand-side of the mount. For example: Environment=\"SC4S_LOCAL_CONFIG_MOUNT=-v /home/sc4s/local:/etc/syslog-ng/conf.d/local:z\" Replace all references to standard UDP/TCP outside listening ports (typically 514) on the left hand side only of the port pairs with arbirtrary high-numbered (> 1024) ports so that the container can listen without root privleges. The right hand side of the pairs (also typically 514) should remain unchanged: ExecStart=/usr/bin/podman run -p 2514:514 -p 2514:514/udp -p 6514:6514 If not done in the \u201cPrepare SC4S user\u201d above, create the three local mount directories as instructed in the main instructions, replacing the head of the directory /opt/sc4s with the sc4s service user\u2019s home directory as shown below: mkdir /home/sc4s/local mkdir /home/sc4s/archive mkdir /home/sc4s/tls","title":"Initial Setup"},{"location":"gettingstarted/podman-systemd-general/#remaining-setup","text":"The remainder of the setup can be followed directly from the main setup instructions.","title":"Remaining Setup"},{"location":"gettingstarted/quickstart_guide/","text":"Quickstart Guide \u00b6 Splunk setup \u00b6 Create the following default indexes that are used by SC4S email epav netauth netdlp netdns netfw netids netops netwaf netproxy netipam oswinsec osnix em_metrics (Optional opt-in for SC4S operational metrics; ensure this is created as a metrics index) Create a HEC token for SC4S. When filling out the form for the token, it is recommended that the \u201cSelected Indexes\u201d pane be left blank and that a lastChanceIndex be created so that all data received by SC4S will land somewhere in Splunk. SC4S setup (using RHEL 7.6) \u00b6 Set the host OS kernel to match the default receive buffer of sc4s which is set to 16MB Add following to /etc/sysctl.conf net.core.rmem_default = 17039360 net.core.rmem_max = 17039360 Apply to the kernel sysctl -p Ensure the kernel is not dropping packets netstat -su | grep \"receive errors\" Create the systemd unit file /lib/systemd/system/sc4s.service . Copy and paste from the SC4S sample unit file . Install podman or docker bash sudo yum -y install podman or bash sudo yum install docker-engine -y Create a podman/docker local volume that will contain the disk buffer files and other SC4S state files (choose one in the command below) bash sudo podman|docker volume create splunk-sc4s-var Create directories used as a mount point for local overrides and configurations bash mkdir /opt/sc4s/local mkdir /opt/sc4s/archive mkdir /opt/sc4s/tls Create the environment file /opt/sc4s/env_file and replace the HEC_URL and HEC_TOKEN as appropriate ```bash SC4S_DEST_SPLUNK_HEC_DEFAULT_URL= SC4S_DEST_SPLUNK_HEC_DEFAULT_TOKEN= Uncomment the following line if using untrusted SSL certificates \u00b6 SC4S_DEST_SPLUNK_HEC_DEFAULT_TLS_VERIFY=no \u00b6 ``` Configure SC4S for systemd and start SC4S bash sudo systemctl daemon-reload sudo systemctl enable sc4s sudo systemctl start sc4s Check podman/docker logs for errors (choose one in command below) bash sudo podman|docker logs SC4S Search on Splunk for successful installation of SC4S index=* sourcetype=sc4s:events \"starting up\" Send sample data to default udp port 514 of SC4S host bash echo \u201cHello SC4S\u201d > /dev/udp/<SC4S_ip>/514","title":"Quickstart Guide"},{"location":"gettingstarted/quickstart_guide/#quickstart-guide","text":"","title":"Quickstart Guide"},{"location":"gettingstarted/quickstart_guide/#splunk-setup","text":"Create the following default indexes that are used by SC4S email epav netauth netdlp netdns netfw netids netops netwaf netproxy netipam oswinsec osnix em_metrics (Optional opt-in for SC4S operational metrics; ensure this is created as a metrics index) Create a HEC token for SC4S. When filling out the form for the token, it is recommended that the \u201cSelected Indexes\u201d pane be left blank and that a lastChanceIndex be created so that all data received by SC4S will land somewhere in Splunk.","title":"Splunk setup"},{"location":"gettingstarted/quickstart_guide/#sc4s-setup-using-rhel-76","text":"Set the host OS kernel to match the default receive buffer of sc4s which is set to 16MB Add following to /etc/sysctl.conf net.core.rmem_default = 17039360 net.core.rmem_max = 17039360 Apply to the kernel sysctl -p Ensure the kernel is not dropping packets netstat -su | grep \"receive errors\" Create the systemd unit file /lib/systemd/system/sc4s.service . Copy and paste from the SC4S sample unit file . Install podman or docker bash sudo yum -y install podman or bash sudo yum install docker-engine -y Create a podman/docker local volume that will contain the disk buffer files and other SC4S state files (choose one in the command below) bash sudo podman|docker volume create splunk-sc4s-var Create directories used as a mount point for local overrides and configurations bash mkdir /opt/sc4s/local mkdir /opt/sc4s/archive mkdir /opt/sc4s/tls Create the environment file /opt/sc4s/env_file and replace the HEC_URL and HEC_TOKEN as appropriate ```bash SC4S_DEST_SPLUNK_HEC_DEFAULT_URL= SC4S_DEST_SPLUNK_HEC_DEFAULT_TOKEN=","title":"SC4S setup (using RHEL 7.6)"},{"location":"gettingstarted/quickstart_guide/#uncomment-the-following-line-if-using-untrusted-ssl-certificates","text":"","title":"Uncomment the following line if using untrusted SSL certificates"},{"location":"gettingstarted/quickstart_guide/#sc4s_dest_splunk_hec_default_tls_verifyno","text":"``` Configure SC4S for systemd and start SC4S bash sudo systemctl daemon-reload sudo systemctl enable sc4s sudo systemctl start sc4s Check podman/docker logs for errors (choose one in command below) bash sudo podman|docker logs SC4S Search on Splunk for successful installation of SC4S index=* sourcetype=sc4s:events \"starting up\" Send sample data to default udp port 514 of SC4S host bash echo \u201cHello SC4S\u201d > /dev/udp/<SC4S_ip>/514","title":"SC4S_DEST_SPLUNK_HEC_DEFAULT_TLS_VERIFY=no"},{"location":"sources/","text":"Introduction \u00b6 When using Splunk Connect for Syslog to onboard a data source, the SC4S filter (or \u201clog path\u201d) performs the operations that are traditionally performed at index-time by the corresponding Technical Add-on installed there. These index-time operations include linebreaking, sourcetype setting and timestamping. For this reason, if a data source is exclusively onboarded using SC4S then you will not need to install its corresponding Add-On on the indexers. You must, however, install the Add-on on the search head(s) for the user communities interested in this data source. SC4S \u201cunique\u201d filters are based either on the port upon which events arrive or the hostname/CIDR block from which they are sent. The \u201csoup\u201d filters run for events that arrive on port 514 (default for syslog), and contain regex and other syslog-specific parsers to identify events from a specific source, apply the correct sourcetype, and set other metadata. Data sources which generate events that are not unique enough to accurately identify with soup filters must employ the \u201cunique\u201d filters (port/hostname/CIDR block) instead \u2013 the soup filters are unavailable for these sources. The SC4S \u201cfallback\u201d sourcetype \u00b6 If SC4S receives an event on port 514 which has no soup filter, that event will be given a \u201cfallback\u201d sourcetype. If you see events in Splunk with the fallback sourcetype, then you should figure out what source the events are from and determine why these events are not being sourcetyped correctly. The most common reason for events categorized as \u201cfallback\u201d is the lack of a SC4S filter for that source, and in some cases a misconfigured relay which alters the integrity of the message format. In most cases this means a new SC4S filter must be developed. In this situation you can either build a filter or file an issue with the community to request help. The \u201cfallback\u201d sourcetype is formatted in JSON to allow the administrator to see the constituent syslog-ng \u201cmacros\u201d (fields) that have been autmaticially parsed by the syslog-ng server An RFC3164 (legacy BSD syslog) \u201con the wire\u201d raw message is usually (but unfortunately not always) comprised of the following syslog-ng macros, in this order and spacing: <$PRI> $HOST $LEGACY_MSGHDR$MESSAGE These fields can be very useful in building a new filter for that sourcetype. In addition, the indexed field sc4s_syslog_format is helpful in determining if the incoming message is standard RFC3164. A value of anything other than rfc3164 or rfc5424_strict indicates a vendor purturbation of standard syslog, which will warrant more careful examination when building a filter. Splunk Connect for Syslog and Splunk metadata \u00b6 A key aspect of SC4S is to properly set Splunk metadata prior to the data arriving in Splunk (and before any TA processing takes place. The filters will apply the proper index, source, sourcetype, host, and timestamp metadata automatically by individual data source. Proper values for this metadata (including a recommended index) are included with all \u201cout-of-the-box\u201d log paths included with SC4S and are chosen to properly interface with the corresponding TA in Splunk. The administrator will need to ensure all recommneded indexes be created to accept this data if the defaults are not changed. It is understood that default values will need to be changed in many installations. Each source documented in this section has a table entitled \u201cSourcetype and Index Configuration\u201d, which highlights the default index and sourcetype for each source. See the section \u201cSC4S metadata configuration\u201d in the \u201cConfiguration\u201d page for more information on how to override the default values in this table. Unique listening ports \u00b6 SC4S supports unique listening ports for each source technology/log path (e.g. Cisco ASA), which is useful when the device is sending data on a port different from the typical default syslog port (UDP port 514). In some cases, when the source device emits data that is not able to be distinguished from other device types, a unique port is sometimes required. The specific environment variables used for setting \u201cunique ports\u201d are outlined in each source document in this section. In most cases only one \u201cunique port\u201d is needed for each source. However, SC4S also supports multiple network listening ports per source, which can be useful for a narrow set of compliance use cases. When configuring a source port variable to enable multiple ports, use a comma-separated list with no spaces (e.g. SC4S_LISTEN_CISCO_ASA_UDP_PORT=5005,6005 ).","title":"About"},{"location":"sources/#introduction","text":"When using Splunk Connect for Syslog to onboard a data source, the SC4S filter (or \u201clog path\u201d) performs the operations that are traditionally performed at index-time by the corresponding Technical Add-on installed there. These index-time operations include linebreaking, sourcetype setting and timestamping. For this reason, if a data source is exclusively onboarded using SC4S then you will not need to install its corresponding Add-On on the indexers. You must, however, install the Add-on on the search head(s) for the user communities interested in this data source. SC4S \u201cunique\u201d filters are based either on the port upon which events arrive or the hostname/CIDR block from which they are sent. The \u201csoup\u201d filters run for events that arrive on port 514 (default for syslog), and contain regex and other syslog-specific parsers to identify events from a specific source, apply the correct sourcetype, and set other metadata. Data sources which generate events that are not unique enough to accurately identify with soup filters must employ the \u201cunique\u201d filters (port/hostname/CIDR block) instead \u2013 the soup filters are unavailable for these sources.","title":"Introduction"},{"location":"sources/#the-sc4s-fallback-sourcetype","text":"If SC4S receives an event on port 514 which has no soup filter, that event will be given a \u201cfallback\u201d sourcetype. If you see events in Splunk with the fallback sourcetype, then you should figure out what source the events are from and determine why these events are not being sourcetyped correctly. The most common reason for events categorized as \u201cfallback\u201d is the lack of a SC4S filter for that source, and in some cases a misconfigured relay which alters the integrity of the message format. In most cases this means a new SC4S filter must be developed. In this situation you can either build a filter or file an issue with the community to request help. The \u201cfallback\u201d sourcetype is formatted in JSON to allow the administrator to see the constituent syslog-ng \u201cmacros\u201d (fields) that have been autmaticially parsed by the syslog-ng server An RFC3164 (legacy BSD syslog) \u201con the wire\u201d raw message is usually (but unfortunately not always) comprised of the following syslog-ng macros, in this order and spacing: <$PRI> $HOST $LEGACY_MSGHDR$MESSAGE These fields can be very useful in building a new filter for that sourcetype. In addition, the indexed field sc4s_syslog_format is helpful in determining if the incoming message is standard RFC3164. A value of anything other than rfc3164 or rfc5424_strict indicates a vendor purturbation of standard syslog, which will warrant more careful examination when building a filter.","title":"The SC4S \"fallback\" sourcetype"},{"location":"sources/#splunk-connect-for-syslog-and-splunk-metadata","text":"A key aspect of SC4S is to properly set Splunk metadata prior to the data arriving in Splunk (and before any TA processing takes place. The filters will apply the proper index, source, sourcetype, host, and timestamp metadata automatically by individual data source. Proper values for this metadata (including a recommended index) are included with all \u201cout-of-the-box\u201d log paths included with SC4S and are chosen to properly interface with the corresponding TA in Splunk. The administrator will need to ensure all recommneded indexes be created to accept this data if the defaults are not changed. It is understood that default values will need to be changed in many installations. Each source documented in this section has a table entitled \u201cSourcetype and Index Configuration\u201d, which highlights the default index and sourcetype for each source. See the section \u201cSC4S metadata configuration\u201d in the \u201cConfiguration\u201d page for more information on how to override the default values in this table.","title":"Splunk Connect for Syslog and Splunk metadata"},{"location":"sources/#unique-listening-ports","text":"SC4S supports unique listening ports for each source technology/log path (e.g. Cisco ASA), which is useful when the device is sending data on a port different from the typical default syslog port (UDP port 514). In some cases, when the source device emits data that is not able to be distinguished from other device types, a unique port is sometimes required. The specific environment variables used for setting \u201cunique ports\u201d are outlined in each source document in this section. In most cases only one \u201cunique port\u201d is needed for each source. However, SC4S also supports multiple network listening ports per source, which can be useful for a narrow set of compliance use cases. When configuring a source port variable to enable multiple ports, use a comma-separated list with no spaces (e.g. SC4S_LISTEN_CISCO_ASA_UDP_PORT=5005,6005 ).","title":"Unique listening ports"},{"location":"sources/Alcatel/","text":"Vendor - Alcatel \u00b6 Product - Switches \u00b6 Ref Link Splunk Add-on None Product Manual unknown Sourcetypes \u00b6 sourcetype notes alcatel:switch None Sourcetype and Index Configuration \u00b6 key sourcetype index notes alcatel_switch alcatel:switch netops none Filter type \u00b6 MSG Parsing Setup and Configuration \u00b6 Device setup unknown Options \u00b6 Variable default description SC4S_LISTEN_ALCATEL_SWITCH_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_ALCATEL_SWITCH_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_ALCATEL_SWITCH no Enable archive to disk for this specific source SC4S_DEST_ALCATEL_SWITCH_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 An active device will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=alcatel:switch | stats count by host","title":"Alcatel"},{"location":"sources/Alcatel/#vendor-alcatel","text":"","title":"Vendor - Alcatel"},{"location":"sources/Alcatel/#product-switches","text":"Ref Link Splunk Add-on None Product Manual unknown","title":"Product - Switches"},{"location":"sources/Alcatel/#sourcetypes","text":"sourcetype notes alcatel:switch None","title":"Sourcetypes"},{"location":"sources/Alcatel/#sourcetype-and-index-configuration","text":"key sourcetype index notes alcatel_switch alcatel:switch netops none","title":"Sourcetype and Index Configuration"},{"location":"sources/Alcatel/#filter-type","text":"MSG Parsing","title":"Filter type"},{"location":"sources/Alcatel/#setup-and-configuration","text":"Device setup unknown","title":"Setup and Configuration"},{"location":"sources/Alcatel/#options","text":"Variable default description SC4S_LISTEN_ALCATEL_SWITCH_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_ALCATEL_SWITCH_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_ALCATEL_SWITCH no Enable archive to disk for this specific source SC4S_DEST_ALCATEL_SWITCH_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/Alcatel/#verification","text":"An active device will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=alcatel:switch | stats count by host","title":"Verification"},{"location":"sources/Alsid/","text":"Vendor - Alsid \u00b6 Product - Switches \u00b6 Ref Link Splunk Add-on https://splunkbase.splunk.com/app/5173/ Product Manual unknown Sourcetypes \u00b6 sourcetype notes alsid:syslog None Sourcetype and Index Configuration \u00b6 key sourcetype index notes alsid_syslog alsid:syslog oswinsec none Filter type \u00b6 MSG Parsing Setup and Configuration \u00b6 Device setup unknown Options \u00b6 Variable default description SC4S_LISTEN_ALSID_SYSLOG_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_ALSID_SYSLOG_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_ALSID_SYSLOG no Enable archive to disk for this specific source SC4S_DEST_ALSID_SYSLOG_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 An active device will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=alsid:syslog | stats count by host","title":"Alsid"},{"location":"sources/Alsid/#vendor-alsid","text":"","title":"Vendor - Alsid"},{"location":"sources/Alsid/#product-switches","text":"Ref Link Splunk Add-on https://splunkbase.splunk.com/app/5173/ Product Manual unknown","title":"Product - Switches"},{"location":"sources/Alsid/#sourcetypes","text":"sourcetype notes alsid:syslog None","title":"Sourcetypes"},{"location":"sources/Alsid/#sourcetype-and-index-configuration","text":"key sourcetype index notes alsid_syslog alsid:syslog oswinsec none","title":"Sourcetype and Index Configuration"},{"location":"sources/Alsid/#filter-type","text":"MSG Parsing","title":"Filter type"},{"location":"sources/Alsid/#setup-and-configuration","text":"Device setup unknown","title":"Setup and Configuration"},{"location":"sources/Alsid/#options","text":"Variable default description SC4S_LISTEN_ALSID_SYSLOG_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_ALSID_SYSLOG_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_ALSID_SYSLOG no Enable archive to disk for this specific source SC4S_DEST_ALSID_SYSLOG_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/Alsid/#verification","text":"An active device will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=alsid:syslog | stats count by host","title":"Verification"},{"location":"sources/Avaya/","text":"Vendor - Avaya \u00b6 Product - Avaya Sip Manager \u00b6 Ref Link Splunk Add-on None Product Manual unknown Sourcetypes \u00b6 sourcetype notes avaya:avaya None Sourcetype and Index Configuration \u00b6 key sourcetype index notes avaya_sipmgr avaya:avaya main none Filter type \u00b6 This filter uses msg parsgin. Setup and Configuration \u00b6 The source device send non compliant syslog format (legacy bsd based) with embeded new line and no IETF frames this source must be configured to use UDP protocol. Options \u00b6 Variable default description SC4S_LISTEN_AVAYA_SIPMGR_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers Verification \u00b6 An active device will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=avaya:sipmgr| stats count by host","title":"Avaya"},{"location":"sources/Avaya/#vendor-avaya","text":"","title":"Vendor - Avaya"},{"location":"sources/Avaya/#product-avaya-sip-manager","text":"Ref Link Splunk Add-on None Product Manual unknown","title":"Product - Avaya Sip Manager"},{"location":"sources/Avaya/#sourcetypes","text":"sourcetype notes avaya:avaya None","title":"Sourcetypes"},{"location":"sources/Avaya/#sourcetype-and-index-configuration","text":"key sourcetype index notes avaya_sipmgr avaya:avaya main none","title":"Sourcetype and Index Configuration"},{"location":"sources/Avaya/#filter-type","text":"This filter uses msg parsgin.","title":"Filter type"},{"location":"sources/Avaya/#setup-and-configuration","text":"The source device send non compliant syslog format (legacy bsd based) with embeded new line and no IETF frames this source must be configured to use UDP protocol.","title":"Setup and Configuration"},{"location":"sources/Avaya/#options","text":"Variable default description SC4S_LISTEN_AVAYA_SIPMGR_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers","title":"Options"},{"location":"sources/Avaya/#verification","text":"An active device will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=avaya:sipmgr| stats count by host","title":"Verification"},{"location":"sources/Avi_Networks/","text":"Vendor - Avi Networks \u00b6 Product - Switches \u00b6 Ref Link Splunk Add-on None Product Manual https://avinetworks.com/docs/latest/syslog-formats/ Sourcetypes \u00b6 sourcetype notes avi:events None Sourcetype and Index Configuration \u00b6 key sourcetype index notes avi_vantage avi:events netops none Filter type \u00b6 Must be identified by host or ip assignment. Update the filter f_brocade_syslog or configure a dedicated port as required Setup and Configuration \u00b6 Device setup unknown Options \u00b6 Variable default description SC4S_LISTEN_AVI_VANTAGE_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_AVI_VANTAGE_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_AVI_VANTAGE no Enable archive to disk for this specific source SC4S_DEST_AVI_VANTAGE_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 An active device will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=avi:events| stats count by host","title":"Avi Networks"},{"location":"sources/Avi_Networks/#vendor-avi-networks","text":"","title":"Vendor - Avi Networks"},{"location":"sources/Avi_Networks/#product-switches","text":"Ref Link Splunk Add-on None Product Manual https://avinetworks.com/docs/latest/syslog-formats/","title":"Product - Switches"},{"location":"sources/Avi_Networks/#sourcetypes","text":"sourcetype notes avi:events None","title":"Sourcetypes"},{"location":"sources/Avi_Networks/#sourcetype-and-index-configuration","text":"key sourcetype index notes avi_vantage avi:events netops none","title":"Sourcetype and Index Configuration"},{"location":"sources/Avi_Networks/#filter-type","text":"Must be identified by host or ip assignment. Update the filter f_brocade_syslog or configure a dedicated port as required","title":"Filter type"},{"location":"sources/Avi_Networks/#setup-and-configuration","text":"Device setup unknown","title":"Setup and Configuration"},{"location":"sources/Avi_Networks/#options","text":"Variable default description SC4S_LISTEN_AVI_VANTAGE_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_AVI_VANTAGE_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_AVI_VANTAGE no Enable archive to disk for this specific source SC4S_DEST_AVI_VANTAGE_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/Avi_Networks/#verification","text":"An active device will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=avi:events| stats count by host","title":"Verification"},{"location":"sources/Broadcom/","text":"Vendor - Broadcom \u00b6 Broadcom products are inclusive of products formerly marketed under Symantec and Bluecoat brands. Product - SSL Visibility Appliance \u00b6 Ref Link Splunk Add-on None Product Manual https://knowledge.broadcom.com/external/article/168879/when-sending-session-logs-from-ssl-visib.html Sourcetypes \u00b6 sourcetype notes broadcom:sslva none Product - Symantec Endpoint Protection \u00b6 Ref Link Splunk Add-on https://splunkbase.splunk.com/app/2772/ Product Manual https://techdocs.broadcom.com/content/broadcom/techdocs/us/en/symantec-security-software/endpoint-security-and-management/endpoint-protection/all/Monitoring-Reporting-and-Enforcing-Compliance/viewing-logs-v7522439-d37e464/exporting-data-to-a-syslog-server-v8442743-d15e1107.html Index Configuration \u00b6 key index notes broadcom_sslva netproxy none Filter type \u00b6 MSG Parse: This filter parses message content Options \u00b6 Variable default description SC4S_LISTEN_SYMANTEC_EP_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_SYMANTEC_EP_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_SYMANTEC_EP no Enable archive to disk for this specific source SC4S_DEST_SYMANTEC_EP_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 An active server will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=symantec:ep:*:syslog | stats count by host Sourcetypes \u00b6 sourcetype notes symantec:ep:syslog Warning the syslog method of accepting EP logs has been reported to show high data loss and is not Supported by Splunk symantec:ep:admin:syslog none symantec:ep:agent:syslog none symantec:ep:agt:system:syslog none symantec:ep:behavior:syslog none symantec:ep:packet:syslog none symantec:ep:policy:syslog none symantec:ep:proactive:syslog none symantec:ep:risk:syslog none symantec:ep:scan:syslog none symantec:ep:scm:system:syslog none symantec:ep:security:syslog none symantec:ep:traffic:syslog none Index Configuration \u00b6 key index notes symantec_ep epav none Filter type \u00b6 MSG Parse: This filter parses message content Options \u00b6 Variable default description SC4S_LISTEN_SYMANTEC_EP_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_SYMANTEC_EP_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_SYMANTEC_EP no Enable archive to disk for this specific source SC4S_DEST_SYMANTEC_EP_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 An active server will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=symantec:ep:*:syslog | stats count by host Product - ProxySG/ASG (Bluecoat) \u00b6 Ref Link Splunk Add-on https://splunkbase.splunk.com/app/2758/ Product Manual https://support.symantec.com/us/en/article.tech242216.html Sourcetypes \u00b6 sourcetype notes bluecoat:proxysg:access:kv Requires version TA 3.6 Sourcetype and Index Configuration \u00b6 key sourcetype index notes bluecoat_proxy bluecoat:proxysg:access:kv netops none Filter type \u00b6 MSG Parse: This filter parses message content Setup and Configuration \u00b6 Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used the addon is not required on the indexer. Review and update the splunk_metadata.csv file and set the index and sourcetype as required for the data source. Refer to the Splunk TA documentation for the specific customer format required for proxy configuration Select TCP or SSL transport option Ensure the format of the event is customized as follows < 111 > 1 $ ( date ) T $ ( x - bluecoat - hour - utc ) :$ ( x - bluecoat - minute - utc ) :$ ( x - bluecoat - second - utc ) $ ( s - computername ) bluecoat - splunk_format - c - ip = $ ( c - ip ) rs - Content - Type = $ ( quot ) $ ( rs ( Content - Type )) $ ( quot ) cs - auth - groups = $ ( cs - auth - groups ) cs - bytes = $ ( cs - bytes ) cs - categories = $ ( cs - categories ) cs - host = $ ( cs - host ) cs - ip = $ ( cs - ip ) cs - method = $ ( cs - method ) cs - uri - port = $ ( cs - uri - port ) cs - uri - scheme = $ ( cs - uri - scheme ) cs - User - Agent = $ ( quot ) $ ( cs ( User - Agent )) $ ( quot ) cs - username = $ ( cs - username ) dnslookup - time = $ ( dnslookup - time ) duration = $ ( duration ) rs - status = $ ( rs - status ) rs - version = $ ( rs - version ) s - action = $ ( s - action ) s - ip = $ ( s - ip ) service . name = $ ( service . name ) service . group = $ ( service . group ) s - supplier - ip = $ ( s - supplier - ip ) s - supplier - name = $ ( s - supplier - name ) sc - bytes = $ ( sc - bytes ) sc - filter - result = $ ( sc - filter - result ) sc - status = $ ( sc - status ) time - taken = $ ( time - taken ) x - exception - id = $ ( x - exception - id ) x - virus - id = $ ( x - virus - id ) c - url = $ ( quot ) $ ( url ) $ ( quot ) cs - Referer = $ ( quot ) $ ( cs ( Referer )) $ ( quot ) c - cpu = $ ( c - cpu ) connect - time = $ ( connect - time ) cs - auth - groups = $ ( cs - auth - groups ) cs - headerlength = $ ( cs - headerlength ) cs - threat - risk = $ ( cs - threat - risk ) r - ip = $ ( r - ip ) r - supplier - ip = $ ( r - supplier - ip ) rs - time - taken = $ ( rs - time - taken ) rs - server = $ ( rs ( server )) s - connect - type = $ ( s - connect - type ) s - icap - status = $ ( s - icap - status ) s - sitename = $ ( s - sitename ) s - source - port = $ ( s - source - port ) s - supplier - country = $ ( s - supplier - country ) sc - Content - Encoding = $ ( sc ( Content - Encoding )) sr - Accept - Encoding = $ ( sr ( Accept - Encoding )) x - auth - credential - type = $ ( x - auth - credential - type ) x - cookie - date = $ ( x - cookie - date ) x - cs - certificate - subject = $ ( x - cs - certificate - subject ) x - cs - connection - negotiated - cipher = $ ( x - cs - connection - negotiated - cipher ) x - cs - connection - negotiated - cipher - size = $ ( x - cs - connection - negotiated - cipher - size ) x - cs - connection - negotiated - ssl - version = $ ( x - cs - connection - negotiated - ssl - version ) x - cs - ocsp - error = $ ( x - cs - ocsp - error ) x - cs - Referer - uri = $ ( x - cs ( Referer ) - uri ) x - cs - Referer - uri - address = $ ( x - cs ( Referer ) - uri - address ) x - cs - Referer - uri - extension = $ ( x - cs ( Referer ) - uri - extension ) x - cs - Referer - uri - host = $ ( x - cs ( Referer ) - uri - host ) x - cs - Referer - uri - hostname = $ ( x - cs ( Referer ) - uri - hostname ) x - cs - Referer - uri - path = $ ( x - cs ( Referer ) - uri - path ) x - cs - Referer - uri - pathquery = $ ( x - cs ( Referer ) - uri - pathquery ) x - cs - Referer - uri - port = $ ( x - cs ( Referer ) - uri - port ) x - cs - Referer - uri - query = $ ( x - cs ( Referer ) - uri - query ) x - cs - Referer - uri - scheme = $ ( x - cs ( Referer ) - uri - scheme ) x - cs - Referer - uri - stem = $ ( x - cs ( Referer ) - uri - stem ) x - exception - category = $ ( x - exception - category ) x - exception - category - review - message = $ ( x - exception - category - review - message ) x - exception - company - name = $ ( x - exception - company - name ) x - exception - contact = $ ( x - exception - contact ) x - exception - details = $ ( x - exception - details ) x - exception - header = $ ( x - exception - header ) x - exception - help = $ ( x - exception - help ) x - exception - last - error = $ ( x - exception - last - error ) x - exception - reason = $ ( x - exception - reason ) x - exception - sourcefile = $ ( x - exception - sourcefile ) x - exception - sourceline = $ ( x - exception - sourceline ) x - exception - summary = $ ( x - exception - summary ) x - icap - error - code = $ ( x - icap - error - code ) x - rs - certificate - hostname = $ ( x - rs - certificate - hostname ) x - rs - certificate - hostname - category = $ ( x - rs - certificate - hostname - category ) x - rs - certificate - observed - errors = $ ( x - rs - certificate - observed - errors ) x - rs - certificate - subject = $ ( x - rs - certificate - subject ) x - rs - certificate - validate - status = $ ( x - rs - certificate - validate - status ) x - rs - connection - negotiated - cipher = $ ( x - rs - connection - negotiated - cipher ) x - rs - connection - negotiated - cipher - size = $ ( x - rs - connection - negotiated - cipher - size ) x - rs - connection - negotiated - ssl - version = $ ( x - rs - connection - negotiated - ssl - version ) x - rs - ocsp - error = $ ( x - rs - ocsp - error ) cs - uri - extension = $ ( cs - uri - extension ) cs - uri - path = $ ( cs - uri - path ) cs - uri - query = $ ( quot ) $ ( cs - uri - query ) $ ( quot ) c - uri - pathquery = $ ( c - uri - pathquery ) Options \u00b6 Variable default description SC4S_LISTEN_SYMANTEC_PROXY_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_SYMANTEC_PROXY_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_SYMANTEC_PROXY no Enable archive to disk for this specific source SC4S_DEST_SYMANTEC_PROXY_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 An active proxy will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=bluecoat:proxysg:access:kv | stats count by host Product - Mail Gateway (Brightmail) \u00b6 Ref Link Splunk Add-on TBD Product Manual https://support.symantec.com/us/en/article.howto38250.html Sourcetypes \u00b6 sourcetype notes symantec:smg Requires version TA 3.6 Sourcetype and Index Configuration \u00b6 key sourcetype index notes symantec_brightmail symantec:smg email none Filter type \u00b6 MSG Parse: This filter parses message content Setup and Configuration \u00b6 No TA available Review and update the splunk_metadata.csv file and set the index and sourcetype as required for the data source. Refer to the Splunk TA documentation for the specific customer format required for proxy configuration Select TCP or SSL transport option Ensure the format of the event is customized per Splunk documentation Options \u00b6 Variable default description SC4S_LISTEN_SYMANTEC_BRIGHTMAIL_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_SYMANTEC_BRIGHTMAIL_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_SYMANTEC_BRIGHTMAIL no Enable archive to disk for this specific source SC4S_DEST_SYMANTEC_BRIGHTMAIL_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source SC4S_SOURCE_FF_SYMANTEC_BRIGHTMAIL_GROUPMSG yes Email processing events generated by the bmserver process will be grouped by host+program+pid+msg ID into a single event ### Verification An active mail server will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=symantec:smg | stats count by host","title":"Broadcom"},{"location":"sources/Broadcom/#vendor-broadcom","text":"Broadcom products are inclusive of products formerly marketed under Symantec and Bluecoat brands.","title":"Vendor - Broadcom"},{"location":"sources/Broadcom/#product-ssl-visibility-appliance","text":"Ref Link Splunk Add-on None Product Manual https://knowledge.broadcom.com/external/article/168879/when-sending-session-logs-from-ssl-visib.html","title":"Product - SSL Visibility Appliance"},{"location":"sources/Broadcom/#sourcetypes","text":"sourcetype notes broadcom:sslva none","title":"Sourcetypes"},{"location":"sources/Broadcom/#product-symantec-endpoint-protection","text":"Ref Link Splunk Add-on https://splunkbase.splunk.com/app/2772/ Product Manual https://techdocs.broadcom.com/content/broadcom/techdocs/us/en/symantec-security-software/endpoint-security-and-management/endpoint-protection/all/Monitoring-Reporting-and-Enforcing-Compliance/viewing-logs-v7522439-d37e464/exporting-data-to-a-syslog-server-v8442743-d15e1107.html","title":"Product - Symantec Endpoint Protection"},{"location":"sources/Broadcom/#index-configuration","text":"key index notes broadcom_sslva netproxy none","title":"Index Configuration"},{"location":"sources/Broadcom/#filter-type","text":"MSG Parse: This filter parses message content","title":"Filter type"},{"location":"sources/Broadcom/#options","text":"Variable default description SC4S_LISTEN_SYMANTEC_EP_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_SYMANTEC_EP_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_SYMANTEC_EP no Enable archive to disk for this specific source SC4S_DEST_SYMANTEC_EP_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/Broadcom/#verification","text":"An active server will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=symantec:ep:*:syslog | stats count by host","title":"Verification"},{"location":"sources/Broadcom/#sourcetypes_1","text":"sourcetype notes symantec:ep:syslog Warning the syslog method of accepting EP logs has been reported to show high data loss and is not Supported by Splunk symantec:ep:admin:syslog none symantec:ep:agent:syslog none symantec:ep:agt:system:syslog none symantec:ep:behavior:syslog none symantec:ep:packet:syslog none symantec:ep:policy:syslog none symantec:ep:proactive:syslog none symantec:ep:risk:syslog none symantec:ep:scan:syslog none symantec:ep:scm:system:syslog none symantec:ep:security:syslog none symantec:ep:traffic:syslog none","title":"Sourcetypes"},{"location":"sources/Broadcom/#index-configuration_1","text":"key index notes symantec_ep epav none","title":"Index Configuration"},{"location":"sources/Broadcom/#filter-type_1","text":"MSG Parse: This filter parses message content","title":"Filter type"},{"location":"sources/Broadcom/#options_1","text":"Variable default description SC4S_LISTEN_SYMANTEC_EP_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_SYMANTEC_EP_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_SYMANTEC_EP no Enable archive to disk for this specific source SC4S_DEST_SYMANTEC_EP_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/Broadcom/#verification_1","text":"An active server will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=symantec:ep:*:syslog | stats count by host","title":"Verification"},{"location":"sources/Broadcom/#product-proxysgasg-bluecoat","text":"Ref Link Splunk Add-on https://splunkbase.splunk.com/app/2758/ Product Manual https://support.symantec.com/us/en/article.tech242216.html","title":"Product - ProxySG/ASG (Bluecoat)"},{"location":"sources/Broadcom/#sourcetypes_2","text":"sourcetype notes bluecoat:proxysg:access:kv Requires version TA 3.6","title":"Sourcetypes"},{"location":"sources/Broadcom/#sourcetype-and-index-configuration","text":"key sourcetype index notes bluecoat_proxy bluecoat:proxysg:access:kv netops none","title":"Sourcetype and Index Configuration"},{"location":"sources/Broadcom/#filter-type_2","text":"MSG Parse: This filter parses message content","title":"Filter type"},{"location":"sources/Broadcom/#setup-and-configuration","text":"Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used the addon is not required on the indexer. Review and update the splunk_metadata.csv file and set the index and sourcetype as required for the data source. Refer to the Splunk TA documentation for the specific customer format required for proxy configuration Select TCP or SSL transport option Ensure the format of the event is customized as follows < 111 > 1 $ ( date ) T $ ( x - bluecoat - hour - utc ) :$ ( x - bluecoat - minute - utc ) :$ ( x - bluecoat - second - utc ) $ ( s - computername ) bluecoat - splunk_format - c - ip = $ ( c - ip ) rs - Content - Type = $ ( quot ) $ ( rs ( Content - Type )) $ ( quot ) cs - auth - groups = $ ( cs - auth - groups ) cs - bytes = $ ( cs - bytes ) cs - categories = $ ( cs - categories ) cs - host = $ ( cs - host ) cs - ip = $ ( cs - ip ) cs - method = $ ( cs - method ) cs - uri - port = $ ( cs - uri - port ) cs - uri - scheme = $ ( cs - uri - scheme ) cs - User - Agent = $ ( quot ) $ ( cs ( User - Agent )) $ ( quot ) cs - username = $ ( cs - username ) dnslookup - time = $ ( dnslookup - time ) duration = $ ( duration ) rs - status = $ ( rs - status ) rs - version = $ ( rs - version ) s - action = $ ( s - action ) s - ip = $ ( s - ip ) service . name = $ ( service . name ) service . group = $ ( service . group ) s - supplier - ip = $ ( s - supplier - ip ) s - supplier - name = $ ( s - supplier - name ) sc - bytes = $ ( sc - bytes ) sc - filter - result = $ ( sc - filter - result ) sc - status = $ ( sc - status ) time - taken = $ ( time - taken ) x - exception - id = $ ( x - exception - id ) x - virus - id = $ ( x - virus - id ) c - url = $ ( quot ) $ ( url ) $ ( quot ) cs - Referer = $ ( quot ) $ ( cs ( Referer )) $ ( quot ) c - cpu = $ ( c - cpu ) connect - time = $ ( connect - time ) cs - auth - groups = $ ( cs - auth - groups ) cs - headerlength = $ ( cs - headerlength ) cs - threat - risk = $ ( cs - threat - risk ) r - ip = $ ( r - ip ) r - supplier - ip = $ ( r - supplier - ip ) rs - time - taken = $ ( rs - time - taken ) rs - server = $ ( rs ( server )) s - connect - type = $ ( s - connect - type ) s - icap - status = $ ( s - icap - status ) s - sitename = $ ( s - sitename ) s - source - port = $ ( s - source - port ) s - supplier - country = $ ( s - supplier - country ) sc - Content - Encoding = $ ( sc ( Content - Encoding )) sr - Accept - Encoding = $ ( sr ( Accept - Encoding )) x - auth - credential - type = $ ( x - auth - credential - type ) x - cookie - date = $ ( x - cookie - date ) x - cs - certificate - subject = $ ( x - cs - certificate - subject ) x - cs - connection - negotiated - cipher = $ ( x - cs - connection - negotiated - cipher ) x - cs - connection - negotiated - cipher - size = $ ( x - cs - connection - negotiated - cipher - size ) x - cs - connection - negotiated - ssl - version = $ ( x - cs - connection - negotiated - ssl - version ) x - cs - ocsp - error = $ ( x - cs - ocsp - error ) x - cs - Referer - uri = $ ( x - cs ( Referer ) - uri ) x - cs - Referer - uri - address = $ ( x - cs ( Referer ) - uri - address ) x - cs - Referer - uri - extension = $ ( x - cs ( Referer ) - uri - extension ) x - cs - Referer - uri - host = $ ( x - cs ( Referer ) - uri - host ) x - cs - Referer - uri - hostname = $ ( x - cs ( Referer ) - uri - hostname ) x - cs - Referer - uri - path = $ ( x - cs ( Referer ) - uri - path ) x - cs - Referer - uri - pathquery = $ ( x - cs ( Referer ) - uri - pathquery ) x - cs - Referer - uri - port = $ ( x - cs ( Referer ) - uri - port ) x - cs - Referer - uri - query = $ ( x - cs ( Referer ) - uri - query ) x - cs - Referer - uri - scheme = $ ( x - cs ( Referer ) - uri - scheme ) x - cs - Referer - uri - stem = $ ( x - cs ( Referer ) - uri - stem ) x - exception - category = $ ( x - exception - category ) x - exception - category - review - message = $ ( x - exception - category - review - message ) x - exception - company - name = $ ( x - exception - company - name ) x - exception - contact = $ ( x - exception - contact ) x - exception - details = $ ( x - exception - details ) x - exception - header = $ ( x - exception - header ) x - exception - help = $ ( x - exception - help ) x - exception - last - error = $ ( x - exception - last - error ) x - exception - reason = $ ( x - exception - reason ) x - exception - sourcefile = $ ( x - exception - sourcefile ) x - exception - sourceline = $ ( x - exception - sourceline ) x - exception - summary = $ ( x - exception - summary ) x - icap - error - code = $ ( x - icap - error - code ) x - rs - certificate - hostname = $ ( x - rs - certificate - hostname ) x - rs - certificate - hostname - category = $ ( x - rs - certificate - hostname - category ) x - rs - certificate - observed - errors = $ ( x - rs - certificate - observed - errors ) x - rs - certificate - subject = $ ( x - rs - certificate - subject ) x - rs - certificate - validate - status = $ ( x - rs - certificate - validate - status ) x - rs - connection - negotiated - cipher = $ ( x - rs - connection - negotiated - cipher ) x - rs - connection - negotiated - cipher - size = $ ( x - rs - connection - negotiated - cipher - size ) x - rs - connection - negotiated - ssl - version = $ ( x - rs - connection - negotiated - ssl - version ) x - rs - ocsp - error = $ ( x - rs - ocsp - error ) cs - uri - extension = $ ( cs - uri - extension ) cs - uri - path = $ ( cs - uri - path ) cs - uri - query = $ ( quot ) $ ( cs - uri - query ) $ ( quot ) c - uri - pathquery = $ ( c - uri - pathquery )","title":"Setup and Configuration"},{"location":"sources/Broadcom/#options_2","text":"Variable default description SC4S_LISTEN_SYMANTEC_PROXY_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_SYMANTEC_PROXY_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_SYMANTEC_PROXY no Enable archive to disk for this specific source SC4S_DEST_SYMANTEC_PROXY_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/Broadcom/#verification_2","text":"An active proxy will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=bluecoat:proxysg:access:kv | stats count by host","title":"Verification"},{"location":"sources/Broadcom/#product-mail-gateway-brightmail","text":"Ref Link Splunk Add-on TBD Product Manual https://support.symantec.com/us/en/article.howto38250.html","title":"Product - Mail Gateway (Brightmail)"},{"location":"sources/Broadcom/#sourcetypes_3","text":"sourcetype notes symantec:smg Requires version TA 3.6","title":"Sourcetypes"},{"location":"sources/Broadcom/#sourcetype-and-index-configuration_1","text":"key sourcetype index notes symantec_brightmail symantec:smg email none","title":"Sourcetype and Index Configuration"},{"location":"sources/Broadcom/#filter-type_3","text":"MSG Parse: This filter parses message content","title":"Filter type"},{"location":"sources/Broadcom/#setup-and-configuration_1","text":"No TA available Review and update the splunk_metadata.csv file and set the index and sourcetype as required for the data source. Refer to the Splunk TA documentation for the specific customer format required for proxy configuration Select TCP or SSL transport option Ensure the format of the event is customized per Splunk documentation","title":"Setup and Configuration"},{"location":"sources/Broadcom/#options_3","text":"Variable default description SC4S_LISTEN_SYMANTEC_BRIGHTMAIL_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_SYMANTEC_BRIGHTMAIL_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_SYMANTEC_BRIGHTMAIL no Enable archive to disk for this specific source SC4S_DEST_SYMANTEC_BRIGHTMAIL_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source SC4S_SOURCE_FF_SYMANTEC_BRIGHTMAIL_GROUPMSG yes Email processing events generated by the bmserver process will be grouped by host+program+pid+msg ID into a single event ### Verification An active mail server will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=symantec:smg | stats count by host","title":"Options"},{"location":"sources/Brocade/","text":"Vendor - Brocade \u00b6 Product - Switches \u00b6 Ref Link Splunk Add-on None Product Manual unknown Sourcetypes \u00b6 sourcetype notes brocade:syslog None Sourcetype and Index Configuration \u00b6 key sourcetype index notes brocade_syslog brocade:syslog netops none Filter type \u00b6 Must be identified by host or ip assignment. Update the filter f_brocade_syslog or configure a dedicated port as required Setup and Configuration \u00b6 Device setup unknown Options \u00b6 Variable default description SC4S_LISTEN_BROCADE_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_BROCADE_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_BROCADE no Enable archive to disk for this specific source SC4S_DEST_BROCADE_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 An active device will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=brocade:syslog| stats count by host","title":"Brocade"},{"location":"sources/Brocade/#vendor-brocade","text":"","title":"Vendor - Brocade"},{"location":"sources/Brocade/#product-switches","text":"Ref Link Splunk Add-on None Product Manual unknown","title":"Product - Switches"},{"location":"sources/Brocade/#sourcetypes","text":"sourcetype notes brocade:syslog None","title":"Sourcetypes"},{"location":"sources/Brocade/#sourcetype-and-index-configuration","text":"key sourcetype index notes brocade_syslog brocade:syslog netops none","title":"Sourcetype and Index Configuration"},{"location":"sources/Brocade/#filter-type","text":"Must be identified by host or ip assignment. Update the filter f_brocade_syslog or configure a dedicated port as required","title":"Filter type"},{"location":"sources/Brocade/#setup-and-configuration","text":"Device setup unknown","title":"Setup and Configuration"},{"location":"sources/Brocade/#options","text":"Variable default description SC4S_LISTEN_BROCADE_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_BROCADE_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_BROCADE no Enable archive to disk for this specific source SC4S_DEST_BROCADE_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/Brocade/#verification","text":"An active device will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=brocade:syslog| stats count by host","title":"Verification"},{"location":"sources/Checkpoint/","text":"Vendor - Checkpoint \u00b6 Product - Log Exporter (Splunk) \u00b6 Ref Link Splunk Add-on https://splunkbase.splunk.com/app/4293/ Product Manual https://sc1.checkpoint.com/documents/App_for_Splunk/html_frameset.htm Sourcetypes \u00b6 sourcetype notes cp_log None Sourcetype and Index Configuration \u00b6 key sourcetype index notes checkpoint_splunk cp_log netops none Source and Index Configuration \u00b6 Checkpoint Software blades with CIM mapping have been sub-grouped into sources to allow routing to appropriate indexes. All other source meta data is left at default key source index notes checkpoint_splunk_dlp dlp netdlp none checkpoint_splunk_email email email none checkpoint_splunk_firewall firewall netfw none checkpoint_splunk_os program:${program} netops none checkpoint_splunk_sessions sessions netops none checkpoint_splunk_web web netproxy none checkpoint_splunk_audit audit netops none checkpoint_splunk_endpoint endpoint netops none checkpoint_splunk_network network netops checkpoint_splunk_ids ids netids checkpoint_splunk_ids_malware ids_malware netids Filter type \u00b6 MSG Parse: This filter parses message content The Splunk host field will be derived as follows using the first match Use the hostname field Use the first CN component of origin_sic_name/originsicname If host is not set from CN use the hostname field If host is not set use the BSD syslog header host If the host is in the format <host>-v_<bladename> use bladename for host Setup and Configuration \u00b6 Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used the addon is not required on the indexer. Review and update the splunk_metadata.csv file and set the index and sourcetype as required for the data source. Follow vendor configuration steps per Product Manual above Options \u00b6 Variable default description SC4S_LISTEN_CHECKPOINT_SPLUNK_TCP_PORT empty string Enable a TCP port for this specific vendor product using the port number defined SC4S_LISTEN_CHECKPOINT_SPLUNK_UDP_PORT empty string Enable a UDP port for this specific vendor product using the port number defined SC4S_ARCHIVE_CHECKPOINT_SPLUNK no Enable archive to disk for this specific source SC4S_DEST_CHECKPOINT_SPLUNK_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source SC4S_LISTEN_CHECKPOINT_SPLUNK_NOISE_CONTROL no Suppress any duplicate product+loguid pairs processed within 2 seconds of the last matching event SC4S_LISTEN_CHECKPOINT_SPLUNK_OLD_HOST_RULES empty string when set to yes reverts host name selection order to originsicname\u2013>origin_sic_name\u2013>hostname Verification \u00b6 Use the following search to validate events are present index=<asconfigured> sourcetype=cp_log Verify timestamp, and host values match as expected Product - Log Exporter (Syslog) \u00b6 This is an alpha release not for production use. The syslog format from the log_exporter is the recommended format to collect checkpoint logs as it is more performant and efficient than its other default formats. Ref Link Splunk Add-on Product Manual https://sc1.checkpoint.com/documents/App_for_Splunk/html_frameset.htm Sourcetypes \u00b6 sourcetype notes cp_log:syslog None Sourcetype and Index Configuration \u00b6 key sourcetype index notes checkpoint_splunk cp_log:syslog netops none Source and Index Configuration \u00b6 Checkpoint Software blades with CIM mapping have been sub-grouped into sources to allow routing to appropriate indexes. All other source meta data is left at default key source index notes checkpoint_splunk_dlp dlp netdlp none checkpoint_splunk_email email email none checkpoint_splunk_firewall firewall netfw none checkpoint_splunk_sessions sessions netops none checkpoint_splunk_web web netproxy none checkpoint_splunk_audit audit netops none checkpoint_splunk_endpoint endpoint netops none checkpoint_splunk_network network netops checkpoint_splunk_ids ids netids checkpoint_splunk_ids_malware ids_malware netids Filter type \u00b6 MSG Parse: This filter parses message content Setup and Configuration \u00b6 Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used the addon is not required on the indexer. Review and update the splunk_metadata.csv file and set the index and sourcetype as required for the data source. To configure the valid syslog format in Checkpoint, follow the steps below Go to the cp terminal Enter expert command for login in expert mode Enter cd $EXPORTERDIR Then navigate to conf directory Execute cp SyslogFormatDefination.xml SplunkRecommendedFormatDefinition.xml Open SplunkRecommendedFormatDefinition.xml in edit mode and modify the start_message_body,fields_seperatator,field_value_seperatator as shown below. < start_message_body > [ sc4s @2620 </ start_message_body > <fields_seperatator> </fields_seperatator> <field_value_seperatator> = </field_value_seperatator> Copy SplunkRecommendedFormatDefinition.xml into $EXPORTERDIR/targets/ /conf Navigate to the configuration file $EXPORTERDIR/targets/ /conf/targetConfigurationSample.xml and open it in edit mode. Add the reference to the SplunkRecommendedFormatDefinition.xml under the key . For example, if $EXPORTERDIR=/opt/CPrt-R81/log_exporter, the absolute path will become: <formatHeaderFile> /opt/CPrt-R81/log_exporter/targets/ <your_log_exporter> /conf/SplunkRecommendedFormatDefinition.xml </formatHeaderFile> Restart cp_log_exporter by executing the command cp_log_export restart name Warning: Make sure if you migrating to different format, the earlier format is disabled or else it would lead to data duplication. Options \u00b6 Variable default description SC4S_LISTEN_CHECKPOINT_SYSLOG_TCP_PORT empty string Enable a TCP port for this specific vendor product using the port number defined SC4S_LISTEN_CHECKPOINT_SYSLOG_UDP_PORT empty string Enable a UDP port for this specific vendor product using the port number defined SC4S_ARCHIVE_CHECKPOINT_SYSLOG no Enable archive to disk for this specific source SC4S_DEST_CHECKPOINT_SYSLOG_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 Use the following search to validate events are present index=<asconfigured> sourcetype=cp_log:syslog Verify timestamp, and host values match as expected Product - Firewall OS \u00b6 Ref Link Splunk Add-on na Product Manual unknown Sourcetypes \u00b6 sourcetype notes cp_log:fw:syslog None Sourcetype and Index Configuration \u00b6 key sourcetype index notes checkpoint_fw cp_log:fw:syslog netops none Filter type \u00b6 Custom port or vendor_product_by_source configuration required Options \u00b6 Variable default description SC4S_LISTEN_CHECKPOINT_FW_TCP_PORT empty string Enable a TCP port for this specific vendor product using the port number defined SC4S_LISTEN_CHECKPOINT_FW_UDP_PORT empty string Enable a UDP port for this specific vendor product using the port number defined SC4S_ARCHIVE_CHECKPOINT_FW no Enable archive to disk for this specific source SC4S_DEST_CHECKPOINT_FW_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 Use the following search to validate events are present ``` index= sourcetype=cp_log:fw:syslog","title":"Checkpoint"},{"location":"sources/Checkpoint/#vendor-checkpoint","text":"","title":"Vendor - Checkpoint"},{"location":"sources/Checkpoint/#product-log-exporter-splunk","text":"Ref Link Splunk Add-on https://splunkbase.splunk.com/app/4293/ Product Manual https://sc1.checkpoint.com/documents/App_for_Splunk/html_frameset.htm","title":"Product - Log Exporter (Splunk)"},{"location":"sources/Checkpoint/#sourcetypes","text":"sourcetype notes cp_log None","title":"Sourcetypes"},{"location":"sources/Checkpoint/#sourcetype-and-index-configuration","text":"key sourcetype index notes checkpoint_splunk cp_log netops none","title":"Sourcetype and Index Configuration"},{"location":"sources/Checkpoint/#source-and-index-configuration","text":"Checkpoint Software blades with CIM mapping have been sub-grouped into sources to allow routing to appropriate indexes. All other source meta data is left at default key source index notes checkpoint_splunk_dlp dlp netdlp none checkpoint_splunk_email email email none checkpoint_splunk_firewall firewall netfw none checkpoint_splunk_os program:${program} netops none checkpoint_splunk_sessions sessions netops none checkpoint_splunk_web web netproxy none checkpoint_splunk_audit audit netops none checkpoint_splunk_endpoint endpoint netops none checkpoint_splunk_network network netops checkpoint_splunk_ids ids netids checkpoint_splunk_ids_malware ids_malware netids","title":"Source and Index Configuration"},{"location":"sources/Checkpoint/#filter-type","text":"MSG Parse: This filter parses message content The Splunk host field will be derived as follows using the first match Use the hostname field Use the first CN component of origin_sic_name/originsicname If host is not set from CN use the hostname field If host is not set use the BSD syslog header host If the host is in the format <host>-v_<bladename> use bladename for host","title":"Filter type"},{"location":"sources/Checkpoint/#setup-and-configuration","text":"Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used the addon is not required on the indexer. Review and update the splunk_metadata.csv file and set the index and sourcetype as required for the data source. Follow vendor configuration steps per Product Manual above","title":"Setup and Configuration"},{"location":"sources/Checkpoint/#options","text":"Variable default description SC4S_LISTEN_CHECKPOINT_SPLUNK_TCP_PORT empty string Enable a TCP port for this specific vendor product using the port number defined SC4S_LISTEN_CHECKPOINT_SPLUNK_UDP_PORT empty string Enable a UDP port for this specific vendor product using the port number defined SC4S_ARCHIVE_CHECKPOINT_SPLUNK no Enable archive to disk for this specific source SC4S_DEST_CHECKPOINT_SPLUNK_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source SC4S_LISTEN_CHECKPOINT_SPLUNK_NOISE_CONTROL no Suppress any duplicate product+loguid pairs processed within 2 seconds of the last matching event SC4S_LISTEN_CHECKPOINT_SPLUNK_OLD_HOST_RULES empty string when set to yes reverts host name selection order to originsicname\u2013>origin_sic_name\u2013>hostname","title":"Options"},{"location":"sources/Checkpoint/#verification","text":"Use the following search to validate events are present index=<asconfigured> sourcetype=cp_log Verify timestamp, and host values match as expected","title":"Verification"},{"location":"sources/Checkpoint/#product-log-exporter-syslog","text":"This is an alpha release not for production use. The syslog format from the log_exporter is the recommended format to collect checkpoint logs as it is more performant and efficient than its other default formats. Ref Link Splunk Add-on Product Manual https://sc1.checkpoint.com/documents/App_for_Splunk/html_frameset.htm","title":"Product - Log Exporter (Syslog)"},{"location":"sources/Checkpoint/#sourcetypes_1","text":"sourcetype notes cp_log:syslog None","title":"Sourcetypes"},{"location":"sources/Checkpoint/#sourcetype-and-index-configuration_1","text":"key sourcetype index notes checkpoint_splunk cp_log:syslog netops none","title":"Sourcetype and Index Configuration"},{"location":"sources/Checkpoint/#source-and-index-configuration_1","text":"Checkpoint Software blades with CIM mapping have been sub-grouped into sources to allow routing to appropriate indexes. All other source meta data is left at default key source index notes checkpoint_splunk_dlp dlp netdlp none checkpoint_splunk_email email email none checkpoint_splunk_firewall firewall netfw none checkpoint_splunk_sessions sessions netops none checkpoint_splunk_web web netproxy none checkpoint_splunk_audit audit netops none checkpoint_splunk_endpoint endpoint netops none checkpoint_splunk_network network netops checkpoint_splunk_ids ids netids checkpoint_splunk_ids_malware ids_malware netids","title":"Source and Index Configuration"},{"location":"sources/Checkpoint/#filter-type_1","text":"MSG Parse: This filter parses message content","title":"Filter type"},{"location":"sources/Checkpoint/#setup-and-configuration_1","text":"Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used the addon is not required on the indexer. Review and update the splunk_metadata.csv file and set the index and sourcetype as required for the data source. To configure the valid syslog format in Checkpoint, follow the steps below Go to the cp terminal Enter expert command for login in expert mode Enter cd $EXPORTERDIR Then navigate to conf directory Execute cp SyslogFormatDefination.xml SplunkRecommendedFormatDefinition.xml Open SplunkRecommendedFormatDefinition.xml in edit mode and modify the start_message_body,fields_seperatator,field_value_seperatator as shown below. < start_message_body > [ sc4s @2620 </ start_message_body > <fields_seperatator> </fields_seperatator> <field_value_seperatator> = </field_value_seperatator> Copy SplunkRecommendedFormatDefinition.xml into $EXPORTERDIR/targets/ /conf Navigate to the configuration file $EXPORTERDIR/targets/ /conf/targetConfigurationSample.xml and open it in edit mode. Add the reference to the SplunkRecommendedFormatDefinition.xml under the key . For example, if $EXPORTERDIR=/opt/CPrt-R81/log_exporter, the absolute path will become: <formatHeaderFile> /opt/CPrt-R81/log_exporter/targets/ <your_log_exporter> /conf/SplunkRecommendedFormatDefinition.xml </formatHeaderFile> Restart cp_log_exporter by executing the command cp_log_export restart name Warning: Make sure if you migrating to different format, the earlier format is disabled or else it would lead to data duplication.","title":"Setup and Configuration"},{"location":"sources/Checkpoint/#options_1","text":"Variable default description SC4S_LISTEN_CHECKPOINT_SYSLOG_TCP_PORT empty string Enable a TCP port for this specific vendor product using the port number defined SC4S_LISTEN_CHECKPOINT_SYSLOG_UDP_PORT empty string Enable a UDP port for this specific vendor product using the port number defined SC4S_ARCHIVE_CHECKPOINT_SYSLOG no Enable archive to disk for this specific source SC4S_DEST_CHECKPOINT_SYSLOG_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/Checkpoint/#verification_1","text":"Use the following search to validate events are present index=<asconfigured> sourcetype=cp_log:syslog Verify timestamp, and host values match as expected","title":"Verification"},{"location":"sources/Checkpoint/#product-firewall-os","text":"Ref Link Splunk Add-on na Product Manual unknown","title":"Product - Firewall OS"},{"location":"sources/Checkpoint/#sourcetypes_2","text":"sourcetype notes cp_log:fw:syslog None","title":"Sourcetypes"},{"location":"sources/Checkpoint/#sourcetype-and-index-configuration_2","text":"key sourcetype index notes checkpoint_fw cp_log:fw:syslog netops none","title":"Sourcetype and Index Configuration"},{"location":"sources/Checkpoint/#filter-type_2","text":"Custom port or vendor_product_by_source configuration required","title":"Filter type"},{"location":"sources/Checkpoint/#options_2","text":"Variable default description SC4S_LISTEN_CHECKPOINT_FW_TCP_PORT empty string Enable a TCP port for this specific vendor product using the port number defined SC4S_LISTEN_CHECKPOINT_FW_UDP_PORT empty string Enable a UDP port for this specific vendor product using the port number defined SC4S_ARCHIVE_CHECKPOINT_FW no Enable archive to disk for this specific source SC4S_DEST_CHECKPOINT_FW_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/Checkpoint/#verification_2","text":"Use the following search to validate events are present ``` index= sourcetype=cp_log:fw:syslog","title":"Verification"},{"location":"sources/Cisco/","text":"Vendor - Cisco \u00b6 Product - Application Control Engine (ACE) \u00b6 Ref Link Splunk Add-on None Sourcetypes \u00b6 sourcetype notes cisco:ace This source type is also used for ACE Sourcetype and Index Configuration \u00b6 key sourcetype index notes cisco_ace cisco:ace netops none Filter type \u00b6 Cisco ACE products can be identified by message parsing alone Setup and Configuration \u00b6 Unknown this product is unsupported by Cisco Options \u00b6 Variable default description SC4S_LISTEN_CISCO_ACE_UDP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_CISCO_ACE_TCP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_CISCO_ACE no Enable archive to disk for this specific source SC4S_DEST_CISCO_ACE_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 Use the following search to validate events are present index=<asconfigured> sourcetype=cisco:ace | stats count by host Product - Cisco Access Control System (ACS) \u00b6 Ref Link Splunk Add-on https://splunkbase.splunk.com/app/1811/ Product Manual https://community.cisco.com/t5/security-documents/acs-5-x-configuring-the-external-syslog-server/ta-p/3143143 Sourcetypes \u00b6 sourcetype notes cisco:acs Aggregation used Sourcetype and Index Configuration \u00b6 key sourcetype index notes cisco_acs cisco:acs netauth None Filter type \u00b6 PATTERN MATCH Setup and Configuration \u00b6 Replace the following extract using Splunk local configuration. Impacts version 1.5.0 of the addond EXTRACT-AA-signature = CSCOacs_(?<signature>\\S+):? # Note the value of this config is empty to disable EXTRACT-AA-syslog_message = EXTRACT-acs_message_header2 = ^CSCOacs_\\S+\\s+(?<log_session_id>\\S+)\\s+(?<total_segments>\\d+)\\s+(?<segment_number>\\d+)\\s+(?<acs_message>.*) Options \u00b6 Variable default description SC4S_LISTEN_CISCO_ACS_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_CISCO_ACS_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_CISCO_ACS no Enable archive to disk for this specific source SC4S_DEST_CISCO_ACS_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 Use the following search to validate events are present index=<asconfigured> sourcetype=cisco:acs Verify timestamp, and host values match as expected Product - ASA AND FTD (Firepower) \u00b6 Including Legacy FWSM and PIX Ref Link Splunk Add-on for ASA (No long supports FWSM and PIX) https://splunkbase.splunk.com/app/1620/ Cisco eStreamer for Splunk https://splunkbase.splunk.com/app/1629/ Product Manual https://www.cisco.com/c/en/us/td/docs/security/asa/asa82/configuration/guide/config/monitor_syslog.html Sourcetypes \u00b6 sourcetype notes cisco:asa cisco FTD Firepower will also use this source type except those noted below cisco:ftd cisco FTD Firepower will also use this source type except those noted below cisco:fwsm Splunk has cisco:pix cisco PIX will also use this source type except those noted below cisco:firepower:syslog FTD Unified events see https://www.cisco.com/c/en/us/td/docs/security/firepower/Syslogs/b_fptd_syslog_guide.pdf Sourcetype and Index Configuration \u00b6 key sourcetype index notes cisco_asa cisco:asa netfw none cisco_fwsm cisco:fwsm netfw none cisco_pix cisco:pix netfw none cisco_firepower cisco:firepower:syslog netids none cisco_ftd cisco:ftd netfw none Filter type \u00b6 MSG Parse: This filter parses message content Setup and Configuration \u00b6 Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used the addon is not required on the indexer. Review and update the splunk_metadata.csv file and set the index and sourcetype as required for the data source. Follow vendor configuration steps per Product Manual above ensure: Log Level is 6 \u201cInformational\u201d Protocol is TCP/IP permit-hostdown is on device-id is hostname and included timestamp is included Options \u00b6 Variable default description SC4S_LISTEN_CISCO_ASA_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_CISCO_ASA_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_CISCO_ASA no Enable archive to disk for this specific source SC4S_DEST_CISCO_ASA_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source SC4S_LISTEN_CISCO_ASA_LEGACY_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers expecting RFC3164 format SC4S_LISTEN_CISCO_ASA_LEGACY_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers expecting RFC3164 format SC4S_ARCHIVE_CISCO_ASA_LEGACY no Enable archive to disk for this specific source SC4S_DEST_CISCO_ASA_LEGACY_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 Use the following search to validate events are present index=<asconfigured> sourcetype=cisco:asa Verify timestamp, and host values match as expected Product - Cisco Email Security Appliance (ESA) \u00b6 Ref Link Splunk Add-on https://splunkbase.splunk.com/app/1761/ Product Manual https://www.cisco.com/c/en/us/td/docs/security/esa/esa14-0/user_guide/b_ESA_Admin_Guide_14-0.pdf Sourcetypes \u00b6 sourcetype notes cisco:esa:http The HTTP logs of Cisco IronPort ESA record information about the secure HTTP services enabled on the interface. cisco:esa:textmail Text mail logs of Cisco IronPort ESA record email information and status. cisco:esa:amp Advanced Malware Protection (AMP) of Cisco IronPort ESA records malware detection and blocking, continuous analysis, and retrospective alerting details. cisco:esa:authentication These logs record successful user logins and unsuccessful login attempts. cisco:esa:cef The Consolidated Event Logs summarizes each message event in a single log line. cisco:esa:error_logs Error logs of Cisco IronPort ESA records error that occured for ESA configurations or internal issues. cisco:esa:content_scanner Content scanner logs of Cisco IronPort ESA scans messages that contain password-protected attachments for malicious activity and data privacy. cisco:esa:antispam Anti-spam logs record the status of the anti-spam scanning feature of your system, including the status on receiving updates of the latest anti-spam rules. Also, any logs related to the Context Adaptive Scanning Engine are logged here. cisco:esa:system_logs System logs record the boot information, virtual appliance license expiration alerts, DNS status information, and comments users typed using commit command. Sourcetype and Index Configuration \u00b6 key sourcetype index notes cisco_esa cisco:esa:http email None cisco_esa cisco:esa:textmail email None cisco_esa cisco:esa:amp email None cisco_esa cisco:esa:authentication email None cisco_esa cisco:esa:cef email None cisco_esa cisco:esa:error_logs email None cisco_esa cisco:esa:content_scanner email None cisco_esa cisco:esa:antispam email None cisco_esa cisco:esa:system_logs email None Filter type \u00b6 IP, Netmask or Host Setup and Configuration \u00b6 Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used the addon is not required on the indexer. ESA Follow vendor configuration steps per Product Manual. Ensure host and timestamp are included. Update vi /opt/sc4s/local/context/vendor_product_by_source.conf update the host or ip mask for f_cisco_esa to identiy the esa events. Options \u00b6 Variable default description SC4S_LISTEN_CISCO_ESA_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_CISCO_ESA_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_CISCO_ESA no Enable archive to disk for this specific source SC4S_DEST_CISCO_ESA_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 Use the following search to validate events are present index=email sourcetype=cisco:esa:* Verify timestamp, and host values match as expected Product - Cisco Integrated Management Controller (IMC) \u00b6 Ref Link Splunk Add-on na Product Manual multiple Sourcetypes \u00b6 sourcetype notes cisco:ucm None Sourcetype and Index Configuration \u00b6 key sourcetype index notes cisco_cimc cisco:infraops infraops None Filter type \u00b6 PATTERN MATCH Setup and Configuration \u00b6 Refer to Cisco support web site Options \u00b6 Variable default description SC4S_LISTEN_CISCO_CIMC_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_CISCO_CIMC_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_CISCO_CIMC no Enable archive to disk for this specific source SC4S_DEST_CISCO_CIMC_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 Use the following search to validate events are present index=<asconfigured> sourcetype=cisco:cimc Verify timestamp, and host values match as expected Product - Cisco Networking (IOS and flavors) \u00b6 Cisco Network Products of multiple types share common logging characteristics the following types are known to be compatible: Cisco AireOS (AP & WLC) Cisco APIC/ACI Cisco IOS Cisco IOS-XR Cisco IOS-XE Cisco NX-OS Cisco FX-OS Ref Link Splunk Add-on https://splunkbase.splunk.com/app/1467/ IOS Manual https://www.cisco.com/c/en/us/td/docs/switches/lan/catalyst2960/software/release/12-2_55_se/configuration/guide/scg_2960/swlog.html NX-OS Manual https://www.cisco.com/c/en/us/td/docs/switches/datacenter/nexus9000/sw/6-x/system_management/configuration/guide/b_Cisco_Nexus_9000_Series_NX-OS_System_Management_Configuration_Guide/sm_5syslog.html Cisco ACI https://community.cisco.com/legacyfs/online/attachments/document/technote-aci-syslog_external-v1.pdf Cisco WLC & AP https://www.cisco.com/c/en/us/support/docs/wireless/4100-series-wireless-lan-controllers/107252-WLC-Syslog-Server.html#anc8 Sourcetypes \u00b6 sourcetype notes cisco:ios This source type is also used for NX-OS, ACI and WLC product lines Sourcetype and Index Configuration \u00b6 key sourcetype index notes cisco_ios cisco:ios netops none Filter type \u00b6 Cisco IOS products can be identified by message parsing alone Cisco WLC, and ACI products must be identified by host or ip assignment update the filter f_cisco_ios as required Setup and Configuration \u00b6 Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used the addon is not required on the indexer. Review and update the splunk_metadata.csv file and set the index and sourcetype as required for the data source. IOS Follow vendor configuration steps per Product Manual above ensure: Ensure a reliable NTP server is set and synced Log Level is 6 \u201cInformational\u201d Protocol is TCP/IP permit-hostdown is on device-id is hostname and included timestamp is included NX-OS Follow vendor configuration steps per Product Manual above ensure: Ensure a reliable NTP server is set and synced Log Level is 6 \u201cInformational\u201d user may select alternate levels by module based on use cases Protocol is TCP/IP device-id is hostname and included timestamp is included and milisecond accuracy selected ACI Logging configuration of the ACI product often varies by use case. Ensure NTP sync is configured and active Ensure proper host names are configured WLC Ensure NTP sync is configured and active Ensure proper host names are configured For security use cases per AP logging is required Options \u00b6 Variable default description SC4S_LISTEN_CISCO_IOS_UDP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_CISCO_IOS_TCP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_CISCO_IOS no Enable archive to disk for this specific source SC4S_DEST_CISCO_IOS_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 Use the following search to validate events are present, for NX-OS, WLC and ACI products ensure each host filter condition is verified index=<asconfigured> sourcetype=cisco:ios | stats count by host Product - Cisco Identity Services Engine (ISE) \u00b6 Ref Link Splunk Add-on https://splunkbase.splunk.com/app/1915/ Product Manual https://www.cisco.com/c/en/us/td/docs/security/ise/2-6/Cisco_ISE_Syslogs/Cisco_ISE_Syslogs/Cisco_ISE_Syslogs_chapter_00.html Sourcetypes \u00b6 sourcetype notes cisco:ise:syslog Aggregation used Sourcetype and Index Configuration \u00b6 key sourcetype index notes cisco_ise cisco:ise:syslog netauth None Filter type \u00b6 PATTERN MATCH Setup and Configuration \u00b6 No special steps required Options \u00b6 Variable default description SC4S_LISTEN_CISCO_ISE_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers expecting RFC5424 format SC4S_LISTEN_CISCO_ISE_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers expecting RFC5424 format SC4S_ARCHIVE_CISCO_ISE no Enable archive to disk for this specific source SC4S_DEST_CISCO_ISE_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 Use the following search to validate events are present index=<asconfigured> sourcetype=cisco:ise:syslog Verify timestamp, and host values match as expected Product - Meraki Product Line (MR, MS, MX, MV) \u00b6 Ref Link Splunk Add-on https://splunkbase.splunk.com/app/3018/ Product Manual https://documentation.meraki.com/zGeneral_Administration/Monitoring_and_Reporting/Syslog_Server_Overview_and_Configuration Sourcetypes \u00b6 sourcetype notes meraki None Sourcetype and Index Configuration \u00b6 key sourcetype index notes cisco_meraki meraki netfw The current TA does not sub sourcetype or utilize source preventing segmenation into more appropriate indexes Filter type \u00b6 IP, Netmask, Host or Port Setup and Configuration \u00b6 Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used the addon is not required on the indexer. Review and update the splunk_metadata.csv file and set the index and sourcetype as required for the data source. Follow vendor configuration steps per Product Manual above Options \u00b6 Variable default description SC4S_LISTEN_CISCO_MERAKI_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers expecting RFC5424 format SC4S_LISTEN_CISCO_MERAKI_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers expecting RFC5424 format SC4S_ARCHIVE_CISCO_MERAKI no Enable archive to disk for this specific source SC4S_DEST_CISCO_MERAKI_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 Use the following search to validate events are present index=<asconfigured> sourcetype=merkai Verify timestamp, and host values match as expected Product - Cisco TelePresence Video Communication Server (TVCS) \u00b6 Ref Link Product Manual https://www.cisco.com/c/en/us/products/unified-communications/telepresence-video-communication-server-vcs/index.html Sourcetypes \u00b6 sourcetype notes cisco:vcs none Sourcetype and Index Configuration \u00b6 key sourcetype index notes cisco_tvcs cisco:tvcs main none Filter type \u00b6 MSG Parse: This filter parses message content Setup and Configuration \u00b6 Source side unknown | Variable | default | description | |----------------|----------------|----------------| | SC4S_LISTEN_CISCO_TVCS_TCP_PORT | empty string | Enable a TCP port for this specific vendor product using a comma-separated list of port numbers | | SC4S_LISTEN_CISCO_TVCS_UDP_PORT | empty string | Enable a UDP port for this specific vendor product using a comma-separated list of port numbers | | SC4S_ARCHIVE_CISCO_TVCS | no | Enable archive to disk for this specific source | | SC4S_DEST_CISCO_TVCS_HEC | no | When Splunk HEC is disabled globally set to yes to enable this specific source | | SC4S_LISTEN_CISCO_TVCS_LEGACY_TCP_PORT | empty string | Enable a TCP port for this specific vendor product using a comma-separated list of port numbers expecting RFC3164 format | | SC4S_LISTEN_CISCO_TVCS_LEGACY_UDP_PORT | empty string | Enable a UDP port for this specific vendor product using a comma-separated list of port numbers expecting RFC3164 format | | SC4S_ARCHIVE_CISCO_TVCS_LEGACY | no | Enable archive to disk for this specific source | Verification \u00b6 Use the following search to validate events are present index=<asconfigured> sourcetype=cisco:tvcs Verify timestamp, and host values match as expected Product - Cisco Unified Communications Manager (UCM) \u00b6 Ref Link Splunk Add-on na Product Manual multiple Sourcetypes \u00b6 sourcetype notes cisco:ucm None Sourcetype and Index Configuration \u00b6 key sourcetype index notes cisco_ucm cisco:ucm ucm None Filter type \u00b6 PATTERN MATCH Setup and Configuration \u00b6 Refer to Cisco support web site Options \u00b6 Variable default description SC4S_LISTEN_CISCO_UCM_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_CISCO_UCM_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_CISCO_UCM no Enable archive to disk for this specific source SC4S_DEST_CISCO_UCM_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 Use the following search to validate events are present index=<asconfigured> sourcetype=cisco:ucm Verify timestamp, and host values match as expected Product - Cisco Unified Computing System (UCS) \u00b6 Ref Link Splunk Add-on na Product Manual multiple Sourcetypes \u00b6 sourcetype notes cisco:ucs None Sourcetype and Index Configuration \u00b6 key sourcetype index notes cisco_ucs cisco:ucs infraops None Filter type \u00b6 PATTERN MATCH Setup and Configuration \u00b6 Refer to Cisco support web site Options \u00b6 Variable default description SC4S_LISTEN_CISCO_UCS_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_CISCO_UCS_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_CISCO_UCS no Enable archive to disk for this specific source SC4S_DEST_CISCO_UCS_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 Use the following search to validate events are present index=<asconfigured> sourcetype=cisco:ucs Verify timestamp, and host values match as expected Product - Cisco UCS Hyperflex \u00b6 Ref Link Splunk Add-on na Product Manual multiple Sourcetypes \u00b6 sourcetype notes cisco:ucs:hx None Sourcetype and Index Configuration \u00b6 key sourcetype index notes cisco_ucs_hx cisco:ucs:hx infraops None Filter type \u00b6 PATTERN MATCH Setup and Configuration \u00b6 Refer to Cisco support web site Options \u00b6 Variable default description SC4S_LISTEN_CISCO_UCS_HX_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_CISCO_UCS_HX_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_CISCO_UCS_HX no Enable archive to disk for this specific source SC4S_DEST_CISCO_UCS_HX_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 Use the following search to validate events are present index=<asconfigured> sourcetype=cisco:ucs:hx Verify timestamp, and host values match as expected Product - Cisco Web Security Appliance (WSA) \u00b6 Ref Link Splunk Add-on https://splunkbase.splunk.com/app/1747/ Product Manual https://www.cisco.com/c/en/us/td/docs/security/wsa/wsa11-7/user_guide/b_WSA_UserGuide_11_7.html Update vi /opt/sc4s/local/context/vendor_product_by_source.conf update the host or ip mask for f_cisco_wsa to identiy the wsa squid events prior to WSA v11.7 and f_cisco_wsa11_7 to identify the squid events since WSA v11.7. Update the host or ip mask for f_cisco_wsa_w3crecommended to identify the wsa w3c events since WSA v12.5. Sourcetypes \u00b6 | cisco:wsa:l4tm | The L4TM logs of Cisco IronPort WSA record sites added to the L4TM block and allow lists. | | cisco:wsa:squid | The access logs of Cisco IronPort WSA version prior to 11.7 record Web Proxy client history in squid. | | cisco:wsa:squid:new | The access logs of Cisco IronPort WSA version since 11.7 record Web Proxy client history in squid. | | cisco:wsa:w3c:recommended | The access logs of Cisco IronPort WSA version since 12.5 record Web Proxy client history in W3C. | Sourcetype and Index Configuration \u00b6 key sourcetype index notes cisco_wsa cisco:wsa:l4tm netproxy None cisco_wsa cisco:wsa:squid netproxy None cisco_wsa cisco:wsa:squid:new netproxy None cisco_wsa cisco:wsa:w3c:recommended netproxy None Filter type \u00b6 IP, Netmask or Host Setup and Configuration \u00b6 Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used the addon is not required on the indexer. WSA Follow vendor configuration steps per Product Manual. Ensure host and timestamp are included. Options \u00b6 Variable default description SC4S_LISTEN_CISCO_WSA_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_CISCO_WSA_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_CISCO_WSA no Enable archive to disk for this specific source SC4S_DEST_CISCO_WSA_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 Use the following search to validate events are present index=netops sourcetype=cisco:wsa:* Verify timestamp, and host values match as expected","title":"Cisco"},{"location":"sources/Cisco/#vendor-cisco","text":"","title":"Vendor - Cisco"},{"location":"sources/Cisco/#product-application-control-engine-ace","text":"Ref Link Splunk Add-on None","title":"Product - Application Control Engine (ACE)"},{"location":"sources/Cisco/#sourcetypes","text":"sourcetype notes cisco:ace This source type is also used for ACE","title":"Sourcetypes"},{"location":"sources/Cisco/#sourcetype-and-index-configuration","text":"key sourcetype index notes cisco_ace cisco:ace netops none","title":"Sourcetype and Index Configuration"},{"location":"sources/Cisco/#filter-type","text":"Cisco ACE products can be identified by message parsing alone","title":"Filter type"},{"location":"sources/Cisco/#setup-and-configuration","text":"Unknown this product is unsupported by Cisco","title":"Setup and Configuration"},{"location":"sources/Cisco/#options","text":"Variable default description SC4S_LISTEN_CISCO_ACE_UDP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_CISCO_ACE_TCP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_CISCO_ACE no Enable archive to disk for this specific source SC4S_DEST_CISCO_ACE_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/Cisco/#verification","text":"Use the following search to validate events are present index=<asconfigured> sourcetype=cisco:ace | stats count by host","title":"Verification"},{"location":"sources/Cisco/#product-cisco-access-control-system-acs","text":"Ref Link Splunk Add-on https://splunkbase.splunk.com/app/1811/ Product Manual https://community.cisco.com/t5/security-documents/acs-5-x-configuring-the-external-syslog-server/ta-p/3143143","title":"Product - Cisco Access Control System (ACS)"},{"location":"sources/Cisco/#sourcetypes_1","text":"sourcetype notes cisco:acs Aggregation used","title":"Sourcetypes"},{"location":"sources/Cisco/#sourcetype-and-index-configuration_1","text":"key sourcetype index notes cisco_acs cisco:acs netauth None","title":"Sourcetype and Index Configuration"},{"location":"sources/Cisco/#filter-type_1","text":"PATTERN MATCH","title":"Filter type"},{"location":"sources/Cisco/#setup-and-configuration_1","text":"Replace the following extract using Splunk local configuration. Impacts version 1.5.0 of the addond EXTRACT-AA-signature = CSCOacs_(?<signature>\\S+):? # Note the value of this config is empty to disable EXTRACT-AA-syslog_message = EXTRACT-acs_message_header2 = ^CSCOacs_\\S+\\s+(?<log_session_id>\\S+)\\s+(?<total_segments>\\d+)\\s+(?<segment_number>\\d+)\\s+(?<acs_message>.*)","title":"Setup and Configuration"},{"location":"sources/Cisco/#options_1","text":"Variable default description SC4S_LISTEN_CISCO_ACS_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_CISCO_ACS_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_CISCO_ACS no Enable archive to disk for this specific source SC4S_DEST_CISCO_ACS_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/Cisco/#verification_1","text":"Use the following search to validate events are present index=<asconfigured> sourcetype=cisco:acs Verify timestamp, and host values match as expected","title":"Verification"},{"location":"sources/Cisco/#product-asa-and-ftd-firepower","text":"Including Legacy FWSM and PIX Ref Link Splunk Add-on for ASA (No long supports FWSM and PIX) https://splunkbase.splunk.com/app/1620/ Cisco eStreamer for Splunk https://splunkbase.splunk.com/app/1629/ Product Manual https://www.cisco.com/c/en/us/td/docs/security/asa/asa82/configuration/guide/config/monitor_syslog.html","title":"Product - ASA AND FTD (Firepower)"},{"location":"sources/Cisco/#sourcetypes_2","text":"sourcetype notes cisco:asa cisco FTD Firepower will also use this source type except those noted below cisco:ftd cisco FTD Firepower will also use this source type except those noted below cisco:fwsm Splunk has cisco:pix cisco PIX will also use this source type except those noted below cisco:firepower:syslog FTD Unified events see https://www.cisco.com/c/en/us/td/docs/security/firepower/Syslogs/b_fptd_syslog_guide.pdf","title":"Sourcetypes"},{"location":"sources/Cisco/#sourcetype-and-index-configuration_2","text":"key sourcetype index notes cisco_asa cisco:asa netfw none cisco_fwsm cisco:fwsm netfw none cisco_pix cisco:pix netfw none cisco_firepower cisco:firepower:syslog netids none cisco_ftd cisco:ftd netfw none","title":"Sourcetype and Index Configuration"},{"location":"sources/Cisco/#filter-type_2","text":"MSG Parse: This filter parses message content","title":"Filter type"},{"location":"sources/Cisco/#setup-and-configuration_2","text":"Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used the addon is not required on the indexer. Review and update the splunk_metadata.csv file and set the index and sourcetype as required for the data source. Follow vendor configuration steps per Product Manual above ensure: Log Level is 6 \u201cInformational\u201d Protocol is TCP/IP permit-hostdown is on device-id is hostname and included timestamp is included","title":"Setup and Configuration"},{"location":"sources/Cisco/#options_2","text":"Variable default description SC4S_LISTEN_CISCO_ASA_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_CISCO_ASA_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_CISCO_ASA no Enable archive to disk for this specific source SC4S_DEST_CISCO_ASA_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source SC4S_LISTEN_CISCO_ASA_LEGACY_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers expecting RFC3164 format SC4S_LISTEN_CISCO_ASA_LEGACY_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers expecting RFC3164 format SC4S_ARCHIVE_CISCO_ASA_LEGACY no Enable archive to disk for this specific source SC4S_DEST_CISCO_ASA_LEGACY_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/Cisco/#verification_2","text":"Use the following search to validate events are present index=<asconfigured> sourcetype=cisco:asa Verify timestamp, and host values match as expected","title":"Verification"},{"location":"sources/Cisco/#product-cisco-email-security-appliance-esa","text":"Ref Link Splunk Add-on https://splunkbase.splunk.com/app/1761/ Product Manual https://www.cisco.com/c/en/us/td/docs/security/esa/esa14-0/user_guide/b_ESA_Admin_Guide_14-0.pdf","title":"Product - Cisco Email Security Appliance (ESA)"},{"location":"sources/Cisco/#sourcetypes_3","text":"sourcetype notes cisco:esa:http The HTTP logs of Cisco IronPort ESA record information about the secure HTTP services enabled on the interface. cisco:esa:textmail Text mail logs of Cisco IronPort ESA record email information and status. cisco:esa:amp Advanced Malware Protection (AMP) of Cisco IronPort ESA records malware detection and blocking, continuous analysis, and retrospective alerting details. cisco:esa:authentication These logs record successful user logins and unsuccessful login attempts. cisco:esa:cef The Consolidated Event Logs summarizes each message event in a single log line. cisco:esa:error_logs Error logs of Cisco IronPort ESA records error that occured for ESA configurations or internal issues. cisco:esa:content_scanner Content scanner logs of Cisco IronPort ESA scans messages that contain password-protected attachments for malicious activity and data privacy. cisco:esa:antispam Anti-spam logs record the status of the anti-spam scanning feature of your system, including the status on receiving updates of the latest anti-spam rules. Also, any logs related to the Context Adaptive Scanning Engine are logged here. cisco:esa:system_logs System logs record the boot information, virtual appliance license expiration alerts, DNS status information, and comments users typed using commit command.","title":"Sourcetypes"},{"location":"sources/Cisco/#sourcetype-and-index-configuration_3","text":"key sourcetype index notes cisco_esa cisco:esa:http email None cisco_esa cisco:esa:textmail email None cisco_esa cisco:esa:amp email None cisco_esa cisco:esa:authentication email None cisco_esa cisco:esa:cef email None cisco_esa cisco:esa:error_logs email None cisco_esa cisco:esa:content_scanner email None cisco_esa cisco:esa:antispam email None cisco_esa cisco:esa:system_logs email None","title":"Sourcetype and Index Configuration"},{"location":"sources/Cisco/#filter-type_3","text":"IP, Netmask or Host","title":"Filter type"},{"location":"sources/Cisco/#setup-and-configuration_3","text":"Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used the addon is not required on the indexer. ESA Follow vendor configuration steps per Product Manual. Ensure host and timestamp are included. Update vi /opt/sc4s/local/context/vendor_product_by_source.conf update the host or ip mask for f_cisco_esa to identiy the esa events.","title":"Setup and Configuration"},{"location":"sources/Cisco/#options_3","text":"Variable default description SC4S_LISTEN_CISCO_ESA_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_CISCO_ESA_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_CISCO_ESA no Enable archive to disk for this specific source SC4S_DEST_CISCO_ESA_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/Cisco/#verification_3","text":"Use the following search to validate events are present index=email sourcetype=cisco:esa:* Verify timestamp, and host values match as expected","title":"Verification"},{"location":"sources/Cisco/#product-cisco-integrated-management-controller-imc","text":"Ref Link Splunk Add-on na Product Manual multiple","title":"Product - Cisco Integrated Management Controller (IMC)"},{"location":"sources/Cisco/#sourcetypes_4","text":"sourcetype notes cisco:ucm None","title":"Sourcetypes"},{"location":"sources/Cisco/#sourcetype-and-index-configuration_4","text":"key sourcetype index notes cisco_cimc cisco:infraops infraops None","title":"Sourcetype and Index Configuration"},{"location":"sources/Cisco/#filter-type_4","text":"PATTERN MATCH","title":"Filter type"},{"location":"sources/Cisco/#setup-and-configuration_4","text":"Refer to Cisco support web site","title":"Setup and Configuration"},{"location":"sources/Cisco/#options_4","text":"Variable default description SC4S_LISTEN_CISCO_CIMC_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_CISCO_CIMC_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_CISCO_CIMC no Enable archive to disk for this specific source SC4S_DEST_CISCO_CIMC_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/Cisco/#verification_4","text":"Use the following search to validate events are present index=<asconfigured> sourcetype=cisco:cimc Verify timestamp, and host values match as expected","title":"Verification"},{"location":"sources/Cisco/#product-cisco-networking-ios-and-flavors","text":"Cisco Network Products of multiple types share common logging characteristics the following types are known to be compatible: Cisco AireOS (AP & WLC) Cisco APIC/ACI Cisco IOS Cisco IOS-XR Cisco IOS-XE Cisco NX-OS Cisco FX-OS Ref Link Splunk Add-on https://splunkbase.splunk.com/app/1467/ IOS Manual https://www.cisco.com/c/en/us/td/docs/switches/lan/catalyst2960/software/release/12-2_55_se/configuration/guide/scg_2960/swlog.html NX-OS Manual https://www.cisco.com/c/en/us/td/docs/switches/datacenter/nexus9000/sw/6-x/system_management/configuration/guide/b_Cisco_Nexus_9000_Series_NX-OS_System_Management_Configuration_Guide/sm_5syslog.html Cisco ACI https://community.cisco.com/legacyfs/online/attachments/document/technote-aci-syslog_external-v1.pdf Cisco WLC & AP https://www.cisco.com/c/en/us/support/docs/wireless/4100-series-wireless-lan-controllers/107252-WLC-Syslog-Server.html#anc8","title":"Product - Cisco Networking (IOS and flavors)"},{"location":"sources/Cisco/#sourcetypes_5","text":"sourcetype notes cisco:ios This source type is also used for NX-OS, ACI and WLC product lines","title":"Sourcetypes"},{"location":"sources/Cisco/#sourcetype-and-index-configuration_5","text":"key sourcetype index notes cisco_ios cisco:ios netops none","title":"Sourcetype and Index Configuration"},{"location":"sources/Cisco/#filter-type_5","text":"Cisco IOS products can be identified by message parsing alone Cisco WLC, and ACI products must be identified by host or ip assignment update the filter f_cisco_ios as required","title":"Filter type"},{"location":"sources/Cisco/#setup-and-configuration_5","text":"Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used the addon is not required on the indexer. Review and update the splunk_metadata.csv file and set the index and sourcetype as required for the data source. IOS Follow vendor configuration steps per Product Manual above ensure: Ensure a reliable NTP server is set and synced Log Level is 6 \u201cInformational\u201d Protocol is TCP/IP permit-hostdown is on device-id is hostname and included timestamp is included NX-OS Follow vendor configuration steps per Product Manual above ensure: Ensure a reliable NTP server is set and synced Log Level is 6 \u201cInformational\u201d user may select alternate levels by module based on use cases Protocol is TCP/IP device-id is hostname and included timestamp is included and milisecond accuracy selected ACI Logging configuration of the ACI product often varies by use case. Ensure NTP sync is configured and active Ensure proper host names are configured WLC Ensure NTP sync is configured and active Ensure proper host names are configured For security use cases per AP logging is required","title":"Setup and Configuration"},{"location":"sources/Cisco/#options_5","text":"Variable default description SC4S_LISTEN_CISCO_IOS_UDP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_CISCO_IOS_TCP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_CISCO_IOS no Enable archive to disk for this specific source SC4S_DEST_CISCO_IOS_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/Cisco/#verification_5","text":"Use the following search to validate events are present, for NX-OS, WLC and ACI products ensure each host filter condition is verified index=<asconfigured> sourcetype=cisco:ios | stats count by host","title":"Verification"},{"location":"sources/Cisco/#product-cisco-identity-services-engine-ise","text":"Ref Link Splunk Add-on https://splunkbase.splunk.com/app/1915/ Product Manual https://www.cisco.com/c/en/us/td/docs/security/ise/2-6/Cisco_ISE_Syslogs/Cisco_ISE_Syslogs/Cisco_ISE_Syslogs_chapter_00.html","title":"Product - Cisco Identity Services Engine (ISE)"},{"location":"sources/Cisco/#sourcetypes_6","text":"sourcetype notes cisco:ise:syslog Aggregation used","title":"Sourcetypes"},{"location":"sources/Cisco/#sourcetype-and-index-configuration_6","text":"key sourcetype index notes cisco_ise cisco:ise:syslog netauth None","title":"Sourcetype and Index Configuration"},{"location":"sources/Cisco/#filter-type_6","text":"PATTERN MATCH","title":"Filter type"},{"location":"sources/Cisco/#setup-and-configuration_6","text":"No special steps required","title":"Setup and Configuration"},{"location":"sources/Cisco/#options_6","text":"Variable default description SC4S_LISTEN_CISCO_ISE_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers expecting RFC5424 format SC4S_LISTEN_CISCO_ISE_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers expecting RFC5424 format SC4S_ARCHIVE_CISCO_ISE no Enable archive to disk for this specific source SC4S_DEST_CISCO_ISE_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/Cisco/#verification_6","text":"Use the following search to validate events are present index=<asconfigured> sourcetype=cisco:ise:syslog Verify timestamp, and host values match as expected","title":"Verification"},{"location":"sources/Cisco/#product-meraki-product-line-mr-ms-mx-mv","text":"Ref Link Splunk Add-on https://splunkbase.splunk.com/app/3018/ Product Manual https://documentation.meraki.com/zGeneral_Administration/Monitoring_and_Reporting/Syslog_Server_Overview_and_Configuration","title":"Product - Meraki Product Line (MR, MS, MX, MV)"},{"location":"sources/Cisco/#sourcetypes_7","text":"sourcetype notes meraki None","title":"Sourcetypes"},{"location":"sources/Cisco/#sourcetype-and-index-configuration_7","text":"key sourcetype index notes cisco_meraki meraki netfw The current TA does not sub sourcetype or utilize source preventing segmenation into more appropriate indexes","title":"Sourcetype and Index Configuration"},{"location":"sources/Cisco/#filter-type_7","text":"IP, Netmask, Host or Port","title":"Filter type"},{"location":"sources/Cisco/#setup-and-configuration_7","text":"Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used the addon is not required on the indexer. Review and update the splunk_metadata.csv file and set the index and sourcetype as required for the data source. Follow vendor configuration steps per Product Manual above","title":"Setup and Configuration"},{"location":"sources/Cisco/#options_7","text":"Variable default description SC4S_LISTEN_CISCO_MERAKI_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers expecting RFC5424 format SC4S_LISTEN_CISCO_MERAKI_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers expecting RFC5424 format SC4S_ARCHIVE_CISCO_MERAKI no Enable archive to disk for this specific source SC4S_DEST_CISCO_MERAKI_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/Cisco/#verification_7","text":"Use the following search to validate events are present index=<asconfigured> sourcetype=merkai Verify timestamp, and host values match as expected","title":"Verification"},{"location":"sources/Cisco/#product-cisco-telepresence-video-communication-server-tvcs","text":"Ref Link Product Manual https://www.cisco.com/c/en/us/products/unified-communications/telepresence-video-communication-server-vcs/index.html","title":"Product - Cisco TelePresence Video Communication Server (TVCS)"},{"location":"sources/Cisco/#sourcetypes_8","text":"sourcetype notes cisco:vcs none","title":"Sourcetypes"},{"location":"sources/Cisco/#sourcetype-and-index-configuration_8","text":"key sourcetype index notes cisco_tvcs cisco:tvcs main none","title":"Sourcetype and Index Configuration"},{"location":"sources/Cisco/#filter-type_8","text":"MSG Parse: This filter parses message content","title":"Filter type"},{"location":"sources/Cisco/#setup-and-configuration_8","text":"Source side unknown | Variable | default | description | |----------------|----------------|----------------| | SC4S_LISTEN_CISCO_TVCS_TCP_PORT | empty string | Enable a TCP port for this specific vendor product using a comma-separated list of port numbers | | SC4S_LISTEN_CISCO_TVCS_UDP_PORT | empty string | Enable a UDP port for this specific vendor product using a comma-separated list of port numbers | | SC4S_ARCHIVE_CISCO_TVCS | no | Enable archive to disk for this specific source | | SC4S_DEST_CISCO_TVCS_HEC | no | When Splunk HEC is disabled globally set to yes to enable this specific source | | SC4S_LISTEN_CISCO_TVCS_LEGACY_TCP_PORT | empty string | Enable a TCP port for this specific vendor product using a comma-separated list of port numbers expecting RFC3164 format | | SC4S_LISTEN_CISCO_TVCS_LEGACY_UDP_PORT | empty string | Enable a UDP port for this specific vendor product using a comma-separated list of port numbers expecting RFC3164 format | | SC4S_ARCHIVE_CISCO_TVCS_LEGACY | no | Enable archive to disk for this specific source |","title":"Setup and Configuration"},{"location":"sources/Cisco/#verification_8","text":"Use the following search to validate events are present index=<asconfigured> sourcetype=cisco:tvcs Verify timestamp, and host values match as expected","title":"Verification"},{"location":"sources/Cisco/#product-cisco-unified-communications-manager-ucm","text":"Ref Link Splunk Add-on na Product Manual multiple","title":"Product - Cisco Unified Communications Manager (UCM)"},{"location":"sources/Cisco/#sourcetypes_9","text":"sourcetype notes cisco:ucm None","title":"Sourcetypes"},{"location":"sources/Cisco/#sourcetype-and-index-configuration_9","text":"key sourcetype index notes cisco_ucm cisco:ucm ucm None","title":"Sourcetype and Index Configuration"},{"location":"sources/Cisco/#filter-type_9","text":"PATTERN MATCH","title":"Filter type"},{"location":"sources/Cisco/#setup-and-configuration_9","text":"Refer to Cisco support web site","title":"Setup and Configuration"},{"location":"sources/Cisco/#options_8","text":"Variable default description SC4S_LISTEN_CISCO_UCM_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_CISCO_UCM_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_CISCO_UCM no Enable archive to disk for this specific source SC4S_DEST_CISCO_UCM_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/Cisco/#verification_9","text":"Use the following search to validate events are present index=<asconfigured> sourcetype=cisco:ucm Verify timestamp, and host values match as expected","title":"Verification"},{"location":"sources/Cisco/#product-cisco-unified-computing-system-ucs","text":"Ref Link Splunk Add-on na Product Manual multiple","title":"Product - Cisco Unified Computing System (UCS)"},{"location":"sources/Cisco/#sourcetypes_10","text":"sourcetype notes cisco:ucs None","title":"Sourcetypes"},{"location":"sources/Cisco/#sourcetype-and-index-configuration_10","text":"key sourcetype index notes cisco_ucs cisco:ucs infraops None","title":"Sourcetype and Index Configuration"},{"location":"sources/Cisco/#filter-type_10","text":"PATTERN MATCH","title":"Filter type"},{"location":"sources/Cisco/#setup-and-configuration_10","text":"Refer to Cisco support web site","title":"Setup and Configuration"},{"location":"sources/Cisco/#options_9","text":"Variable default description SC4S_LISTEN_CISCO_UCS_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_CISCO_UCS_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_CISCO_UCS no Enable archive to disk for this specific source SC4S_DEST_CISCO_UCS_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/Cisco/#verification_10","text":"Use the following search to validate events are present index=<asconfigured> sourcetype=cisco:ucs Verify timestamp, and host values match as expected","title":"Verification"},{"location":"sources/Cisco/#product-cisco-ucs-hyperflex","text":"Ref Link Splunk Add-on na Product Manual multiple","title":"Product - Cisco UCS Hyperflex"},{"location":"sources/Cisco/#sourcetypes_11","text":"sourcetype notes cisco:ucs:hx None","title":"Sourcetypes"},{"location":"sources/Cisco/#sourcetype-and-index-configuration_11","text":"key sourcetype index notes cisco_ucs_hx cisco:ucs:hx infraops None","title":"Sourcetype and Index Configuration"},{"location":"sources/Cisco/#filter-type_11","text":"PATTERN MATCH","title":"Filter type"},{"location":"sources/Cisco/#setup-and-configuration_11","text":"Refer to Cisco support web site","title":"Setup and Configuration"},{"location":"sources/Cisco/#options_10","text":"Variable default description SC4S_LISTEN_CISCO_UCS_HX_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_CISCO_UCS_HX_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_CISCO_UCS_HX no Enable archive to disk for this specific source SC4S_DEST_CISCO_UCS_HX_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/Cisco/#verification_11","text":"Use the following search to validate events are present index=<asconfigured> sourcetype=cisco:ucs:hx Verify timestamp, and host values match as expected","title":"Verification"},{"location":"sources/Cisco/#product-cisco-web-security-appliance-wsa","text":"Ref Link Splunk Add-on https://splunkbase.splunk.com/app/1747/ Product Manual https://www.cisco.com/c/en/us/td/docs/security/wsa/wsa11-7/user_guide/b_WSA_UserGuide_11_7.html Update vi /opt/sc4s/local/context/vendor_product_by_source.conf update the host or ip mask for f_cisco_wsa to identiy the wsa squid events prior to WSA v11.7 and f_cisco_wsa11_7 to identify the squid events since WSA v11.7. Update the host or ip mask for f_cisco_wsa_w3crecommended to identify the wsa w3c events since WSA v12.5.","title":"Product - Cisco Web Security Appliance (WSA)"},{"location":"sources/Cisco/#sourcetypes_12","text":"| cisco:wsa:l4tm | The L4TM logs of Cisco IronPort WSA record sites added to the L4TM block and allow lists. | | cisco:wsa:squid | The access logs of Cisco IronPort WSA version prior to 11.7 record Web Proxy client history in squid. | | cisco:wsa:squid:new | The access logs of Cisco IronPort WSA version since 11.7 record Web Proxy client history in squid. | | cisco:wsa:w3c:recommended | The access logs of Cisco IronPort WSA version since 12.5 record Web Proxy client history in W3C. |","title":"Sourcetypes"},{"location":"sources/Cisco/#sourcetype-and-index-configuration_12","text":"key sourcetype index notes cisco_wsa cisco:wsa:l4tm netproxy None cisco_wsa cisco:wsa:squid netproxy None cisco_wsa cisco:wsa:squid:new netproxy None cisco_wsa cisco:wsa:w3c:recommended netproxy None","title":"Sourcetype and Index Configuration"},{"location":"sources/Cisco/#filter-type_12","text":"IP, Netmask or Host","title":"Filter type"},{"location":"sources/Cisco/#setup-and-configuration_12","text":"Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used the addon is not required on the indexer. WSA Follow vendor configuration steps per Product Manual. Ensure host and timestamp are included.","title":"Setup and Configuration"},{"location":"sources/Cisco/#options_11","text":"Variable default description SC4S_LISTEN_CISCO_WSA_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_CISCO_WSA_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_CISCO_WSA no Enable archive to disk for this specific source SC4S_DEST_CISCO_WSA_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/Cisco/#verification_12","text":"Use the following search to validate events are present index=netops sourcetype=cisco:wsa:* Verify timestamp, and host values match as expected","title":"Verification"},{"location":"sources/Citrix/","text":"Vendor - Citrix \u00b6 Product - Netscaler ADC/SDX \u00b6 Ref Link Splunk Add-on https://splunkbase.splunk.com/app/2770/ Product Manual https://docs.citrix.com/en-us/citrix-adc/12-1/system/audit-logging/configuring-audit-logging.html Sourcetypes \u00b6 sourcetype notes citrix:netscaler:syslog None Sourcetype and Index Configuration \u00b6 key sourcetype index notes citrix_netscaler citrix:netscaler:syslog netfw none Filter type \u00b6 MSG Parse: This filter parses message content Setup and Configuration \u00b6 Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used the addon is not required on the indexer. Review and update the splunk_metadata.csv file and set the index and sourcetype as required for the data source. Follow vendor configuration steps per Product Manual above. Ensure the data format selected is \u201cDDMMYYYY\u201d Options \u00b6 Variable default description SC4S_LISTEN_CITRIX_NETSCALER_TCP_PORT empty string Enable a TCP port for this specific vendor product using the port number defined SC4S_LISTEN_CITRIX_NETSCALER_UDP_PORT empty string Enable a UDP port for this specific vendor product using the port number defined SC4S_DEST_CITRIX_NETSCALER_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 Use the following search to validate events are present index=<asconfigured> sourcetype=cp_log Verify timestamp, and host values match as expected","title":"Citrix"},{"location":"sources/Citrix/#vendor-citrix","text":"","title":"Vendor - Citrix"},{"location":"sources/Citrix/#product-netscaler-adcsdx","text":"Ref Link Splunk Add-on https://splunkbase.splunk.com/app/2770/ Product Manual https://docs.citrix.com/en-us/citrix-adc/12-1/system/audit-logging/configuring-audit-logging.html","title":"Product - Netscaler ADC/SDX"},{"location":"sources/Citrix/#sourcetypes","text":"sourcetype notes citrix:netscaler:syslog None","title":"Sourcetypes"},{"location":"sources/Citrix/#sourcetype-and-index-configuration","text":"key sourcetype index notes citrix_netscaler citrix:netscaler:syslog netfw none","title":"Sourcetype and Index Configuration"},{"location":"sources/Citrix/#filter-type","text":"MSG Parse: This filter parses message content","title":"Filter type"},{"location":"sources/Citrix/#setup-and-configuration","text":"Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used the addon is not required on the indexer. Review and update the splunk_metadata.csv file and set the index and sourcetype as required for the data source. Follow vendor configuration steps per Product Manual above. Ensure the data format selected is \u201cDDMMYYYY\u201d","title":"Setup and Configuration"},{"location":"sources/Citrix/#options","text":"Variable default description SC4S_LISTEN_CITRIX_NETSCALER_TCP_PORT empty string Enable a TCP port for this specific vendor product using the port number defined SC4S_LISTEN_CITRIX_NETSCALER_UDP_PORT empty string Enable a UDP port for this specific vendor product using the port number defined SC4S_DEST_CITRIX_NETSCALER_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/Citrix/#verification","text":"Use the following search to validate events are present index=<asconfigured> sourcetype=cp_log Verify timestamp, and host values match as expected","title":"Verification"},{"location":"sources/CommonEventFormat/","text":"Vendor - Common Event Format Data Sources \u00b6 Product - Various products that send CEF-format messages via syslog \u00b6 Each CEF product should have their own source entry in this documentation set. In a departure from normal configuration, all CEF products should use the \u201cCEF\u201d version of the unique port and archive environment variable settings (rather than a unique one per product), as the CEF log path handles all products sending events to SC4S in the CEF format. Examples of this include Arcsight, Imperva, and Cyberark. Therefore, the CEF environment variables for unique port, archive, etc. should be set only once . If your deployment has multiple CEF devices that send to more than one port, set the CEF unique port variable(s) as a comma-separated list. See Unique Listening Ports for details. The source documentation included below is a reference baseline for any product that sends data using the CEF log path. Ref Link Splunk Add-on CEF https://bitbucket.org/SPLServices/ta-cef-for-splunk/downloads/ Product Manual https://docs.imperva.com/bundle/cloud-application-security/page/more/log-configuration.htm Splunk Metadata with CEF events \u00b6 The keys (first column) in splunk_metadata.csv for CEF data sources have a slightly different meaning than those for non-CEF ones. The typical vendor_product syntax is instead replaced by checks against specific columns of the CEF event \u2013 namely the first, second, and fourth columns following the leading CEF:0 (\u201ccolumn 0\u201d). These specific columns refer to the CEF device_vendor , device_product , and device_event_class , respectively. The third column, device_version , is not used for metadata assignment. SC4S sets metadata based on the first two columns, and (optionally) the fourth. While the key (first column) in the splunk_metadata file for non-CEF sources uses a \u201cvendor_product\u201d syntax that is arbitrary, the syntax for this key for CEF events is based on the actual contents of columns 1,2 and 4 from the CEF event, namely: device_vendor _ device_product _ device_class The final device_class portion is optional. Therefore, CEF entries in splunk_metadata can have a key representing the vendor and product, and others representing a vendor and product coupled with one or more additional classes. This allows for more granular metadata assignment (or overrides). Here is a snippet of a sample Imperva CEF event that includes a CEF device class entry (which is \u201cFirewall\u201d): Apr 19 10:29:53 3.3.3.3 CEF:0|Imperva Inc.|SecureSphere|12.0.0|Firewall|SSL Untraceable Connection|Medium| and the corresponding match in splunk_metadata.csv : Imperva Inc._SecureSphere_Firewall,sourcetype,imperva:waf:firewall:cef Default Sourcetype \u00b6 sourcetype notes cef Common sourcetype Default Source \u00b6 source notes Varies Varies Default Index Configuration \u00b6 key source index notes Vendor_Product Varies main none Filter type \u00b6 MSG Parse: This filter parses message content Options \u00b6 Variable default description SC4S_LISTEN_CEF_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_CEF_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_CEF_TLS_PORT empty string Enable a TLS port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_CEF no Enable archive to disk for this specific source SC4S_DEST_CEF_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=cef source=<asconfigured>)","title":"Common Event Format"},{"location":"sources/CommonEventFormat/#vendor-common-event-format-data-sources","text":"","title":"Vendor - Common Event Format Data Sources"},{"location":"sources/CommonEventFormat/#product-various-products-that-send-cef-format-messages-via-syslog","text":"Each CEF product should have their own source entry in this documentation set. In a departure from normal configuration, all CEF products should use the \u201cCEF\u201d version of the unique port and archive environment variable settings (rather than a unique one per product), as the CEF log path handles all products sending events to SC4S in the CEF format. Examples of this include Arcsight, Imperva, and Cyberark. Therefore, the CEF environment variables for unique port, archive, etc. should be set only once . If your deployment has multiple CEF devices that send to more than one port, set the CEF unique port variable(s) as a comma-separated list. See Unique Listening Ports for details. The source documentation included below is a reference baseline for any product that sends data using the CEF log path. Ref Link Splunk Add-on CEF https://bitbucket.org/SPLServices/ta-cef-for-splunk/downloads/ Product Manual https://docs.imperva.com/bundle/cloud-application-security/page/more/log-configuration.htm","title":"Product - Various products that send CEF-format messages via syslog"},{"location":"sources/CommonEventFormat/#splunk-metadata-with-cef-events","text":"The keys (first column) in splunk_metadata.csv for CEF data sources have a slightly different meaning than those for non-CEF ones. The typical vendor_product syntax is instead replaced by checks against specific columns of the CEF event \u2013 namely the first, second, and fourth columns following the leading CEF:0 (\u201ccolumn 0\u201d). These specific columns refer to the CEF device_vendor , device_product , and device_event_class , respectively. The third column, device_version , is not used for metadata assignment. SC4S sets metadata based on the first two columns, and (optionally) the fourth. While the key (first column) in the splunk_metadata file for non-CEF sources uses a \u201cvendor_product\u201d syntax that is arbitrary, the syntax for this key for CEF events is based on the actual contents of columns 1,2 and 4 from the CEF event, namely: device_vendor _ device_product _ device_class The final device_class portion is optional. Therefore, CEF entries in splunk_metadata can have a key representing the vendor and product, and others representing a vendor and product coupled with one or more additional classes. This allows for more granular metadata assignment (or overrides). Here is a snippet of a sample Imperva CEF event that includes a CEF device class entry (which is \u201cFirewall\u201d): Apr 19 10:29:53 3.3.3.3 CEF:0|Imperva Inc.|SecureSphere|12.0.0|Firewall|SSL Untraceable Connection|Medium| and the corresponding match in splunk_metadata.csv : Imperva Inc._SecureSphere_Firewall,sourcetype,imperva:waf:firewall:cef","title":"Splunk Metadata with CEF events"},{"location":"sources/CommonEventFormat/#default-sourcetype","text":"sourcetype notes cef Common sourcetype","title":"Default Sourcetype"},{"location":"sources/CommonEventFormat/#default-source","text":"source notes Varies Varies","title":"Default Source"},{"location":"sources/CommonEventFormat/#default-index-configuration","text":"key source index notes Vendor_Product Varies main none","title":"Default Index Configuration"},{"location":"sources/CommonEventFormat/#filter-type","text":"MSG Parse: This filter parses message content","title":"Filter type"},{"location":"sources/CommonEventFormat/#options","text":"Variable default description SC4S_LISTEN_CEF_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_CEF_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_CEF_TLS_PORT empty string Enable a TLS port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_CEF no Enable archive to disk for this specific source SC4S_DEST_CEF_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/CommonEventFormat/#verification","text":"An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=cef source=<asconfigured>)","title":"Verification"},{"location":"sources/CyberArk/","text":"Vendor - CyberArk \u00b6 Product - EPV \u00b6 Ref Link Splunk Add-on CyberArk https://splunkbase.splunk.com/app/2891/ Add-on Manual https://docs.splunk.com/Documentation/AddOns/latest/CyberArk/About Sourcetypes \u00b6 sourcetype notes cyberark:epv:cef None Index Configuration \u00b6 key sourcetype index notes CyberArk_Vault cyberark:epv:cef netauth none Filter type \u00b6 MSG Parse: This filter parses message content Options \u00b6 Variable default description SC4S_LISTEN_CEF_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers NOTE: Set only one set of CEF variables for the entire SC4S deployment, regardless of how many ports are in use by this CEF source (or any others). See the \u201cCommon Event Format\u201d source documentation for more information. Verification \u00b6 An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=cef sourcetype=\"cyberark:epv:cef\") Product - PTA \u00b6 Ref Link Splunk Add-on CyberArk https://splunkbase.splunk.com/app/2891/ Add-on Manual https://docs.splunk.com/Documentation/AddOns/latest/CyberArk/About Sourcetypes \u00b6 sourcetype notes cyberark:pta:cef None Index Configuration \u00b6 key sourcetype index notes Cyber-Ark_Vault cyberark:pta:cef main none Filter type \u00b6 MSG Parse: This filter parses message content Options \u00b6 Variable default description SC4S_LISTEN_CEF_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers NOTE: Set only one set of CEF variables for the entire SC4S deployment, regardless of how many ports are in use by this CEF source (or any others). See the \u201cCommon Event Format\u201d source documentation for more information. Verification \u00b6 An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=cef sourcetype=\"cyberark:pta:cef\")","title":"CyberArk"},{"location":"sources/CyberArk/#vendor-cyberark","text":"","title":"Vendor - CyberArk"},{"location":"sources/CyberArk/#product-epv","text":"Ref Link Splunk Add-on CyberArk https://splunkbase.splunk.com/app/2891/ Add-on Manual https://docs.splunk.com/Documentation/AddOns/latest/CyberArk/About","title":"Product - EPV"},{"location":"sources/CyberArk/#sourcetypes","text":"sourcetype notes cyberark:epv:cef None","title":"Sourcetypes"},{"location":"sources/CyberArk/#index-configuration","text":"key sourcetype index notes CyberArk_Vault cyberark:epv:cef netauth none","title":"Index Configuration"},{"location":"sources/CyberArk/#filter-type","text":"MSG Parse: This filter parses message content","title":"Filter type"},{"location":"sources/CyberArk/#options","text":"Variable default description SC4S_LISTEN_CEF_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers NOTE: Set only one set of CEF variables for the entire SC4S deployment, regardless of how many ports are in use by this CEF source (or any others). See the \u201cCommon Event Format\u201d source documentation for more information.","title":"Options"},{"location":"sources/CyberArk/#verification","text":"An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=cef sourcetype=\"cyberark:epv:cef\")","title":"Verification"},{"location":"sources/CyberArk/#product-pta","text":"Ref Link Splunk Add-on CyberArk https://splunkbase.splunk.com/app/2891/ Add-on Manual https://docs.splunk.com/Documentation/AddOns/latest/CyberArk/About","title":"Product - PTA"},{"location":"sources/CyberArk/#sourcetypes_1","text":"sourcetype notes cyberark:pta:cef None","title":"Sourcetypes"},{"location":"sources/CyberArk/#index-configuration_1","text":"key sourcetype index notes Cyber-Ark_Vault cyberark:pta:cef main none","title":"Index Configuration"},{"location":"sources/CyberArk/#filter-type_1","text":"MSG Parse: This filter parses message content","title":"Filter type"},{"location":"sources/CyberArk/#options_1","text":"Variable default description SC4S_LISTEN_CEF_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers NOTE: Set only one set of CEF variables for the entire SC4S deployment, regardless of how many ports are in use by this CEF source (or any others). See the \u201cCommon Event Format\u201d source documentation for more information.","title":"Options"},{"location":"sources/CyberArk/#verification_1","text":"An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=cef sourcetype=\"cyberark:pta:cef\")","title":"Verification"},{"location":"sources/Dell/","text":"Vendor - Dell \u00b6 Product - iDrac \u00b6 Ref Link Splunk Add-on na Add-on Manual https://www.dell.com/support/manuals/en-au/dell-opnmang-sw-v8.1/eemi_13g_v1.2-v1/introduction?guid=guid-8f22a1a9-ac01-43d1-a9d2-390ca6708d5e&lang=en-us Sourcetypes \u00b6 sourcetype notes dell:poweredge:idrac:syslog None Index Configuration \u00b6 key sourcetype index notes dell_poweredge_idrac dell:poweredge:idrac:syslog infraops none Filter type \u00b6 MSG Parse: This filter parses message content Options \u00b6 Variable default description SC4S_LISTEN_DELL_POWEREDGE_IDRAC_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_DELL_POWEREDGE_IDRAC_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers Verification \u00b6 An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=dell:poweredge:idrac:syslog sourcetype=\"UDP\") Product - CMC (VRTX) \u00b6 Ref Link Splunk Add-on na Add-on Manual https://www.dell.com/support/manuals/en-us/dell-chassis-management-controller-v3.10-dell-poweredge-vrtx/cmcvrtx31ug/overview?guid=guid-84595265-d37c-4765-8890-90f629737b17 Sourcetypes \u00b6 sourcetype notes dell:poweredge:cmc:syslog None Index Configuration \u00b6 key sourcetype index notes dell_poweredge_cmc dell:poweredge:cmc:syslog infraops none Filter type \u00b6 host or port Note: CMC devices will also forward idrac events which will be matched using the MSG parser above. Options \u00b6 Variable default description SC4S_LISTEN_DELL_POWEREDGE_CMC_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_DELL_POWEREDGE_CMC_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers Verification \u00b6 An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=dell:poweredge:cmc:syslog sourcetype=\"UDP\")","title":"Dell"},{"location":"sources/Dell/#vendor-dell","text":"","title":"Vendor - Dell"},{"location":"sources/Dell/#product-idrac","text":"Ref Link Splunk Add-on na Add-on Manual https://www.dell.com/support/manuals/en-au/dell-opnmang-sw-v8.1/eemi_13g_v1.2-v1/introduction?guid=guid-8f22a1a9-ac01-43d1-a9d2-390ca6708d5e&lang=en-us","title":"Product - iDrac"},{"location":"sources/Dell/#sourcetypes","text":"sourcetype notes dell:poweredge:idrac:syslog None","title":"Sourcetypes"},{"location":"sources/Dell/#index-configuration","text":"key sourcetype index notes dell_poweredge_idrac dell:poweredge:idrac:syslog infraops none","title":"Index Configuration"},{"location":"sources/Dell/#filter-type","text":"MSG Parse: This filter parses message content","title":"Filter type"},{"location":"sources/Dell/#options","text":"Variable default description SC4S_LISTEN_DELL_POWEREDGE_IDRAC_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_DELL_POWEREDGE_IDRAC_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers","title":"Options"},{"location":"sources/Dell/#verification","text":"An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=dell:poweredge:idrac:syslog sourcetype=\"UDP\")","title":"Verification"},{"location":"sources/Dell/#product-cmc-vrtx","text":"Ref Link Splunk Add-on na Add-on Manual https://www.dell.com/support/manuals/en-us/dell-chassis-management-controller-v3.10-dell-poweredge-vrtx/cmcvrtx31ug/overview?guid=guid-84595265-d37c-4765-8890-90f629737b17","title":"Product - CMC (VRTX)"},{"location":"sources/Dell/#sourcetypes_1","text":"sourcetype notes dell:poweredge:cmc:syslog None","title":"Sourcetypes"},{"location":"sources/Dell/#index-configuration_1","text":"key sourcetype index notes dell_poweredge_cmc dell:poweredge:cmc:syslog infraops none","title":"Index Configuration"},{"location":"sources/Dell/#filter-type_1","text":"host or port Note: CMC devices will also forward idrac events which will be matched using the MSG parser above.","title":"Filter type"},{"location":"sources/Dell/#options_1","text":"Variable default description SC4S_LISTEN_DELL_POWEREDGE_CMC_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_DELL_POWEREDGE_CMC_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers","title":"Options"},{"location":"sources/Dell/#verification_1","text":"An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=dell:poweredge:cmc:syslog sourcetype=\"UDP\")","title":"Verification"},{"location":"sources/Dell_EMC/","text":"Vendor - Dell EMC \u00b6 Product - Powerswitch N Series \u00b6 Ref Link Splunk Add-on None Product Manual unknown Sourcetypes \u00b6 sourcetype notes dell:emc:powerswitch:n None nix:syslog Non conforming messages Sourcetype and Index Configuration \u00b6 key sourcetype index notes dell_emc_powerswitch_n all netops none Filter type \u00b6 Message Format Setup and Configuration \u00b6 Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used the addon is not required on the indexer. Review and update the splunk_metadata.csv file and set the index and sourcetype as required for the data source. Refer to the admin manual for specific details of configuration Options \u00b6 Variable default description SC4S_LISTEN_DELL_DELL_EMC_POWERSWITCH_N_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_DELL_DELL_EMC_POWERSWITCH_N_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_DELL_DELL_EMC_POWERSWITCH_N no Enable archive to disk for this specific source SC4S_DEST_DELL_DELL_EMC_POWERSWITCH_N_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 An active device will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=dell:emc:powerswitch:n | stats count by host","title":"Dell EMC"},{"location":"sources/Dell_EMC/#vendor-dell-emc","text":"","title":"Vendor - Dell EMC"},{"location":"sources/Dell_EMC/#product-powerswitch-n-series","text":"Ref Link Splunk Add-on None Product Manual unknown","title":"Product - Powerswitch N Series"},{"location":"sources/Dell_EMC/#sourcetypes","text":"sourcetype notes dell:emc:powerswitch:n None nix:syslog Non conforming messages","title":"Sourcetypes"},{"location":"sources/Dell_EMC/#sourcetype-and-index-configuration","text":"key sourcetype index notes dell_emc_powerswitch_n all netops none","title":"Sourcetype and Index Configuration"},{"location":"sources/Dell_EMC/#filter-type","text":"Message Format","title":"Filter type"},{"location":"sources/Dell_EMC/#setup-and-configuration","text":"Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used the addon is not required on the indexer. Review and update the splunk_metadata.csv file and set the index and sourcetype as required for the data source. Refer to the admin manual for specific details of configuration","title":"Setup and Configuration"},{"location":"sources/Dell_EMC/#options","text":"Variable default description SC4S_LISTEN_DELL_DELL_EMC_POWERSWITCH_N_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_DELL_DELL_EMC_POWERSWITCH_N_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_DELL_DELL_EMC_POWERSWITCH_N no Enable archive to disk for this specific source SC4S_DEST_DELL_DELL_EMC_POWERSWITCH_N_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/Dell_EMC/#verification","text":"An active device will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=dell:emc:powerswitch:n | stats count by host","title":"Verification"},{"location":"sources/Dell_RSA/","text":"Vendor - Dell RSA \u00b6 Product - SecureID \u00b6 Ref Link Splunk Add-on https://splunkbase.splunk.com/app/2958/ Product Manual http://docs.splunk.com/Documentation/AddOns/latest/RSASecurID/About Sourcetypes \u00b6 sourcetype notes rsa:securid:syslog Catchall; used if a more specific source type can not be identified rsa:securid:admin:syslog None rsa:securid:runtime:syslog None nix:syslog None Sourcetype and Index Configuration \u00b6 key sourcetype index notes dell_rsa_secureid all netauth none dell_rsa_secureid nix:syslog osnix uses os_nix key of not configured bye host/ip/port Filter type \u00b6 Must be identified by host or ip assignment. Update the filter f_dell_rsa_secureid or configure a dedicated port as required NOTE: Java trace and exception will default to sc4s:fallback if the host/ip filter or port is not configured Setup and Configuration \u00b6 Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used the addon is not required on the indexer. Review and update the splunk_metadata.csv file and set the index and sourcetype as required for the data source. Refer to the admin manual for specific details of configuration Options \u00b6 Variable default description SC4S_LISTEN_DELL_RSA_SECUREID_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_DELL_RSA_SECUREID_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_DELL_RSA_SECUREID no Enable archive to disk for this specific source SC4S_DEST_DELL_RSA_SECUREID_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 An active device will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=DELL_RSA_SECUREID:*| stats count by host","title":"Dell RSA"},{"location":"sources/Dell_RSA/#vendor-dell-rsa","text":"","title":"Vendor - Dell RSA"},{"location":"sources/Dell_RSA/#product-secureid","text":"Ref Link Splunk Add-on https://splunkbase.splunk.com/app/2958/ Product Manual http://docs.splunk.com/Documentation/AddOns/latest/RSASecurID/About","title":"Product - SecureID"},{"location":"sources/Dell_RSA/#sourcetypes","text":"sourcetype notes rsa:securid:syslog Catchall; used if a more specific source type can not be identified rsa:securid:admin:syslog None rsa:securid:runtime:syslog None nix:syslog None","title":"Sourcetypes"},{"location":"sources/Dell_RSA/#sourcetype-and-index-configuration","text":"key sourcetype index notes dell_rsa_secureid all netauth none dell_rsa_secureid nix:syslog osnix uses os_nix key of not configured bye host/ip/port","title":"Sourcetype and Index Configuration"},{"location":"sources/Dell_RSA/#filter-type","text":"Must be identified by host or ip assignment. Update the filter f_dell_rsa_secureid or configure a dedicated port as required NOTE: Java trace and exception will default to sc4s:fallback if the host/ip filter or port is not configured","title":"Filter type"},{"location":"sources/Dell_RSA/#setup-and-configuration","text":"Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used the addon is not required on the indexer. Review and update the splunk_metadata.csv file and set the index and sourcetype as required for the data source. Refer to the admin manual for specific details of configuration","title":"Setup and Configuration"},{"location":"sources/Dell_RSA/#options","text":"Variable default description SC4S_LISTEN_DELL_RSA_SECUREID_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_DELL_RSA_SECUREID_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_DELL_RSA_SECUREID no Enable archive to disk for this specific source SC4S_DEST_DELL_RSA_SECUREID_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/Dell_RSA/#verification","text":"An active device will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=DELL_RSA_SECUREID:*| stats count by host","title":"Verification"},{"location":"sources/F5/","text":"Vendor - F5 \u00b6 Product - BigIP \u00b6 Ref Link Splunk Add-on https://splunkbase.splunk.com/app/2680/ Product Manual unknown Sourcetypes \u00b6 sourcetype notes f5:bigip:syslog None f5:bigip:irule None f5:bigip:ltm:http:irule None f5:bigip:gtm:dns:request:irule None f5:bigip:gtm:dns:response:irule None f5:bigip:ltm:failed:irule None f5:bigip:asm:syslog None nix:syslog None f5:bigip:ltm:access_json User defined configuration via irule producing a RFC5424 syslog event with json content within the message field <111>1 2020-05-28T22:48:15Z foo.example.com F5 - access_json - {\"event_type\":\"HTTP_REQUEST\", \"src_ip\":\"10.66.98.41\"} This source type requires a customer specific Splunk Add-on for utility value Index Configuration \u00b6 key index notes f5_bigip netops none f5_bigip_irule netops none f5_bigip_asm netwaf none f5_bigip_nix netops if f_f5_bigip is not set the index osnix will be used f5_bigip_access_json netops none Filter type \u00b6 MSGPARSE: sourcetypes with the exception of f5:bigip:syslog f5:bigip:syslog Must be identified by host or ip assignment. Update the vendor_product_by_source.conf filter f_f5_bigip or configure a dedicated port as required Setup and Configuration \u00b6 Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used, the addon is not required on the indexer. Review and update the splunk_metadata.csv file and set the index and sourcetype as required for the data source. Refer to the admin manual for specific details of configuration. Options \u00b6 Variable default description SC4S_LISTEN_F5_BIGIP_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_F5_BIGIP_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_F5_BIGIP no Enable archive to disk for this specific source SC4S_DEST_F5_BIGIP_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 An active device will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=f5:bigip:*| stats count by host","title":"F5"},{"location":"sources/F5/#vendor-f5","text":"","title":"Vendor - F5"},{"location":"sources/F5/#product-bigip","text":"Ref Link Splunk Add-on https://splunkbase.splunk.com/app/2680/ Product Manual unknown","title":"Product - BigIP"},{"location":"sources/F5/#sourcetypes","text":"sourcetype notes f5:bigip:syslog None f5:bigip:irule None f5:bigip:ltm:http:irule None f5:bigip:gtm:dns:request:irule None f5:bigip:gtm:dns:response:irule None f5:bigip:ltm:failed:irule None f5:bigip:asm:syslog None nix:syslog None f5:bigip:ltm:access_json User defined configuration via irule producing a RFC5424 syslog event with json content within the message field <111>1 2020-05-28T22:48:15Z foo.example.com F5 - access_json - {\"event_type\":\"HTTP_REQUEST\", \"src_ip\":\"10.66.98.41\"} This source type requires a customer specific Splunk Add-on for utility value","title":"Sourcetypes"},{"location":"sources/F5/#index-configuration","text":"key index notes f5_bigip netops none f5_bigip_irule netops none f5_bigip_asm netwaf none f5_bigip_nix netops if f_f5_bigip is not set the index osnix will be used f5_bigip_access_json netops none","title":"Index Configuration"},{"location":"sources/F5/#filter-type","text":"MSGPARSE: sourcetypes with the exception of f5:bigip:syslog f5:bigip:syslog Must be identified by host or ip assignment. Update the vendor_product_by_source.conf filter f_f5_bigip or configure a dedicated port as required","title":"Filter type"},{"location":"sources/F5/#setup-and-configuration","text":"Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used, the addon is not required on the indexer. Review and update the splunk_metadata.csv file and set the index and sourcetype as required for the data source. Refer to the admin manual for specific details of configuration.","title":"Setup and Configuration"},{"location":"sources/F5/#options","text":"Variable default description SC4S_LISTEN_F5_BIGIP_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_F5_BIGIP_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_F5_BIGIP no Enable archive to disk for this specific source SC4S_DEST_F5_BIGIP_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/F5/#verification","text":"An active device will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=f5:bigip:*| stats count by host","title":"Verification"},{"location":"sources/FireEye/","text":"Vendor - FireEye \u00b6 Product - CMS,eMPS, hx, etp \u00b6 Ref Link Technology Add-On for FireEye https://splunkbase.splunk.com/app/1904/ Sourcetypes \u00b6 sourcetype notes fe_cef_syslog hx_cef_syslog fe_etp source does not provide host name constant \u201cetp.fireeye.com\u201d is use regardless of region Index Configuration \u00b6 key sourcetype index notes FireEye_CMS fe_cef_syslog fireeye FireEye_ETP fe_etp fireeye FireEye_eMPS fe_cef_syslog fireeye fireeye_hx hx_cef_syslog fireeye Filter type \u00b6 MSG Parse: This filter parses message content Options \u00b6 Note: listed for reference; processing utilizes the Microsoft ArcSight log path as this format is a subtype of CEF Variable default description SC4S_LISTEN_CEF_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_CEF_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_CEF no Enable archive to disk for this specific source SC4S_DEST_CEF_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source NOTE: Set only one set of CEF variables for the entire SC4S deployment, regardless of how many ports are in use by this CEF source (or any others). See the \u201cCommon Event Format\u201d source documentation for more information. Verification \u00b6 An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=\"fe_cef_syslog\")","title":"FireEye"},{"location":"sources/FireEye/#vendor-fireeye","text":"","title":"Vendor - FireEye"},{"location":"sources/FireEye/#product-cmsemps-hx-etp","text":"Ref Link Technology Add-On for FireEye https://splunkbase.splunk.com/app/1904/","title":"Product - CMS,eMPS, hx, etp"},{"location":"sources/FireEye/#sourcetypes","text":"sourcetype notes fe_cef_syslog hx_cef_syslog fe_etp source does not provide host name constant \u201cetp.fireeye.com\u201d is use regardless of region","title":"Sourcetypes"},{"location":"sources/FireEye/#index-configuration","text":"key sourcetype index notes FireEye_CMS fe_cef_syslog fireeye FireEye_ETP fe_etp fireeye FireEye_eMPS fe_cef_syslog fireeye fireeye_hx hx_cef_syslog fireeye","title":"Index Configuration"},{"location":"sources/FireEye/#filter-type","text":"MSG Parse: This filter parses message content","title":"Filter type"},{"location":"sources/FireEye/#options","text":"Note: listed for reference; processing utilizes the Microsoft ArcSight log path as this format is a subtype of CEF Variable default description SC4S_LISTEN_CEF_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_CEF_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_CEF no Enable archive to disk for this specific source SC4S_DEST_CEF_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source NOTE: Set only one set of CEF variables for the entire SC4S deployment, regardless of how many ports are in use by this CEF source (or any others). See the \u201cCommon Event Format\u201d source documentation for more information.","title":"Options"},{"location":"sources/FireEye/#verification","text":"An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=\"fe_cef_syslog\")","title":"Verification"},{"location":"sources/Forcepoint/","text":"Vendor - Forcepoint \u00b6 Product - Webprotect (Websense) \u00b6 Ref Link Splunk Add-on https://splunkbase.splunk.com/app/2966/ Product Manual http://www.websense.com/content/support/library/web/v85/siem/siem.pdf Sourcetypes \u00b6 sourcetype notes websense:cg:kv None Sourcetype and Index Configuration \u00b6 key sourcetype index notes forcepoint_webprotect websense:cg:kv netproxy none Filter type \u00b6 MSG Parse: This filter parses message content Setup and Configuration \u00b6 Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used the addon is not required on the indexer. Review and update the splunk_metadata.csv file and set the index and sourcetype as required for the data source. Refer to the admin manual for specific details of configuration to send Reliable syslog using RFC 3195 format, a typical logging configuration will include the following features. Options \u00b6 Variable default description SC4S_LISTEN_FORCEPOINT_WEBPROTECT_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_FORCEPOINT_WEBPROTECT_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_FORCEPOINT_WEBPROTECT no Enable archive to disk for this specific source SC4S_DEST_FORCEPOINT_WEBPROTECT_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 An active proxy will generate frequent events, in addition WebProtect has the ability to test logging functionality using a built in command index=<asconfigured> sourcetype=websense:cg:kv","title":"Forcepoint"},{"location":"sources/Forcepoint/#vendor-forcepoint","text":"","title":"Vendor - Forcepoint"},{"location":"sources/Forcepoint/#product-webprotect-websense","text":"Ref Link Splunk Add-on https://splunkbase.splunk.com/app/2966/ Product Manual http://www.websense.com/content/support/library/web/v85/siem/siem.pdf","title":"Product - Webprotect (Websense)"},{"location":"sources/Forcepoint/#sourcetypes","text":"sourcetype notes websense:cg:kv None","title":"Sourcetypes"},{"location":"sources/Forcepoint/#sourcetype-and-index-configuration","text":"key sourcetype index notes forcepoint_webprotect websense:cg:kv netproxy none","title":"Sourcetype and Index Configuration"},{"location":"sources/Forcepoint/#filter-type","text":"MSG Parse: This filter parses message content","title":"Filter type"},{"location":"sources/Forcepoint/#setup-and-configuration","text":"Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used the addon is not required on the indexer. Review and update the splunk_metadata.csv file and set the index and sourcetype as required for the data source. Refer to the admin manual for specific details of configuration to send Reliable syslog using RFC 3195 format, a typical logging configuration will include the following features.","title":"Setup and Configuration"},{"location":"sources/Forcepoint/#options","text":"Variable default description SC4S_LISTEN_FORCEPOINT_WEBPROTECT_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_FORCEPOINT_WEBPROTECT_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_FORCEPOINT_WEBPROTECT no Enable archive to disk for this specific source SC4S_DEST_FORCEPOINT_WEBPROTECT_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/Forcepoint/#verification","text":"An active proxy will generate frequent events, in addition WebProtect has the ability to test logging functionality using a built in command index=<asconfigured> sourcetype=websense:cg:kv","title":"Verification"},{"location":"sources/Fortinet/","text":"Vendor - Fortinet \u00b6 Fortinet uses incorrect descriptions for syslog destinations in their documentation (conflicting with RFC standard definitions). When configuring a fortigate fortios device for TCP syslog, port 601 or an RFC6587 custom port must be used. UDP syslog should use the default port of 514. WARNING: Legacy Reliable (RFC3195) is not supported; this protocol is obsolete. Product - Fortigate \u00b6 Ref Link Splunk Add-on https://splunkbase.splunk.com/app/2846/ Product Manual https://docs.fortinet.com/product/fortigate/6.2 Sourcetypes \u00b6 sourcetype notes fgt_log Catch-all sourcetype; not used by the TA fgt_traffic None fgt_utm None fgt_event None Sourcetype and Index Configuration \u00b6 key sourcetype index notes fortinet_fortios_traffic fgt_traffic netfw none fortinet_fortios_utm fgt_utm netfw none fortinet_fortios_event fgt_event netops none fortinet_fortios_log fgt_log netops none Filter type \u00b6 MSG Parse: This filter parses message content Setup and Configuration \u00b6 Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used the addon is not required on the indexer. Review and update the splunk_metadata.csv file and set the index and sourcetype as required for the data source. Refer to the admin manual for specific details of configuration to send Reliable syslog using RFC 3195 format, a typical logging configuration will include the following features. config log memory filter set forward - traffic enable set local - traffic enable set sniffer - traffic disable set anomaly enable set voip disable set multicast - traffic enable set dns enable end config system global set cli - audit - log enable end config log setting set neighbor - event enable end Options \u00b6 NOTE: Remember to set the variable(s) below only once , regardless of how many unique ports and/or Fortinet device types are in use. See the introductory note above for more details. Variable default description SC4S_LISTEN_FORTINET_RFC6587_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_FORTINET_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_FORTINET no Enable archive to disk for this specific source SC4S_DEST_FORTINET_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source SC4S_OPTION_FORTINET_SOURCETYPE_PREFIX fgt Notice starting with version 1.6 of the fortinet add-on and app the sourcetype required changes from fgt_* to fortinet_* this is a breaking change to use the new sourcetype set this variable to fortigate in the env_file Verification \u00b6 An active firewall will generate frequent events, in addition fortigate has the ability to test logging functionality using a built in command diag log test Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=fgt_log OR sourcetype=fgt_traffic OR sourcetype=fgt_utm) UTM Message type \u00b6 Traffic Message Type \u00b6 Event Message Type \u00b6 Verify timestamp, and host values match as expected Product - FortiWeb \u00b6 Ref Link Splunk Add-on https://splunkbase.splunk.com/app/4679/ Product Manual https://docs.fortinet.com/product/fortiweb/6.3 Sourcetypes \u00b6 sourcetype notes fgt_log Catch-all sourcetype; not used by the TA fwb_traffic None fwb_attack None fwb_event None Sourcetype and Index Configuration \u00b6 key sourcetype index notes fortinet_fortiweb_traffic fwb_traffic netfw none fortinet_fortiweb_attack fwb_attack netids none fortinet_fortiweb_event fwb_event netops none fortinet_fortiweb_log fwb_log netops none Filter type \u00b6 MSG Parse: This filter parses message content Setup and Configuration \u00b6 Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used the addon is not required on the indexer. Review and update the splunk_metadata.csv file and set the index and sourcetype as required for the data source. Refer to the admin manual for specific details of configuration to send Reliable syslog using RFC 3195 format, a typical logging configuration will include the following features. config log syslog - policy edit splunk config syslog - server - list edit 1 set server x . x . x . x set port 514 ( Example . Should be the same as default or dedicated port selected for sc4s ) end end config log syslogd set policy splunk set status enable end Options \u00b6 NOTE: Remember to set the variable(s) below only once , regardless of how many unique ports and/or Fortinet device types are in use. See the introductory note above for more details. Variable default description SC4S_LISTEN_FORTINET_TCP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_FORTINET_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_FORTINET no Enable archive to disk for this specific source SC4S_DEST_FORTINET_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 An active firewall will generate frequent events, in addition fortigate has the ability to test logging functionality using a built in command diag log test Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=fwb_log OR sourcetype=fwb_traffic OR sourcetype=fwb_attack OR sourcetype=fwb_event) Verify timestamp, and host values match as expected","title":"Fortinet"},{"location":"sources/Fortinet/#vendor-fortinet","text":"Fortinet uses incorrect descriptions for syslog destinations in their documentation (conflicting with RFC standard definitions). When configuring a fortigate fortios device for TCP syslog, port 601 or an RFC6587 custom port must be used. UDP syslog should use the default port of 514. WARNING: Legacy Reliable (RFC3195) is not supported; this protocol is obsolete.","title":"Vendor - Fortinet"},{"location":"sources/Fortinet/#product-fortigate","text":"Ref Link Splunk Add-on https://splunkbase.splunk.com/app/2846/ Product Manual https://docs.fortinet.com/product/fortigate/6.2","title":"Product - Fortigate"},{"location":"sources/Fortinet/#sourcetypes","text":"sourcetype notes fgt_log Catch-all sourcetype; not used by the TA fgt_traffic None fgt_utm None fgt_event None","title":"Sourcetypes"},{"location":"sources/Fortinet/#sourcetype-and-index-configuration","text":"key sourcetype index notes fortinet_fortios_traffic fgt_traffic netfw none fortinet_fortios_utm fgt_utm netfw none fortinet_fortios_event fgt_event netops none fortinet_fortios_log fgt_log netops none","title":"Sourcetype and Index Configuration"},{"location":"sources/Fortinet/#filter-type","text":"MSG Parse: This filter parses message content","title":"Filter type"},{"location":"sources/Fortinet/#setup-and-configuration","text":"Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used the addon is not required on the indexer. Review and update the splunk_metadata.csv file and set the index and sourcetype as required for the data source. Refer to the admin manual for specific details of configuration to send Reliable syslog using RFC 3195 format, a typical logging configuration will include the following features. config log memory filter set forward - traffic enable set local - traffic enable set sniffer - traffic disable set anomaly enable set voip disable set multicast - traffic enable set dns enable end config system global set cli - audit - log enable end config log setting set neighbor - event enable end","title":"Setup and Configuration"},{"location":"sources/Fortinet/#options","text":"NOTE: Remember to set the variable(s) below only once , regardless of how many unique ports and/or Fortinet device types are in use. See the introductory note above for more details. Variable default description SC4S_LISTEN_FORTINET_RFC6587_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_FORTINET_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_FORTINET no Enable archive to disk for this specific source SC4S_DEST_FORTINET_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source SC4S_OPTION_FORTINET_SOURCETYPE_PREFIX fgt Notice starting with version 1.6 of the fortinet add-on and app the sourcetype required changes from fgt_* to fortinet_* this is a breaking change to use the new sourcetype set this variable to fortigate in the env_file","title":"Options"},{"location":"sources/Fortinet/#verification","text":"An active firewall will generate frequent events, in addition fortigate has the ability to test logging functionality using a built in command diag log test Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=fgt_log OR sourcetype=fgt_traffic OR sourcetype=fgt_utm)","title":"Verification"},{"location":"sources/Fortinet/#utm-message-type","text":"","title":"UTM Message type"},{"location":"sources/Fortinet/#traffic-message-type","text":"","title":"Traffic Message Type"},{"location":"sources/Fortinet/#event-message-type","text":"Verify timestamp, and host values match as expected","title":"Event Message Type"},{"location":"sources/Fortinet/#product-fortiweb","text":"Ref Link Splunk Add-on https://splunkbase.splunk.com/app/4679/ Product Manual https://docs.fortinet.com/product/fortiweb/6.3","title":"Product - FortiWeb"},{"location":"sources/Fortinet/#sourcetypes_1","text":"sourcetype notes fgt_log Catch-all sourcetype; not used by the TA fwb_traffic None fwb_attack None fwb_event None","title":"Sourcetypes"},{"location":"sources/Fortinet/#sourcetype-and-index-configuration_1","text":"key sourcetype index notes fortinet_fortiweb_traffic fwb_traffic netfw none fortinet_fortiweb_attack fwb_attack netids none fortinet_fortiweb_event fwb_event netops none fortinet_fortiweb_log fwb_log netops none","title":"Sourcetype and Index Configuration"},{"location":"sources/Fortinet/#filter-type_1","text":"MSG Parse: This filter parses message content","title":"Filter type"},{"location":"sources/Fortinet/#setup-and-configuration_1","text":"Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used the addon is not required on the indexer. Review and update the splunk_metadata.csv file and set the index and sourcetype as required for the data source. Refer to the admin manual for specific details of configuration to send Reliable syslog using RFC 3195 format, a typical logging configuration will include the following features. config log syslog - policy edit splunk config syslog - server - list edit 1 set server x . x . x . x set port 514 ( Example . Should be the same as default or dedicated port selected for sc4s ) end end config log syslogd set policy splunk set status enable end","title":"Setup and Configuration"},{"location":"sources/Fortinet/#options_1","text":"NOTE: Remember to set the variable(s) below only once , regardless of how many unique ports and/or Fortinet device types are in use. See the introductory note above for more details. Variable default description SC4S_LISTEN_FORTINET_TCP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_FORTINET_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_FORTINET no Enable archive to disk for this specific source SC4S_DEST_FORTINET_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/Fortinet/#verification_1","text":"An active firewall will generate frequent events, in addition fortigate has the ability to test logging functionality using a built in command diag log test Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=fwb_log OR sourcetype=fwb_traffic OR sourcetype=fwb_attack OR sourcetype=fwb_event) Verify timestamp, and host values match as expected","title":"Verification"},{"location":"sources/HAProxy/","text":"Vendor - HAProxy \u00b6 Product \u00b6 Ref Link Splunk Add-on https://splunkbase.splunk.com/app/3135/ Sourcetypes \u00b6 sourcetype notes haproxy:tcp Default syslog format haproxy:splunk:http Splunk\u2019s documented custom format. Note: detection is based on client_ip prefix in message Index Configuration \u00b6 key index notes haproxy_syslog netlb none Filter type \u00b6 MSG Parse: This filter parses message content Options \u00b6 Variable default description SC4S_LISTEN_HAPROXY_SYSLOG_RFC6587_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_HAPROXY_SYSLOG_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_HAPROXY_SYSLOG no Enable archive to disk for this specific source SC4S_DEST_HAPROXY_SYSLOG_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=haproxy*\")","title":"HAProxy"},{"location":"sources/HAProxy/#vendor-haproxy","text":"","title":"Vendor - HAProxy"},{"location":"sources/HAProxy/#product","text":"Ref Link Splunk Add-on https://splunkbase.splunk.com/app/3135/","title":"Product"},{"location":"sources/HAProxy/#sourcetypes","text":"sourcetype notes haproxy:tcp Default syslog format haproxy:splunk:http Splunk\u2019s documented custom format. Note: detection is based on client_ip prefix in message","title":"Sourcetypes"},{"location":"sources/HAProxy/#index-configuration","text":"key index notes haproxy_syslog netlb none","title":"Index Configuration"},{"location":"sources/HAProxy/#filter-type","text":"MSG Parse: This filter parses message content","title":"Filter type"},{"location":"sources/HAProxy/#options","text":"Variable default description SC4S_LISTEN_HAPROXY_SYSLOG_RFC6587_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_HAPROXY_SYSLOG_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_HAPROXY_SYSLOG no Enable archive to disk for this specific source SC4S_DEST_HAPROXY_SYSLOG_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/HAProxy/#verification","text":"An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=haproxy*\")","title":"Verification"},{"location":"sources/HPe/","text":"Vendor - HPE \u00b6 Product - Aruba devices \u00b6 Ref Link Sourcetypes \u00b6 sourcetype notes aruba:syslog Dynamically Created Index Configuration \u00b6 key index notes aruba_ap netops none Filter type \u00b6 Partial MSG Parse for BSD-style (non-CEF) messages: This filter parses message content for events that use the traditional aruba (BSD) message format that have program values of authmgr , sapd , stm , or wms . Additional os:nix logs for generic services such as dnsmasq will follow the os:nix rules. Options \u00b6 Variable default description SC4S_LISTEN_ARUBA_AP_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_ARUBA_AP_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_ARUBA_AP no Enable archive to disk for this specific source SC4S_DEST_ARUBA_AP_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=aruba:syslog\") Product - Aruba Clearpass \u00b6 Ref Link Sourcetypes \u00b6 sourcetype notes aruba:clearpass Dynamically Created Index Configuration \u00b6 key index notes aruba_clearpass print none Filter type \u00b6 Partial MSG Parse: This filter parses message content for events with a syslog \u201cprogram\u201d prefix \u201cCPPM_\u201d. For complete parsing a dedicated port or vendor_product_by_source entry must be added. Options \u00b6 Variable default description SC4S_LISTEN_ARUBA_CLEARPASS_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_ARUBA_CLEARPASS_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_ARUBA_CLEARPASS no Enable archive to disk for this specific source SC4S_DEST_ARUBA_CLEARPASS_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=aruba:clearpass\") Product - JetDirect \u00b6 Ref Link Sourcetypes \u00b6 sourcetype notes hpe:jetdirect none Index Configuration \u00b6 key index notes hpe_jetdirect print none Filter type \u00b6 MSG Parse: This filter parses message content Options \u00b6 Note listed for reference processing utilizes the Microsoft ArcSight log path as this format is a subtype of CEF Variable default description SC4S_LISTEN_HPE_JETDIRECT_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_HPE_JETDIRECT_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_HPE_JETDIRECT no Enable archive to disk for this specific source SC4S_DEST_HPE_JETDIRECT_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=hpe:jetdirect\")","title":"HPe"},{"location":"sources/HPe/#vendor-hpe","text":"","title":"Vendor - HPE"},{"location":"sources/HPe/#product-aruba-devices","text":"Ref Link","title":"Product - Aruba devices"},{"location":"sources/HPe/#sourcetypes","text":"sourcetype notes aruba:syslog Dynamically Created","title":"Sourcetypes"},{"location":"sources/HPe/#index-configuration","text":"key index notes aruba_ap netops none","title":"Index Configuration"},{"location":"sources/HPe/#filter-type","text":"Partial MSG Parse for BSD-style (non-CEF) messages: This filter parses message content for events that use the traditional aruba (BSD) message format that have program values of authmgr , sapd , stm , or wms . Additional os:nix logs for generic services such as dnsmasq will follow the os:nix rules.","title":"Filter type"},{"location":"sources/HPe/#options","text":"Variable default description SC4S_LISTEN_ARUBA_AP_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_ARUBA_AP_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_ARUBA_AP no Enable archive to disk for this specific source SC4S_DEST_ARUBA_AP_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/HPe/#verification","text":"An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=aruba:syslog\")","title":"Verification"},{"location":"sources/HPe/#product-aruba-clearpass","text":"Ref Link","title":"Product - Aruba Clearpass"},{"location":"sources/HPe/#sourcetypes_1","text":"sourcetype notes aruba:clearpass Dynamically Created","title":"Sourcetypes"},{"location":"sources/HPe/#index-configuration_1","text":"key index notes aruba_clearpass print none","title":"Index Configuration"},{"location":"sources/HPe/#filter-type_1","text":"Partial MSG Parse: This filter parses message content for events with a syslog \u201cprogram\u201d prefix \u201cCPPM_\u201d. For complete parsing a dedicated port or vendor_product_by_source entry must be added.","title":"Filter type"},{"location":"sources/HPe/#options_1","text":"Variable default description SC4S_LISTEN_ARUBA_CLEARPASS_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_ARUBA_CLEARPASS_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_ARUBA_CLEARPASS no Enable archive to disk for this specific source SC4S_DEST_ARUBA_CLEARPASS_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/HPe/#verification_1","text":"An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=aruba:clearpass\")","title":"Verification"},{"location":"sources/HPe/#product-jetdirect","text":"Ref Link","title":"Product - JetDirect"},{"location":"sources/HPe/#sourcetypes_2","text":"sourcetype notes hpe:jetdirect none","title":"Sourcetypes"},{"location":"sources/HPe/#index-configuration_2","text":"key index notes hpe_jetdirect print none","title":"Index Configuration"},{"location":"sources/HPe/#filter-type_2","text":"MSG Parse: This filter parses message content","title":"Filter type"},{"location":"sources/HPe/#options_2","text":"Note listed for reference processing utilizes the Microsoft ArcSight log path as this format is a subtype of CEF Variable default description SC4S_LISTEN_HPE_JETDIRECT_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_HPE_JETDIRECT_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_HPE_JETDIRECT no Enable archive to disk for this specific source SC4S_DEST_HPE_JETDIRECT_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/HPe/#verification_2","text":"An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=hpe:jetdirect\")","title":"Verification"},{"location":"sources/ISC/","text":"Vendor - ISC \u00b6 Product - dns \u00b6 This source type is often re-implemented by specific add-ons such as infoblox or bluecat if a more specific source type is desired see that source documentation for instructions Ref Link Splunk Add-on https://splunkbase.splunk.com/app/2876/ Sourcetypes \u00b6 sourcetype notes isc:dhcp none Index Configuration \u00b6 key index notes isc_dhcp isc:dhcp none Filter type \u00b6 MSG Parse: This filter parses message content Options \u00b6 None Verification \u00b6 An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=isc:dhcp\") Product - DHCPD \u00b6 This source type is often re-implemented by specific add-ons such as infoblox or bluecat if a more specific source type is desired see that source documentation for instructions Ref Link Splunk Add-on https://splunkbase.splunk.com/app/3010/ Sourcetypes \u00b6 sourcetype notes isc:dhcp none Index Configuration \u00b6 key index notes isc_dhcp isc:dhcp none Filter type \u00b6 MSG Parse: This filter parses message content Options \u00b6 None Verification \u00b6 An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=isc:dhcp\")","title":"ISC"},{"location":"sources/ISC/#vendor-isc","text":"","title":"Vendor - ISC"},{"location":"sources/ISC/#product-dns","text":"This source type is often re-implemented by specific add-ons such as infoblox or bluecat if a more specific source type is desired see that source documentation for instructions Ref Link Splunk Add-on https://splunkbase.splunk.com/app/2876/","title":"Product - dns"},{"location":"sources/ISC/#sourcetypes","text":"sourcetype notes isc:dhcp none","title":"Sourcetypes"},{"location":"sources/ISC/#index-configuration","text":"key index notes isc_dhcp isc:dhcp none","title":"Index Configuration"},{"location":"sources/ISC/#filter-type","text":"MSG Parse: This filter parses message content","title":"Filter type"},{"location":"sources/ISC/#options","text":"None","title":"Options"},{"location":"sources/ISC/#verification","text":"An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=isc:dhcp\")","title":"Verification"},{"location":"sources/ISC/#product-dhcpd","text":"This source type is often re-implemented by specific add-ons such as infoblox or bluecat if a more specific source type is desired see that source documentation for instructions Ref Link Splunk Add-on https://splunkbase.splunk.com/app/3010/","title":"Product - DHCPD"},{"location":"sources/ISC/#sourcetypes_1","text":"sourcetype notes isc:dhcp none","title":"Sourcetypes"},{"location":"sources/ISC/#index-configuration_1","text":"key index notes isc_dhcp isc:dhcp none","title":"Index Configuration"},{"location":"sources/ISC/#filter-type_1","text":"MSG Parse: This filter parses message content","title":"Filter type"},{"location":"sources/ISC/#options_1","text":"None","title":"Options"},{"location":"sources/ISC/#verification_1","text":"An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=isc:dhcp\")","title":"Verification"},{"location":"sources/Imperva/","text":"Vendor - Imperva \u00b6 Product - Incapsula \u00b6 Ref Link Splunk Add-on CEF https://bitbucket.org/SPLServices/ta-cef-for-splunk/downloads/ Splunk Add-on Source Specific https://bitbucket.org/SPLServices/ta-cef-imperva-incapsula/downloads/ Product Manual https://docs.imperva.com/bundle/cloud-application-security/page/more/log-configuration.htm Sourcetypes \u00b6 sourcetype notes cef Common sourcetype Source \u00b6 sourcetype notes Imperva:Incapsula Common sourcetype Index Configuration \u00b6 key source index notes Incapsula_SIEMintegration Imperva:Incapsula netwaf none Filter type \u00b6 MSG Parse: This filter parses message content Options \u00b6 Note listed for reference processing utilizes the Microsoft ArcSight log path as this format is a subtype of CEF Variable default description SC4S_LISTEN_CEF_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_CEF_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_CEF no Enable archive to disk for this specific source SC4S_DEST_CEF_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source NOTE: Set only one set of CEF variables for the entire SC4S deployment, regardless of how many ports are in use by this CEF source (or any others). See the \u201cCommon Event Format\u201d source documentation for more information. Verification \u00b6 An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=cef source=\"Imperva:Incapsula\") Product - On-Premises WAF (SecureSphere WAF) \u00b6 Ref Link Splunk Add-on https://splunkbase.splunk.com/app/2874/ Product Manual https://community.microfocus.com/dcvta86296/attachments/dcvta86296/partner-documentation-h-o/22/2/Imperva_SecureSphere_11_5_CEF_Config_Guide_2018.pdf Sourcetypes \u00b6 sourcetype notes imperva:waf none imperva:waf:firewall:cef none imperva:waf:security:cef none Index Configuration \u00b6 key index notes Imperva Inc._SecureSphere netwaf none Filter type \u00b6 MSG Parse: This filter parses message content Options \u00b6 Variable default description SC4S_LISTEN_CEF_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_CEF_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_CEF no Enable archive to disk for this specific source SC4S_DEST_CEF_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source NOTE: Set only one set of CEF variables for the entire SC4S deployment, regardless of how many ports are in use by this CEF source (or any others). See the \u201cCommon Event Format\u201d source documentation for more information. Verification \u00b6 An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=imperva:waf*)","title":"Imperva"},{"location":"sources/Imperva/#vendor-imperva","text":"","title":"Vendor - Imperva"},{"location":"sources/Imperva/#product-incapsula","text":"Ref Link Splunk Add-on CEF https://bitbucket.org/SPLServices/ta-cef-for-splunk/downloads/ Splunk Add-on Source Specific https://bitbucket.org/SPLServices/ta-cef-imperva-incapsula/downloads/ Product Manual https://docs.imperva.com/bundle/cloud-application-security/page/more/log-configuration.htm","title":"Product - Incapsula"},{"location":"sources/Imperva/#sourcetypes","text":"sourcetype notes cef Common sourcetype","title":"Sourcetypes"},{"location":"sources/Imperva/#source","text":"sourcetype notes Imperva:Incapsula Common sourcetype","title":"Source"},{"location":"sources/Imperva/#index-configuration","text":"key source index notes Incapsula_SIEMintegration Imperva:Incapsula netwaf none","title":"Index Configuration"},{"location":"sources/Imperva/#filter-type","text":"MSG Parse: This filter parses message content","title":"Filter type"},{"location":"sources/Imperva/#options","text":"Note listed for reference processing utilizes the Microsoft ArcSight log path as this format is a subtype of CEF Variable default description SC4S_LISTEN_CEF_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_CEF_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_CEF no Enable archive to disk for this specific source SC4S_DEST_CEF_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source NOTE: Set only one set of CEF variables for the entire SC4S deployment, regardless of how many ports are in use by this CEF source (or any others). See the \u201cCommon Event Format\u201d source documentation for more information.","title":"Options"},{"location":"sources/Imperva/#verification","text":"An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=cef source=\"Imperva:Incapsula\")","title":"Verification"},{"location":"sources/Imperva/#product-on-premises-waf-securesphere-waf","text":"Ref Link Splunk Add-on https://splunkbase.splunk.com/app/2874/ Product Manual https://community.microfocus.com/dcvta86296/attachments/dcvta86296/partner-documentation-h-o/22/2/Imperva_SecureSphere_11_5_CEF_Config_Guide_2018.pdf","title":"Product - On-Premises WAF (SecureSphere WAF)"},{"location":"sources/Imperva/#sourcetypes_1","text":"sourcetype notes imperva:waf none imperva:waf:firewall:cef none imperva:waf:security:cef none","title":"Sourcetypes"},{"location":"sources/Imperva/#index-configuration_1","text":"key index notes Imperva Inc._SecureSphere netwaf none","title":"Index Configuration"},{"location":"sources/Imperva/#filter-type_1","text":"MSG Parse: This filter parses message content","title":"Filter type"},{"location":"sources/Imperva/#options_1","text":"Variable default description SC4S_LISTEN_CEF_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_CEF_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_CEF no Enable archive to disk for this specific source SC4S_DEST_CEF_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source NOTE: Set only one set of CEF variables for the entire SC4S deployment, regardless of how many ports are in use by this CEF source (or any others). See the \u201cCommon Event Format\u201d source documentation for more information.","title":"Options"},{"location":"sources/Imperva/#verification_1","text":"An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=imperva:waf*)","title":"Verification"},{"location":"sources/InfoBlox/","text":"Vendor - Infoblox \u00b6 Warning: Despite the TA indication this data source is CIM compliant the all versions of NIOS including the most recent available as of 2019-12-17 do not support the DNS data model correctly. For DNS security use cases use Splunk Stream instead. Product - NIOS \u00b6 Ref Link Splunk Add-on https://splunkbase.splunk.com/app/2934/ Product Manual https://docs.infoblox.com/display/ILP/NIOS?preview=/8945695/43728387/NIOS_8.4_Admin_Guide.pdf Sourcetypes \u00b6 sourcetype notes infoblox:dns None infoblox:dhcp None infoblox:threat None nix:syslog None Sourcetype and Index Configuration \u00b6 key sourcetype index notes infoblox_dns infoblox:dns netdns none infoblox_dhcp infoblox:dhcp netipam none infoblox_threat infoblox:threatprotect netids none infoblox_audit infoblox:audit netops none infoblox_fallback infoblox:port netops none Filter type \u00b6 Must be identified by host or ip assignment. Update the filter f_infoblox or configure a dedicated port as required Setup and Configuration \u00b6 Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used the addon is not required on the indexer. Review and update the splunk_metadata.csv file and set the index and sourcetype as required for the data source. Refer to the admin manual for specific details of configuration Options \u00b6 Variable default description SC4S_LISTEN_INFOBLOX_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_INFOBLOX_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_INFOBLOX no Enable archive to disk for this specific source SC4S_DEST_INFOBLOX_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 An active device will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=infoblox:*| stats count by host","title":"InfoBlox"},{"location":"sources/InfoBlox/#vendor-infoblox","text":"Warning: Despite the TA indication this data source is CIM compliant the all versions of NIOS including the most recent available as of 2019-12-17 do not support the DNS data model correctly. For DNS security use cases use Splunk Stream instead.","title":"Vendor - Infoblox"},{"location":"sources/InfoBlox/#product-nios","text":"Ref Link Splunk Add-on https://splunkbase.splunk.com/app/2934/ Product Manual https://docs.infoblox.com/display/ILP/NIOS?preview=/8945695/43728387/NIOS_8.4_Admin_Guide.pdf","title":"Product - NIOS"},{"location":"sources/InfoBlox/#sourcetypes","text":"sourcetype notes infoblox:dns None infoblox:dhcp None infoblox:threat None nix:syslog None","title":"Sourcetypes"},{"location":"sources/InfoBlox/#sourcetype-and-index-configuration","text":"key sourcetype index notes infoblox_dns infoblox:dns netdns none infoblox_dhcp infoblox:dhcp netipam none infoblox_threat infoblox:threatprotect netids none infoblox_audit infoblox:audit netops none infoblox_fallback infoblox:port netops none","title":"Sourcetype and Index Configuration"},{"location":"sources/InfoBlox/#filter-type","text":"Must be identified by host or ip assignment. Update the filter f_infoblox or configure a dedicated port as required","title":"Filter type"},{"location":"sources/InfoBlox/#setup-and-configuration","text":"Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used the addon is not required on the indexer. Review and update the splunk_metadata.csv file and set the index and sourcetype as required for the data source. Refer to the admin manual for specific details of configuration","title":"Setup and Configuration"},{"location":"sources/InfoBlox/#options","text":"Variable default description SC4S_LISTEN_INFOBLOX_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_INFOBLOX_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_INFOBLOX no Enable archive to disk for this specific source SC4S_DEST_INFOBLOX_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/InfoBlox/#verification","text":"An active device will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=infoblox:*| stats count by host","title":"Verification"},{"location":"sources/Juniper/","text":"Vendor - Juniper \u00b6 Product - Juniper JunOS \u00b6 Ref Link Splunk Add-on https://splunkbase.splunk.com/app/2847/ JunOS TechLibrary https://www.juniper.net/documentation/en_US/junos/topics/example/syslog-messages-configuring-qfx-series.html Sourcetypes \u00b6 sourcetype notes juniper:junos:firewall None juniper:junos:firewall:structured None juniper:junos:idp None juniper:junos:idp:structured None juniper:junos:aamw:structured None juniper:junos:secintel:structured None juniper:junos:snmp None Sourcetype and Index Configuration \u00b6 key sourcetype index notes juniper_junos_flow juniper:junos:firewall netfw none juniper_junos_idp juniper:junos:idp netids none juniper_junos_utm juniper:junos:firewall netfw none Filter type \u00b6 MSG Parse: This filter parses message content Setup and Configuration \u00b6 Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used the addon is not required on the indexer. Review and update the splunk_metadata.csv file and set the index as required. Follow vendor configuration steps per referenced Product Manual Options \u00b6 Variable default description SC4S_LISTEN_JUNIPER_JUNOS_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers using legacy 3164 format SC4S_LISTEN_JUNIPER_JUNOS_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers using legacy 3164 format SC4S_LISTEN_JUNIPER_JUNOS_TLS_PORT empty string Enable a TLS port for this specific vendor product using a comma-separated list of port numbers using legacy 3164 format SC4S_LISTEN_JUNIPER_JUNOS_STRUCTURED_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers using 5424 format SC4S_LISTEN_JUNIPER_JUNOS_STRUCTURED_TLS_PORT empty string Enable a TLS port for this specific vendor product using a comma-separated list of port numbers using 5424 format SC4S_DEST_JUNIPER_JUNOS_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 Use the following search to validate events are present; for Juniper JunOS ensure each host filter condition is verified index=<asconfigured> sourcetype=juniper:junos:firewall | stats count by host index=<asconfigured> sourcetype=juniper:junos:idp | stats count by host Verify timestamp, and host values match as expected Product - Juniper Netscreen \u00b6 Ref Link Splunk Add-on https://splunkbase.splunk.com/app/2847/ Netscreen Manual http://kb.juniper.net/InfoCenter/index?page=content&id=KB4759 Sourcetypes \u00b6 sourcetype notes netscreen:firewall None Sourcetype and Index Configuration \u00b6 key sourcetype index notes juniper_netscreen netscreen:firewall netfw none Filter type \u00b6 Juniper Netscreen products must be identified by host or ip assignment. Update the filter f_juniper_netscreen as required Setup and Configuration \u00b6 Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used the addon is not required on the indexer. Review and update the splunk_metadata.csv file and set the index as required. Follow vendor configuration steps per Product Manual Options \u00b6 Variable default description SC4S_LISTEN_JUNIPER_NETSCREEN_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_JUNIPER_NETSCREEN_TLS_PORT empty string Enable a TLS port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_JUNIPER_NETSCREEN_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_JUNIPER_NETSCREEN no Enable archive to disk for this specific source SC4S_DEST_JUNIPER_NETSCREEN_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 Use the following search to validate events are present; for Juniper Netscreen products ensure each host filter condition is verified index=<asconfigured> sourcetype=netscreen:firewall | stats count by host Verify timestamp, and host values match as expected","title":"Juniper"},{"location":"sources/Juniper/#vendor-juniper","text":"","title":"Vendor - Juniper"},{"location":"sources/Juniper/#product-juniper-junos","text":"Ref Link Splunk Add-on https://splunkbase.splunk.com/app/2847/ JunOS TechLibrary https://www.juniper.net/documentation/en_US/junos/topics/example/syslog-messages-configuring-qfx-series.html","title":"Product - Juniper JunOS"},{"location":"sources/Juniper/#sourcetypes","text":"sourcetype notes juniper:junos:firewall None juniper:junos:firewall:structured None juniper:junos:idp None juniper:junos:idp:structured None juniper:junos:aamw:structured None juniper:junos:secintel:structured None juniper:junos:snmp None","title":"Sourcetypes"},{"location":"sources/Juniper/#sourcetype-and-index-configuration","text":"key sourcetype index notes juniper_junos_flow juniper:junos:firewall netfw none juniper_junos_idp juniper:junos:idp netids none juniper_junos_utm juniper:junos:firewall netfw none","title":"Sourcetype and Index Configuration"},{"location":"sources/Juniper/#filter-type","text":"MSG Parse: This filter parses message content","title":"Filter type"},{"location":"sources/Juniper/#setup-and-configuration","text":"Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used the addon is not required on the indexer. Review and update the splunk_metadata.csv file and set the index as required. Follow vendor configuration steps per referenced Product Manual","title":"Setup and Configuration"},{"location":"sources/Juniper/#options","text":"Variable default description SC4S_LISTEN_JUNIPER_JUNOS_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers using legacy 3164 format SC4S_LISTEN_JUNIPER_JUNOS_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers using legacy 3164 format SC4S_LISTEN_JUNIPER_JUNOS_TLS_PORT empty string Enable a TLS port for this specific vendor product using a comma-separated list of port numbers using legacy 3164 format SC4S_LISTEN_JUNIPER_JUNOS_STRUCTURED_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers using 5424 format SC4S_LISTEN_JUNIPER_JUNOS_STRUCTURED_TLS_PORT empty string Enable a TLS port for this specific vendor product using a comma-separated list of port numbers using 5424 format SC4S_DEST_JUNIPER_JUNOS_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/Juniper/#verification","text":"Use the following search to validate events are present; for Juniper JunOS ensure each host filter condition is verified index=<asconfigured> sourcetype=juniper:junos:firewall | stats count by host index=<asconfigured> sourcetype=juniper:junos:idp | stats count by host Verify timestamp, and host values match as expected","title":"Verification"},{"location":"sources/Juniper/#product-juniper-netscreen","text":"Ref Link Splunk Add-on https://splunkbase.splunk.com/app/2847/ Netscreen Manual http://kb.juniper.net/InfoCenter/index?page=content&id=KB4759","title":"Product - Juniper Netscreen"},{"location":"sources/Juniper/#sourcetypes_1","text":"sourcetype notes netscreen:firewall None","title":"Sourcetypes"},{"location":"sources/Juniper/#sourcetype-and-index-configuration_1","text":"key sourcetype index notes juniper_netscreen netscreen:firewall netfw none","title":"Sourcetype and Index Configuration"},{"location":"sources/Juniper/#filter-type_1","text":"Juniper Netscreen products must be identified by host or ip assignment. Update the filter f_juniper_netscreen as required","title":"Filter type"},{"location":"sources/Juniper/#setup-and-configuration_1","text":"Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used the addon is not required on the indexer. Review and update the splunk_metadata.csv file and set the index as required. Follow vendor configuration steps per Product Manual","title":"Setup and Configuration"},{"location":"sources/Juniper/#options_1","text":"Variable default description SC4S_LISTEN_JUNIPER_NETSCREEN_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_JUNIPER_NETSCREEN_TLS_PORT empty string Enable a TLS port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_JUNIPER_NETSCREEN_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_JUNIPER_NETSCREEN no Enable archive to disk for this specific source SC4S_DEST_JUNIPER_NETSCREEN_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/Juniper/#verification_1","text":"Use the following search to validate events are present; for Juniper Netscreen products ensure each host filter condition is verified index=<asconfigured> sourcetype=netscreen:firewall | stats count by host Verify timestamp, and host values match as expected","title":"Verification"},{"location":"sources/LogExtendedEventFormat/","text":"Vendor - Log Extended Event Format \u00b6 Product - Various products that send LEEF V1 and V2 format messages via syslog \u00b6 Each LEEF product should have their own source entry in this documentation set by vendor. In a departure from normal configuration, all LEEF products should use the \u201cLEEF\u201d version of the unique port and archive environment variable settings (rather than a unique one per product), as the LEEF log path handles all products sending events to SC4S in the LEEF format. Examples of this include QRadar itself as well as other legacy systems. Therefore, the LEEF environment variables for unique port, archive, etc. should be set only once . If your deployment has multiple LEEF devices that send to more than one port, set the LEEF unique port variable(s) as a comma-separated list. See Unique Listening Ports for details. The source documentation included below is a reference baseline for any product that sends data using the LEEF log path. Some vendors implement LEEF v2.0 format events incorrectly, omitting the required \u201ckey=value\u201d seperator field from the LEEF header, thus forcing the consumer to assume the default tab \\t character. SC4S will correctly process this omission, but will not correctly process other non-compliant formats. The LEEF format allows for the inclusion of a field devTime containing the device timestamp and allows the sender to also specify the format of this timestamp in another field called devTimeFormat , which uses the Java Time format. SC4S uses syslog-ng strptime format which is not directly translatable to the Java Time format. Therefore, SC4S has provided support for the following common formats. If needed, additional time formats can be requested via an issue on github. '%s.%f', '%s', '%b %d %H:%M:%S.%f', '%b %d %H:%M:%S', '%b %d %Y %H:%M:%S.%f', '%b %e %Y %H:%M:%S', '%b %e %H:%M:%S.%f', '%b %e %H:%M:%S', '%b %e %Y %H:%M:%S.%f', '%b %e %Y %H:%M:%S' Ref Link Splunk Add-on LEEF None Product Manual https://www.ibm.com/support/knowledgecenter/SS42VS_DSM/com.ibm.dsm.doc/c_LEEF_Format_Guide_intro.html Splunk Metadata with LEEF events \u00b6 The keys (first column) in splunk_metadata.csv for LEEF data sources have a slightly different meaning than those for non-LEEF ones. The typical vendor_product syntax is instead replaced by checks against specific columns of the LEEF event \u2013 namely the first and second, columns following the leading LEEF:VERSION (\u201ccolumn 0\u201d). These specific columns refer to the LEEF device_vendor , and device_product , respectively. device_vendor _ device_product Here is a snippet of a sample LANCOPE event in LEEF 2.0 format: <111>Apr 19 10:29:53 3.3.3.3 LEEF:2.0|Lancope|StealthWatch|1.0|41|^|src=192.0.2.0^dst=172.50.123.1^sev=5^cat=anomaly^srcPort=81^dstPort=21^usrName=joe.black and the corresponding match in splunk_metadata.csv : Lancope_StealthWatch,source,lancope:stealthwatch Default Sourcetype \u00b6 sourcetype notes LEEF:1 Common sourcetype for all LEEF v1 events LEEF:2: <separator> Common sourcetype for all LEEF v2 events separator is the printable literal or hex value of the seperator used in the event Default Source \u00b6 source notes vendor : product Varies Default Index Configuration \u00b6 key source index notes Vendor_Product Varies main none Filter type \u00b6 MSG Parse: This filter parses message content Options \u00b6 Variable default description SC4S_LISTEN_LEEF_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_LEEF_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_LEEF_TLS_PORT empty string Enable a TLS port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_LEEF no Enable archive to disk for this specific source SC4S_DEST_LEEF_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=LEEF:* source=<asconfigured>)","title":"Log Extended Format"},{"location":"sources/LogExtendedEventFormat/#vendor-log-extended-event-format","text":"","title":"Vendor - Log Extended Event Format"},{"location":"sources/LogExtendedEventFormat/#product-various-products-that-send-leef-v1-and-v2-format-messages-via-syslog","text":"Each LEEF product should have their own source entry in this documentation set by vendor. In a departure from normal configuration, all LEEF products should use the \u201cLEEF\u201d version of the unique port and archive environment variable settings (rather than a unique one per product), as the LEEF log path handles all products sending events to SC4S in the LEEF format. Examples of this include QRadar itself as well as other legacy systems. Therefore, the LEEF environment variables for unique port, archive, etc. should be set only once . If your deployment has multiple LEEF devices that send to more than one port, set the LEEF unique port variable(s) as a comma-separated list. See Unique Listening Ports for details. The source documentation included below is a reference baseline for any product that sends data using the LEEF log path. Some vendors implement LEEF v2.0 format events incorrectly, omitting the required \u201ckey=value\u201d seperator field from the LEEF header, thus forcing the consumer to assume the default tab \\t character. SC4S will correctly process this omission, but will not correctly process other non-compliant formats. The LEEF format allows for the inclusion of a field devTime containing the device timestamp and allows the sender to also specify the format of this timestamp in another field called devTimeFormat , which uses the Java Time format. SC4S uses syslog-ng strptime format which is not directly translatable to the Java Time format. Therefore, SC4S has provided support for the following common formats. If needed, additional time formats can be requested via an issue on github. '%s.%f', '%s', '%b %d %H:%M:%S.%f', '%b %d %H:%M:%S', '%b %d %Y %H:%M:%S.%f', '%b %e %Y %H:%M:%S', '%b %e %H:%M:%S.%f', '%b %e %H:%M:%S', '%b %e %Y %H:%M:%S.%f', '%b %e %Y %H:%M:%S' Ref Link Splunk Add-on LEEF None Product Manual https://www.ibm.com/support/knowledgecenter/SS42VS_DSM/com.ibm.dsm.doc/c_LEEF_Format_Guide_intro.html","title":"Product - Various products that send LEEF V1 and V2 format messages via syslog"},{"location":"sources/LogExtendedEventFormat/#splunk-metadata-with-leef-events","text":"The keys (first column) in splunk_metadata.csv for LEEF data sources have a slightly different meaning than those for non-LEEF ones. The typical vendor_product syntax is instead replaced by checks against specific columns of the LEEF event \u2013 namely the first and second, columns following the leading LEEF:VERSION (\u201ccolumn 0\u201d). These specific columns refer to the LEEF device_vendor , and device_product , respectively. device_vendor _ device_product Here is a snippet of a sample LANCOPE event in LEEF 2.0 format: <111>Apr 19 10:29:53 3.3.3.3 LEEF:2.0|Lancope|StealthWatch|1.0|41|^|src=192.0.2.0^dst=172.50.123.1^sev=5^cat=anomaly^srcPort=81^dstPort=21^usrName=joe.black and the corresponding match in splunk_metadata.csv : Lancope_StealthWatch,source,lancope:stealthwatch","title":"Splunk Metadata with LEEF events"},{"location":"sources/LogExtendedEventFormat/#default-sourcetype","text":"sourcetype notes LEEF:1 Common sourcetype for all LEEF v1 events LEEF:2: <separator> Common sourcetype for all LEEF v2 events separator is the printable literal or hex value of the seperator used in the event","title":"Default Sourcetype"},{"location":"sources/LogExtendedEventFormat/#default-source","text":"source notes vendor : product Varies","title":"Default Source"},{"location":"sources/LogExtendedEventFormat/#default-index-configuration","text":"key source index notes Vendor_Product Varies main none","title":"Default Index Configuration"},{"location":"sources/LogExtendedEventFormat/#filter-type","text":"MSG Parse: This filter parses message content","title":"Filter type"},{"location":"sources/LogExtendedEventFormat/#options","text":"Variable default description SC4S_LISTEN_LEEF_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_LEEF_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_LEEF_TLS_PORT empty string Enable a TLS port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_LEEF no Enable archive to disk for this specific source SC4S_DEST_LEEF_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/LogExtendedEventFormat/#verification","text":"An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=LEEF:* source=<asconfigured>)","title":"Verification"},{"location":"sources/Loggen/","text":"Vendor - Syslog-ng \u00b6 Product - syslog-ng loggen \u00b6 Ref Link Product Manual https://www.syslog-ng.com/technical-documents/doc/syslog-ng-open-source-edition/3.26/administration-guide/96#loggen.1 Sourcetypes \u00b6 sourcetype notes syslogng:loggen By default, loggen uses the legacy BSD-syslog message format. BSD example: loggen --inet --dgram --number 1 <ip> <port> RFC5424 example: loggen --inet --dgram -PF --number 1 <ip> <port> Refer to above manual link for more examples. Index Configuration \u00b6 key index notes syslogng_loggen main none Filter type \u00b6 MSG Parse: This filter parses message content Options \u00b6 Variable default description SC4S_LISTEN_SYSLOGNG_LOGGEN_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_SYSLOGNG_LOGGEN_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_SYSLOGNG_LOGGEN no Enable archive to disk for this specific source SC4S_DEST_SYSLOGNG_LOGGEN_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 An active device will generate frequent events. Use the following search to validate events are present per source device index=main sourcetype=\"syslogng:loggen\"| stats count by host","title":"Loggen"},{"location":"sources/Loggen/#vendor-syslog-ng","text":"","title":"Vendor - Syslog-ng"},{"location":"sources/Loggen/#product-syslog-ng-loggen","text":"Ref Link Product Manual https://www.syslog-ng.com/technical-documents/doc/syslog-ng-open-source-edition/3.26/administration-guide/96#loggen.1","title":"Product -  syslog-ng loggen"},{"location":"sources/Loggen/#sourcetypes","text":"sourcetype notes syslogng:loggen By default, loggen uses the legacy BSD-syslog message format. BSD example: loggen --inet --dgram --number 1 <ip> <port> RFC5424 example: loggen --inet --dgram -PF --number 1 <ip> <port> Refer to above manual link for more examples.","title":"Sourcetypes"},{"location":"sources/Loggen/#index-configuration","text":"key index notes syslogng_loggen main none","title":"Index Configuration"},{"location":"sources/Loggen/#filter-type","text":"MSG Parse: This filter parses message content","title":"Filter type"},{"location":"sources/Loggen/#options","text":"Variable default description SC4S_LISTEN_SYSLOGNG_LOGGEN_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_SYSLOGNG_LOGGEN_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_SYSLOGNG_LOGGEN no Enable archive to disk for this specific source SC4S_DEST_SYSLOGNG_LOGGEN_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/Loggen/#verification","text":"An active device will generate frequent events. Use the following search to validate events are present per source device index=main sourcetype=\"syslogng:loggen\"| stats count by host","title":"Verification"},{"location":"sources/McAfee/","text":"Vendor - McAfee \u00b6 Product - EPO \u00b6 This source requires a TLS connection; in most cases enabling TLS and using the default port 6514 is adequate. The source is understood to require a valid certificate. Ref Link Splunk Add-on https://splunkbase.splunk.com/app/5085/ Product Manual https://kc.mcafee.com/corporate/index?page=content&id=KB87927 Sourcetypes \u00b6 sourcetype notes mcafee:epo:syslog none Source \u00b6 source notes policy_auditor_vulnerability_assessment Policy Auditor Vulnerability Assessment events mcafee_agent McAfee Agent events mcafee_endpoint_security McAfee Endpoint Security events Index Configuration \u00b6 key index notes mcafee_epo epav none Filter type \u00b6 MSG Parse: This filter parses message content Options \u00b6 Variable default description SC4S_LISTEN_MCAFEE_EPO_TLS_PORT empty string Enable a TLS port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_MCAFEE_EPO no Enable archive to disk for this specific source SC4S_DEST_MCAFEE_EPO_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source SC4S_SOURCE_TLS_ENABLE no This must be set to yes so that SC4S listens for encrypted syslog from ePO Additional setup \u00b6 You must create a certificate for the SC4S server to receive encrypted syslog from ePO. A self-signed certificate is fine. Generate a self-signed certificate on the SC4S host: openssl req -newkey rsa:2048 -new -nodes -x509 -days 3650 -keyout /opt/sc4s/tls/server.key -out /opt/sc4s/tls/server.pem Uncomment the following line in /lib/systemd/system/sc4s.service to allow the docker container to use the certificate: Environment=\"SC4S_TLS_DIR=-v :/etc/syslog-ng/tls:z\" Troubleshooting \u00b6 from the command line of the SC4S host, run this: openssl s_client -connect localhost:6514 The message: socket : Bad file descriptor connect : errno = 9 indicates that SC4S is not listening for encrypted syslog. Note that a netstat may show the port open, but it is not accepting encrypted traffic as configured. It may take several minutes for the syslog option to be available in the registered servers dropdown. Verification \u00b6 An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=mcafee:epo:syslog\") Product - Web Gateway \u00b6 Ref Link Splunk Add-on https://splunkbase.splunk.com/app/3009/ Product Manual https://kc.mcafee.com/corporate/index?page=content&id=KB77988&actp=RSS Sourcetypes \u00b6 sourcetype notes mcafee:wg:kv none Index Configuration \u00b6 key index notes mcafee_wg netproxy none Filter type \u00b6 MSG Parse: This filter parses message content Options \u00b6 Variable default description SC4S_LISTEN_MCAFEE_WG_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_MCAFEE_WG_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_MCAFEE_WG no Enable archive to disk for this specific source SC4S_DEST_MCAFEE_WG_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source SC4S_SOURCE_TLS_ENABLE no This must be set to yes so that SC4S listens for encrypted syslog from Mcafee Web Gateway Troubleshooting \u00b6 from the command line of the SC4S host, run this: openssl s_client -connect localhost:6514 The message: socket : Bad file descriptor connect : errno = 9 indicates that SC4S is not listening for encrypted syslog. Note that a netstat may show the port open, but it is not accepting encrypted traffic as configured. It may take several minutes for the syslog option to be available in the registered servers dropdown. Verification \u00b6 An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=mcafee:wg:kv\") Product - Network Security Platform \u00b6 Ref Link Product Manual https://docs.mcafee.com/bundle/network-security-platform-10.1.x-product-guide/page/GUID-373C1CA6-EC0E-49E1-8858-749D1AA2716A.html Sourcetypes \u00b6 sourcetype notes mcafee:nsp none Source \u00b6 source notes mcafee:nsp:alert Alert/Attack Events mcafee:nsp:audit Audit Event or User Activity Events mcafee:nsp:fault Fault Events mcafee:nsp:firewall Firewall Events Index Configuration \u00b6 key index notes mcafee_nsp netids none Filter type \u00b6 MSG Parse: This filter parses message content Options \u00b6 Variable default description SC4S_LISTEN_MCAFEE_NSP_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_MCAFEE_NSP_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_MCAFEE_NSP no Enable archive to disk for this specific source SC4S_DEST_MCAFEE_NSP_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=netids sourcetype=mcafee:nsp","title":"McAfee"},{"location":"sources/McAfee/#vendor-mcafee","text":"","title":"Vendor - McAfee"},{"location":"sources/McAfee/#product-epo","text":"This source requires a TLS connection; in most cases enabling TLS and using the default port 6514 is adequate. The source is understood to require a valid certificate. Ref Link Splunk Add-on https://splunkbase.splunk.com/app/5085/ Product Manual https://kc.mcafee.com/corporate/index?page=content&id=KB87927","title":"Product - EPO"},{"location":"sources/McAfee/#sourcetypes","text":"sourcetype notes mcafee:epo:syslog none","title":"Sourcetypes"},{"location":"sources/McAfee/#source","text":"source notes policy_auditor_vulnerability_assessment Policy Auditor Vulnerability Assessment events mcafee_agent McAfee Agent events mcafee_endpoint_security McAfee Endpoint Security events","title":"Source"},{"location":"sources/McAfee/#index-configuration","text":"key index notes mcafee_epo epav none","title":"Index Configuration"},{"location":"sources/McAfee/#filter-type","text":"MSG Parse: This filter parses message content","title":"Filter type"},{"location":"sources/McAfee/#options","text":"Variable default description SC4S_LISTEN_MCAFEE_EPO_TLS_PORT empty string Enable a TLS port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_MCAFEE_EPO no Enable archive to disk for this specific source SC4S_DEST_MCAFEE_EPO_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source SC4S_SOURCE_TLS_ENABLE no This must be set to yes so that SC4S listens for encrypted syslog from ePO","title":"Options"},{"location":"sources/McAfee/#additional-setup","text":"You must create a certificate for the SC4S server to receive encrypted syslog from ePO. A self-signed certificate is fine. Generate a self-signed certificate on the SC4S host: openssl req -newkey rsa:2048 -new -nodes -x509 -days 3650 -keyout /opt/sc4s/tls/server.key -out /opt/sc4s/tls/server.pem Uncomment the following line in /lib/systemd/system/sc4s.service to allow the docker container to use the certificate: Environment=\"SC4S_TLS_DIR=-v :/etc/syslog-ng/tls:z\"","title":"Additional setup"},{"location":"sources/McAfee/#troubleshooting","text":"from the command line of the SC4S host, run this: openssl s_client -connect localhost:6514 The message: socket : Bad file descriptor connect : errno = 9 indicates that SC4S is not listening for encrypted syslog. Note that a netstat may show the port open, but it is not accepting encrypted traffic as configured. It may take several minutes for the syslog option to be available in the registered servers dropdown.","title":"Troubleshooting"},{"location":"sources/McAfee/#verification","text":"An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=mcafee:epo:syslog\")","title":"Verification"},{"location":"sources/McAfee/#product-web-gateway","text":"Ref Link Splunk Add-on https://splunkbase.splunk.com/app/3009/ Product Manual https://kc.mcafee.com/corporate/index?page=content&id=KB77988&actp=RSS","title":"Product - Web Gateway"},{"location":"sources/McAfee/#sourcetypes_1","text":"sourcetype notes mcafee:wg:kv none","title":"Sourcetypes"},{"location":"sources/McAfee/#index-configuration_1","text":"key index notes mcafee_wg netproxy none","title":"Index Configuration"},{"location":"sources/McAfee/#filter-type_1","text":"MSG Parse: This filter parses message content","title":"Filter type"},{"location":"sources/McAfee/#options_1","text":"Variable default description SC4S_LISTEN_MCAFEE_WG_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_MCAFEE_WG_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_MCAFEE_WG no Enable archive to disk for this specific source SC4S_DEST_MCAFEE_WG_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source SC4S_SOURCE_TLS_ENABLE no This must be set to yes so that SC4S listens for encrypted syslog from Mcafee Web Gateway","title":"Options"},{"location":"sources/McAfee/#troubleshooting_1","text":"from the command line of the SC4S host, run this: openssl s_client -connect localhost:6514 The message: socket : Bad file descriptor connect : errno = 9 indicates that SC4S is not listening for encrypted syslog. Note that a netstat may show the port open, but it is not accepting encrypted traffic as configured. It may take several minutes for the syslog option to be available in the registered servers dropdown.","title":"Troubleshooting"},{"location":"sources/McAfee/#verification_1","text":"An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=mcafee:wg:kv\")","title":"Verification"},{"location":"sources/McAfee/#product-network-security-platform","text":"Ref Link Product Manual https://docs.mcafee.com/bundle/network-security-platform-10.1.x-product-guide/page/GUID-373C1CA6-EC0E-49E1-8858-749D1AA2716A.html","title":"Product - Network Security Platform"},{"location":"sources/McAfee/#sourcetypes_2","text":"sourcetype notes mcafee:nsp none","title":"Sourcetypes"},{"location":"sources/McAfee/#source_1","text":"source notes mcafee:nsp:alert Alert/Attack Events mcafee:nsp:audit Audit Event or User Activity Events mcafee:nsp:fault Fault Events mcafee:nsp:firewall Firewall Events","title":"Source"},{"location":"sources/McAfee/#index-configuration_2","text":"key index notes mcafee_nsp netids none","title":"Index Configuration"},{"location":"sources/McAfee/#filter-type_2","text":"MSG Parse: This filter parses message content","title":"Filter type"},{"location":"sources/McAfee/#options_2","text":"Variable default description SC4S_LISTEN_MCAFEE_NSP_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_MCAFEE_NSP_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_MCAFEE_NSP no Enable archive to disk for this specific source SC4S_DEST_MCAFEE_NSP_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/McAfee/#verification_2","text":"An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=netids sourcetype=mcafee:nsp","title":"Verification"},{"location":"sources/Microfocus/","text":"Vendor - MicroFocus Arcsight \u00b6 Product - Arcsight Internal Agent \u00b6 Ref Link Splunk Add-on CEF https://github.com/splunk/splunk-add-on-for-cefdownloads/ Sourcetypes \u00b6 sourcetype notes cef Common sourcetype Source \u00b6 source notes ArcSight:ArcSight Internal logs Index Configuration \u00b6 key source index notes ArcSight_ArcSight ArcSight:ArcSight main none Filter type \u00b6 MSG Parse: This filter parses message content Options \u00b6 Variable default description SC4S_LISTEN_CEF_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_MICROFOCUS_ARCSIGHT_TCP_PORT empty string Deprecated equivalent of above variable. This is included for backward compatibility and will be removed in a future version. Do not use in new installations. NOTE: Set only one set of CEF variables for the entire SC4S deployment, regardless of how many ports are in use by this CEF source (or any others). See the \u201cCommon Event Format\u201d source documentation for more information. Verification \u00b6 An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=cef source=\"ArcSight:ArcSight\") Product - Arcsight Microsoft Windows (CEF) \u00b6 Ref Link Splunk Add-on CEF https://bitbucket.org/SPLServices/ta-cef-for-splunk/downloads/ Splunk Add-on CEF https://bitbucket.org/SPLServices/ta-cef-microsoft-windows-for-splunk/downloads/ Product Manual https://docs.imperva.com/bundle/cloud-application-security/page/more/log-configuration.htm Sourcetypes \u00b6 sourcetype notes cef Common sourcetype Source \u00b6 source notes CEFEventLog:System or Application Event Windows Application and System Event Logs CEFEventLog:Microsoft Windows Windows Security Event Logs Index Configuration \u00b6 key source index notes Microsoft_System or Application Event CEFEventLog:System or Application Event oswin none Microsoft_Microsoft Windows CEFEventLog:Microsoft Windows oswinsec none Filter type \u00b6 MSG Parse: This filter parses message content Options \u00b6 Variable default description SC4S_LISTEN_CEF_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_CEF_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_CEF no Enable archive to disk for this specific source SC4S_DEST_CEF_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source SC4S_WWW_XXX_MICROFOCUS_ARCSIGHT_YYY_ZZZ no Deprecated equivalents of the above variables. These are included for backward compatibility, and will be removed in a future version. Do not use in new installations. NOTE: Set only one set of CEF variables for the entire SC4S deployment, regardless of how many ports are in use by this CEF source (or any others). See the \u201cCommon Event Format\u201d source documentation for more information. Verification \u00b6 An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=cef (source=\"CEFEventLog:Microsoft Windows\" OR source=\"CEFEventLog:System or Application Event\"))","title":"Microfocus"},{"location":"sources/Microfocus/#vendor-microfocus-arcsight","text":"","title":"Vendor - MicroFocus Arcsight"},{"location":"sources/Microfocus/#product-arcsight-internal-agent","text":"Ref Link Splunk Add-on CEF https://github.com/splunk/splunk-add-on-for-cefdownloads/","title":"Product - Arcsight Internal Agent"},{"location":"sources/Microfocus/#sourcetypes","text":"sourcetype notes cef Common sourcetype","title":"Sourcetypes"},{"location":"sources/Microfocus/#source","text":"source notes ArcSight:ArcSight Internal logs","title":"Source"},{"location":"sources/Microfocus/#index-configuration","text":"key source index notes ArcSight_ArcSight ArcSight:ArcSight main none","title":"Index Configuration"},{"location":"sources/Microfocus/#filter-type","text":"MSG Parse: This filter parses message content","title":"Filter type"},{"location":"sources/Microfocus/#options","text":"Variable default description SC4S_LISTEN_CEF_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_MICROFOCUS_ARCSIGHT_TCP_PORT empty string Deprecated equivalent of above variable. This is included for backward compatibility and will be removed in a future version. Do not use in new installations. NOTE: Set only one set of CEF variables for the entire SC4S deployment, regardless of how many ports are in use by this CEF source (or any others). See the \u201cCommon Event Format\u201d source documentation for more information.","title":"Options"},{"location":"sources/Microfocus/#verification","text":"An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=cef source=\"ArcSight:ArcSight\")","title":"Verification"},{"location":"sources/Microfocus/#product-arcsight-microsoft-windows-cef","text":"Ref Link Splunk Add-on CEF https://bitbucket.org/SPLServices/ta-cef-for-splunk/downloads/ Splunk Add-on CEF https://bitbucket.org/SPLServices/ta-cef-microsoft-windows-for-splunk/downloads/ Product Manual https://docs.imperva.com/bundle/cloud-application-security/page/more/log-configuration.htm","title":"Product - Arcsight Microsoft Windows (CEF)"},{"location":"sources/Microfocus/#sourcetypes_1","text":"sourcetype notes cef Common sourcetype","title":"Sourcetypes"},{"location":"sources/Microfocus/#source_1","text":"source notes CEFEventLog:System or Application Event Windows Application and System Event Logs CEFEventLog:Microsoft Windows Windows Security Event Logs","title":"Source"},{"location":"sources/Microfocus/#index-configuration_1","text":"key source index notes Microsoft_System or Application Event CEFEventLog:System or Application Event oswin none Microsoft_Microsoft Windows CEFEventLog:Microsoft Windows oswinsec none","title":"Index Configuration"},{"location":"sources/Microfocus/#filter-type_1","text":"MSG Parse: This filter parses message content","title":"Filter type"},{"location":"sources/Microfocus/#options_1","text":"Variable default description SC4S_LISTEN_CEF_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_CEF_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_CEF no Enable archive to disk for this specific source SC4S_DEST_CEF_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source SC4S_WWW_XXX_MICROFOCUS_ARCSIGHT_YYY_ZZZ no Deprecated equivalents of the above variables. These are included for backward compatibility, and will be removed in a future version. Do not use in new installations. NOTE: Set only one set of CEF variables for the entire SC4S deployment, regardless of how many ports are in use by this CEF source (or any others). See the \u201cCommon Event Format\u201d source documentation for more information.","title":"Options"},{"location":"sources/Microfocus/#verification_1","text":"An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=cef (source=\"CEFEventLog:Microsoft Windows\" OR source=\"CEFEventLog:System or Application Event\"))","title":"Verification"},{"location":"sources/Microsoft/","text":"Vendor - Microsoft \u00b6 Product - Cloud App Security (MCAS) \u00b6 Ref Link Splunk Add-on CEF https://bitbucket.org/SPLServices/ta-cef-for-splunk/downloads/ Splunk Add-on Source Specific none Product Manual https://docs.microsoft.com/en-us/cloud-app-security/siem Sourcetypes \u00b6 sourcetype notes cef Common sourcetype Source \u00b6 source notes microsoft:cas Common sourcetype Index Configuration \u00b6 key source index notes MCAS_SIEM_Agent microsoft:cas main none Filter type \u00b6 MSG Parse: This filter parses message content Options \u00b6 Note listed for reference processing utilizes the Microsoft ArcSight log path as this format is a subtype of CEF Variable default description SC4S_LISTEN_CEF_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_CEF_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_CEF no Enable archive to disk for this specific source SC4S_DEST_CEF_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source NOTE: Set only one set of CEF variables for the entire SC4S deployment, regardless of how many ports are in use by this CEF source (or any others). See the \u201cCommon Event Format\u201d source documentation for more information. Verification \u00b6 An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=cef source=\"microsoft:cas\")","title":"Microsoft"},{"location":"sources/Microsoft/#vendor-microsoft","text":"","title":"Vendor - Microsoft"},{"location":"sources/Microsoft/#product-cloud-app-security-mcas","text":"Ref Link Splunk Add-on CEF https://bitbucket.org/SPLServices/ta-cef-for-splunk/downloads/ Splunk Add-on Source Specific none Product Manual https://docs.microsoft.com/en-us/cloud-app-security/siem","title":"Product - Cloud App Security (MCAS)"},{"location":"sources/Microsoft/#sourcetypes","text":"sourcetype notes cef Common sourcetype","title":"Sourcetypes"},{"location":"sources/Microsoft/#source","text":"source notes microsoft:cas Common sourcetype","title":"Source"},{"location":"sources/Microsoft/#index-configuration","text":"key source index notes MCAS_SIEM_Agent microsoft:cas main none","title":"Index Configuration"},{"location":"sources/Microsoft/#filter-type","text":"MSG Parse: This filter parses message content","title":"Filter type"},{"location":"sources/Microsoft/#options","text":"Note listed for reference processing utilizes the Microsoft ArcSight log path as this format is a subtype of CEF Variable default description SC4S_LISTEN_CEF_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_CEF_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_CEF no Enable archive to disk for this specific source SC4S_DEST_CEF_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source NOTE: Set only one set of CEF variables for the entire SC4S deployment, regardless of how many ports are in use by this CEF source (or any others). See the \u201cCommon Event Format\u201d source documentation for more information.","title":"Options"},{"location":"sources/Microsoft/#verification","text":"An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=cef source=\"microsoft:cas\")","title":"Verification"},{"location":"sources/NetApp/","text":"Vendor - NetApp \u00b6 Product - OnTap \u00b6 Ref Link Splunk Add-on https://splunkbase.splunk.com/app/3418/ Product Manual unknown Sourcetypes \u00b6 sourcetype notes netapp:ems None Sourcetype and Index Configuration \u00b6 key sourcetype index notes netapp_ontap netapp:ems infraops none Filter type \u00b6 MSG Parsing Setup and Configuration \u00b6 Options \u00b6 Variable default description SC4S_LISTEN_NETAPP_ONTAP_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_NETAPP_ONTAP_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_NETAPP_ONTAP no Enable archive to disk for this specific source SC4S_DEST_NETAPP_ONTAP_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 index=<asconfigured> sourcetype=netapp:ems | stats count by host","title":"NetApp"},{"location":"sources/NetApp/#vendor-netapp","text":"","title":"Vendor - NetApp"},{"location":"sources/NetApp/#product-ontap","text":"Ref Link Splunk Add-on https://splunkbase.splunk.com/app/3418/ Product Manual unknown","title":"Product - OnTap"},{"location":"sources/NetApp/#sourcetypes","text":"sourcetype notes netapp:ems None","title":"Sourcetypes"},{"location":"sources/NetApp/#sourcetype-and-index-configuration","text":"key sourcetype index notes netapp_ontap netapp:ems infraops none","title":"Sourcetype and Index Configuration"},{"location":"sources/NetApp/#filter-type","text":"MSG Parsing","title":"Filter type"},{"location":"sources/NetApp/#setup-and-configuration","text":"","title":"Setup and Configuration"},{"location":"sources/NetApp/#options","text":"Variable default description SC4S_LISTEN_NETAPP_ONTAP_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_NETAPP_ONTAP_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_NETAPP_ONTAP no Enable archive to disk for this specific source SC4S_DEST_NETAPP_ONTAP_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/NetApp/#verification","text":"index=<asconfigured> sourcetype=netapp:ems | stats count by host","title":"Verification"},{"location":"sources/Netmotion/","text":"Vendor - Netmotion \u00b6 Product - Reporting \u00b6 Ref Link Splunk Add-on none Product Manual unknown Sourcetypes \u00b6 sourcetype notes netmotion:reporting None Sourcetype and Index Configuration \u00b6 key sourcetype index notes netmotion_reporting netmotion:reporting netops none Filter type \u00b6 MSG Parsing Setup and Configuration \u00b6 Options \u00b6 Variable default description SC4S_LISTEN_NETMOTION_REPORTING_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_NETMOTION_REPORTING_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_NETMOTION_REPORTING no Enable archive to disk for this specific source SC4S_DEST_NETMOTION_REPORTING_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 An active proxy will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=netmotion:reporting | stats count by host","title":"Netmotion"},{"location":"sources/Netmotion/#vendor-netmotion","text":"","title":"Vendor - Netmotion"},{"location":"sources/Netmotion/#product-reporting","text":"Ref Link Splunk Add-on none Product Manual unknown","title":"Product - Reporting"},{"location":"sources/Netmotion/#sourcetypes","text":"sourcetype notes netmotion:reporting None","title":"Sourcetypes"},{"location":"sources/Netmotion/#sourcetype-and-index-configuration","text":"key sourcetype index notes netmotion_reporting netmotion:reporting netops none","title":"Sourcetype and Index Configuration"},{"location":"sources/Netmotion/#filter-type","text":"MSG Parsing","title":"Filter type"},{"location":"sources/Netmotion/#setup-and-configuration","text":"","title":"Setup and Configuration"},{"location":"sources/Netmotion/#options","text":"Variable default description SC4S_LISTEN_NETMOTION_REPORTING_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_NETMOTION_REPORTING_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_NETMOTION_REPORTING no Enable archive to disk for this specific source SC4S_DEST_NETMOTION_REPORTING_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/Netmotion/#verification","text":"An active proxy will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=netmotion:reporting | stats count by host","title":"Verification"},{"location":"sources/Novell/","text":"Vendor - Novell \u00b6 Product - NetIQ \u00b6 Ref Link Splunk Add-on None Product Manual unknown Sourcetypes \u00b6 sourcetype notes novell:netiq none Sourcetype and Index Configuration \u00b6 key sourcetype index notes novell_netiq novell_netiq netauth None Filter type \u00b6 MSGParser Options \u00b6 Variable default description SC4S_LISTEN_NOVELL_NETIQ_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_NOVELL_NETIQ_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_NOVELL_NETIQ no Enable archive to disk for this specific source SC4S_DEST_NOVELL_NETIQ_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 Use the following search to validate events are present index=netauth sourcetype=novel:netiq Verify timestamp, and host values match as expected","title":"Novell"},{"location":"sources/Novell/#vendor-novell","text":"","title":"Vendor - Novell"},{"location":"sources/Novell/#product-netiq","text":"Ref Link Splunk Add-on None Product Manual unknown","title":"Product - NetIQ"},{"location":"sources/Novell/#sourcetypes","text":"sourcetype notes novell:netiq none","title":"Sourcetypes"},{"location":"sources/Novell/#sourcetype-and-index-configuration","text":"key sourcetype index notes novell_netiq novell_netiq netauth None","title":"Sourcetype and Index Configuration"},{"location":"sources/Novell/#filter-type","text":"MSGParser","title":"Filter type"},{"location":"sources/Novell/#options","text":"Variable default description SC4S_LISTEN_NOVELL_NETIQ_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_NOVELL_NETIQ_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_NOVELL_NETIQ no Enable archive to disk for this specific source SC4S_DEST_NOVELL_NETIQ_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/Novell/#verification","text":"Use the following search to validate events are present index=netauth sourcetype=novel:netiq Verify timestamp, and host values match as expected","title":"Verification"},{"location":"sources/Ossec/","text":"Vendor - Ossec \u00b6 Product - Ossec \u00b6 Ref Link Splunk Add-on https://splunkbase.splunk.com/app/2808/ Product Manual https://www.ossec.net/docs/index.html Sourcetypes \u00b6 sourcetype notes ossec The add-on supports data from the following sources: File Integrity Management (FIM) data, FTP data, su data, ssh data, Windows data, including audit and logon information Sourcetype and Index Configuration \u00b6 key sourcetype index notes ossec ossec main None Filter type \u00b6 IP, Netmask or Host Setup and Configuration \u00b6 Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used the addon is not required on the indexer. Ossec Follow vendor configuration steps per Product Manual. Ensure host and timestamp are included. Update vi /opt/sc4s/local/context/vendor_product_by_source.conf update the host or ip mask for f_ossec to identiy the ossec events. Options \u00b6 Variable default description SC4S_LISTEN_OSSEC_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_OSSEC_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_OSSEC no Enable archive to disk for this specific source SC4S_DEST_OSSEC_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 Use the following search to validate events are present index=main sourcetype=ossec Verify timestamp, and host values match as expected","title":"OSSEC"},{"location":"sources/Ossec/#vendor-ossec","text":"","title":"Vendor - Ossec"},{"location":"sources/Ossec/#product-ossec","text":"Ref Link Splunk Add-on https://splunkbase.splunk.com/app/2808/ Product Manual https://www.ossec.net/docs/index.html","title":"Product - Ossec"},{"location":"sources/Ossec/#sourcetypes","text":"sourcetype notes ossec The add-on supports data from the following sources: File Integrity Management (FIM) data, FTP data, su data, ssh data, Windows data, including audit and logon information","title":"Sourcetypes"},{"location":"sources/Ossec/#sourcetype-and-index-configuration","text":"key sourcetype index notes ossec ossec main None","title":"Sourcetype and Index Configuration"},{"location":"sources/Ossec/#filter-type","text":"IP, Netmask or Host","title":"Filter type"},{"location":"sources/Ossec/#setup-and-configuration","text":"Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used the addon is not required on the indexer. Ossec Follow vendor configuration steps per Product Manual. Ensure host and timestamp are included. Update vi /opt/sc4s/local/context/vendor_product_by_source.conf update the host or ip mask for f_ossec to identiy the ossec events.","title":"Setup and Configuration"},{"location":"sources/Ossec/#options","text":"Variable default description SC4S_LISTEN_OSSEC_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_OSSEC_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_OSSEC no Enable archive to disk for this specific source SC4S_DEST_OSSEC_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/Ossec/#verification","text":"Use the following search to validate events are present index=main sourcetype=ossec Verify timestamp, and host values match as expected","title":"Verification"},{"location":"sources/PaloaltoNetworks/","text":"Vendor - PaloAlto \u00b6 Product - NGFW \u00b6 Ref Link Splunk Add-on https://splunkbase.splunk.com/app/2757/ Product Manual https://docs.paloaltonetworks.com/pan-os/9-0/pan-os-admin/monitoring/use-syslog-for-monitoring/configure-syslog-monitoring.html Sourcetypes \u00b6 sourcetype notes pan:log None pan:pan_globalprotect none pan:traffic None pan:threat None pan:system None pan:config None pan:hipmatch None pan:correlation None Sourcetype and Index Configuration \u00b6 key sourcetype index notes pan_log pan:log netops none pan_globalprotect pan:pan_globalprotect netfw none pan_traffic pan:traffic netfw none pan_threat pan:threat netproxy none pan_system pan:system netops none pan_config pan:config netops none hipmatch pan:hipmatch netops none pan_correlation pan:correlation netops none Filter type \u00b6 MSG Parse: This filter parses message content Setup and Configuration \u00b6 Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used the addon is not required on the indexer. Review and update the splunk_metadata.csv file and set the index and sourcetype as required for the data source. Refer to the admin manual for specific details of configuration Select TCP or SSL transport option Select IETF Format Ensure the format of the event is not customized Options \u00b6 Variable default description SC4S_LISTEN_PULSE_PALOALTO_PANOS_RFC6587_PORT empty string Enable a TCP using IETF Framing (RFC6587) port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_PALOALTO_PANOS_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_PALOALTO_PANOS no Enable archive to disk for this specific source SC4S_DEST_PALOALTO_PANOS_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 An active firewall will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=pan:*| stats count by host Product - TRAPS \u00b6 Ref Link Splunk Add-on https://splunkbase.splunk.com/app/2757/ Sourcetypes \u00b6 sourcetype notes pan:traps4 none Index Configuration \u00b6 key index notes Palo Alto Networks_Traps Agent epintel none Filter type \u00b6 MSG Parse: This filter parses message content Options \u00b6 Variable default description SC4S_LISTEN_CEF_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_CEF_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_CEF no Enable archive to disk for this specific source SC4S_DEST_CEF_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source NOTE: Set only one set of CEF variables for the entire SC4S deployment, regardless of how many ports are in use by this CEF source (or any others). See the \u201cCommon Event Format\u201d source documentation for more information. Verification \u00b6 An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=pan:traps4)","title":"Palo Alto Networks"},{"location":"sources/PaloaltoNetworks/#vendor-paloalto","text":"","title":"Vendor - PaloAlto"},{"location":"sources/PaloaltoNetworks/#product-ngfw","text":"Ref Link Splunk Add-on https://splunkbase.splunk.com/app/2757/ Product Manual https://docs.paloaltonetworks.com/pan-os/9-0/pan-os-admin/monitoring/use-syslog-for-monitoring/configure-syslog-monitoring.html","title":"Product - NGFW"},{"location":"sources/PaloaltoNetworks/#sourcetypes","text":"sourcetype notes pan:log None pan:pan_globalprotect none pan:traffic None pan:threat None pan:system None pan:config None pan:hipmatch None pan:correlation None","title":"Sourcetypes"},{"location":"sources/PaloaltoNetworks/#sourcetype-and-index-configuration","text":"key sourcetype index notes pan_log pan:log netops none pan_globalprotect pan:pan_globalprotect netfw none pan_traffic pan:traffic netfw none pan_threat pan:threat netproxy none pan_system pan:system netops none pan_config pan:config netops none hipmatch pan:hipmatch netops none pan_correlation pan:correlation netops none","title":"Sourcetype and Index Configuration"},{"location":"sources/PaloaltoNetworks/#filter-type","text":"MSG Parse: This filter parses message content","title":"Filter type"},{"location":"sources/PaloaltoNetworks/#setup-and-configuration","text":"Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used the addon is not required on the indexer. Review and update the splunk_metadata.csv file and set the index and sourcetype as required for the data source. Refer to the admin manual for specific details of configuration Select TCP or SSL transport option Select IETF Format Ensure the format of the event is not customized","title":"Setup and Configuration"},{"location":"sources/PaloaltoNetworks/#options","text":"Variable default description SC4S_LISTEN_PULSE_PALOALTO_PANOS_RFC6587_PORT empty string Enable a TCP using IETF Framing (RFC6587) port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_PALOALTO_PANOS_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_PALOALTO_PANOS no Enable archive to disk for this specific source SC4S_DEST_PALOALTO_PANOS_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/PaloaltoNetworks/#verification","text":"An active firewall will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=pan:*| stats count by host","title":"Verification"},{"location":"sources/PaloaltoNetworks/#product-traps","text":"Ref Link Splunk Add-on https://splunkbase.splunk.com/app/2757/","title":"Product - TRAPS"},{"location":"sources/PaloaltoNetworks/#sourcetypes_1","text":"sourcetype notes pan:traps4 none","title":"Sourcetypes"},{"location":"sources/PaloaltoNetworks/#index-configuration","text":"key index notes Palo Alto Networks_Traps Agent epintel none","title":"Index Configuration"},{"location":"sources/PaloaltoNetworks/#filter-type_1","text":"MSG Parse: This filter parses message content","title":"Filter type"},{"location":"sources/PaloaltoNetworks/#options_1","text":"Variable default description SC4S_LISTEN_CEF_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_CEF_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_CEF no Enable archive to disk for this specific source SC4S_DEST_CEF_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source NOTE: Set only one set of CEF variables for the entire SC4S deployment, regardless of how many ports are in use by this CEF source (or any others). See the \u201cCommon Event Format\u201d source documentation for more information.","title":"Options"},{"location":"sources/PaloaltoNetworks/#verification_1","text":"An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=pan:traps4)","title":"Verification"},{"location":"sources/Pfsense/","text":"Vendor - pfSense \u00b6 All pfSense based firewalls Product \u00b6 Ref Link Splunk Add-on https://splunkbase.splunk.com/app/1527/ Product Manual https://docs.netgate.com/pfsense/en/latest/monitoring/copying-logs-to-a-remote-host-with-syslog.html?highlight=syslog Sourcetypes \u00b6 sourcetype notes pfsense:filterlog None pfsense:* All programs other than filterlog Sourcetype and Index Configuration \u00b6 key sourcetype index notes pfsense pfsense netops none pfsense_filterlog pfsense:filterlog netfw none Filter type \u00b6 Source does not provide a hostname, port or IP based filter is required Setup and Configuration \u00b6 Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used the addon is not required on the indexer. Review and update the splunk_metadata.csv file and set the index and sourcetype as required for the data source. Configure a dedicated SC4S port OR configure IP filter Refer to the Splunk TA documentation for the specific customer format required for proxy configuration Select TCP or SSL transport option Ensure the format of the event is customized per Splunk documentation Options \u00b6 Variable default description SC4S_LISTEN_PFSENSE_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_PFSENSE_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_PFSENSE no Enable archive to disk for this specific source SC4S_DEST_PFSENSE_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 An active proxy will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=pfsense:filterlog | stats count by host","title":"pfSense"},{"location":"sources/Pfsense/#vendor-pfsense","text":"All pfSense based firewalls","title":"Vendor - pfSense"},{"location":"sources/Pfsense/#product","text":"Ref Link Splunk Add-on https://splunkbase.splunk.com/app/1527/ Product Manual https://docs.netgate.com/pfsense/en/latest/monitoring/copying-logs-to-a-remote-host-with-syslog.html?highlight=syslog","title":"Product"},{"location":"sources/Pfsense/#sourcetypes","text":"sourcetype notes pfsense:filterlog None pfsense:* All programs other than filterlog","title":"Sourcetypes"},{"location":"sources/Pfsense/#sourcetype-and-index-configuration","text":"key sourcetype index notes pfsense pfsense netops none pfsense_filterlog pfsense:filterlog netfw none","title":"Sourcetype and Index Configuration"},{"location":"sources/Pfsense/#filter-type","text":"Source does not provide a hostname, port or IP based filter is required","title":"Filter type"},{"location":"sources/Pfsense/#setup-and-configuration","text":"Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used the addon is not required on the indexer. Review and update the splunk_metadata.csv file and set the index and sourcetype as required for the data source. Configure a dedicated SC4S port OR configure IP filter Refer to the Splunk TA documentation for the specific customer format required for proxy configuration Select TCP or SSL transport option Ensure the format of the event is customized per Splunk documentation","title":"Setup and Configuration"},{"location":"sources/Pfsense/#options","text":"Variable default description SC4S_LISTEN_PFSENSE_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_PFSENSE_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_PFSENSE no Enable archive to disk for this specific source SC4S_DEST_PFSENSE_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/Pfsense/#verification","text":"An active proxy will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=pfsense:filterlog | stats count by host","title":"Verification"},{"location":"sources/Polycom/","text":"Vendor - Polycom \u00b6 Product - RPRM \u00b6 Ref Link Splunk Add-on none Product Manual unknown Sourcetypes \u00b6 sourcetype notes polycom:rprm:syslog Sourcetype and Index Configuration \u00b6 key sourcetype index notes polycom_rprm polycom:rprm:syslog netops none Filter type \u00b6 MSG Parse: This filter parses message content Options \u00b6 Variable default description SC4S_POLYCOM_RPRM_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers. SC4S_POLYCOM_RPRM_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers. SC4S_ARCHIVE_POLYCOM_RPRM no Enable archive to disk for this specific source SC4S_DEST_POLYCOM_RPRM_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 One or two sourcetypes are included in Proofpoint PPS logs. The search below will surface both of them: index=<asconfigured> sourcetype=polycom:rprm:syslog| stats count by host","title":"Polycom"},{"location":"sources/Polycom/#vendor-polycom","text":"","title":"Vendor - Polycom"},{"location":"sources/Polycom/#product-rprm","text":"Ref Link Splunk Add-on none Product Manual unknown","title":"Product - RPRM"},{"location":"sources/Polycom/#sourcetypes","text":"sourcetype notes polycom:rprm:syslog","title":"Sourcetypes"},{"location":"sources/Polycom/#sourcetype-and-index-configuration","text":"key sourcetype index notes polycom_rprm polycom:rprm:syslog netops none","title":"Sourcetype and Index Configuration"},{"location":"sources/Polycom/#filter-type","text":"MSG Parse: This filter parses message content","title":"Filter type"},{"location":"sources/Polycom/#options","text":"Variable default description SC4S_POLYCOM_RPRM_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers. SC4S_POLYCOM_RPRM_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers. SC4S_ARCHIVE_POLYCOM_RPRM no Enable archive to disk for this specific source SC4S_DEST_POLYCOM_RPRM_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/Polycom/#verification","text":"One or two sourcetypes are included in Proofpoint PPS logs. The search below will surface both of them: index=<asconfigured> sourcetype=polycom:rprm:syslog| stats count by host","title":"Verification"},{"location":"sources/Proofpoint/","text":"Vendor - Proofpoint \u00b6 Product - Proofpoint Protection Server \u00b6 Ref Link Splunk Add-on https://splunkbase.splunk.com/app/3080/ Product Manual https://proofpointcommunities.force.com/community/s/article/Remote-Syslog-Forwarding Sourcetypes \u00b6 sourcetype notes pps_filter_log pps_mail_log This sourcetype will conflict with sendmail itself, so will require that the PPS send syslog on a dedicated port or be uniquely identifiable with a hostname glob or CIDR block if this sourcetype is desired for PPS. Sourcetype and Index Configuration \u00b6 key sourcetype index notes proofpoint_pps_filter pps_filter_log email none proofpoint_pps_sendmail pps_mail_log email none Filter type \u00b6 MSG Parse: This filter parses message content * NOTE: This filter will simply parse the syslog message itself, and will not perform the (required) re-assembly of related messages to create meaningful final output. This will require follow-on processing in Splunk. Setup and Configuration \u00b6 Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used the addon is not required on the indexer. Review and update the splunk_metadata.csv file and set the index and sourcetype as required for the data source. Follow vendor configuration steps per referenced Product Manual Options \u00b6 Variable default description SC4S_PROOFPOINT_PPS_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers. SC4S_PROOFPOINT_PPS_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers. SC4S_ARCHIVE_PROOFPOINT_PPS no Enable archive to disk for this specific source SC4S_DEST_PROOFPOINT_PPS_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 One or two sourcetypes are included in Proofpoint PPS logs. The search below will surface both of them: index=<asconfigured> sourcetype=pps_*_log | stats count by host","title":"Proofpoint"},{"location":"sources/Proofpoint/#vendor-proofpoint","text":"","title":"Vendor - Proofpoint"},{"location":"sources/Proofpoint/#product-proofpoint-protection-server","text":"Ref Link Splunk Add-on https://splunkbase.splunk.com/app/3080/ Product Manual https://proofpointcommunities.force.com/community/s/article/Remote-Syslog-Forwarding","title":"Product - Proofpoint Protection Server"},{"location":"sources/Proofpoint/#sourcetypes","text":"sourcetype notes pps_filter_log pps_mail_log This sourcetype will conflict with sendmail itself, so will require that the PPS send syslog on a dedicated port or be uniquely identifiable with a hostname glob or CIDR block if this sourcetype is desired for PPS.","title":"Sourcetypes"},{"location":"sources/Proofpoint/#sourcetype-and-index-configuration","text":"key sourcetype index notes proofpoint_pps_filter pps_filter_log email none proofpoint_pps_sendmail pps_mail_log email none","title":"Sourcetype and Index Configuration"},{"location":"sources/Proofpoint/#filter-type","text":"MSG Parse: This filter parses message content * NOTE: This filter will simply parse the syslog message itself, and will not perform the (required) re-assembly of related messages to create meaningful final output. This will require follow-on processing in Splunk.","title":"Filter type"},{"location":"sources/Proofpoint/#setup-and-configuration","text":"Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used the addon is not required on the indexer. Review and update the splunk_metadata.csv file and set the index and sourcetype as required for the data source. Follow vendor configuration steps per referenced Product Manual","title":"Setup and Configuration"},{"location":"sources/Proofpoint/#options","text":"Variable default description SC4S_PROOFPOINT_PPS_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers. SC4S_PROOFPOINT_PPS_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers. SC4S_ARCHIVE_PROOFPOINT_PPS no Enable archive to disk for this specific source SC4S_DEST_PROOFPOINT_PPS_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/Proofpoint/#verification","text":"One or two sourcetypes are included in Proofpoint PPS logs. The search below will surface both of them: index=<asconfigured> sourcetype=pps_*_log | stats count by host","title":"Verification"},{"location":"sources/Pulse/","text":"Vendor - Pulse \u00b6 Product - Secure Connect \u00b6 Ref Link Splunk Add-on https://splunkbase.splunk.com/app/3852/ JunOS TechLibrary https://docs.pulsesecure.net/WebHelp/Content/PCS/PCS_AdminGuide_8.2/Configuring%20Syslog.htm Sourcetypes \u00b6 sourcetype notes pulse:connectsecure None pulse:connectsecure:web None Sourcetype and Index Configuration \u00b6 key sourcetype index notes pulse_connect_secure pulse:connectsecure netfw none pulse_connect_secure_web pulse:connectsecure:web netproxy none Filter type \u00b6 MSG Parse: This filter parses message content Setup and Configuration \u00b6 Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used the addon is not required on the indexer. Review and update the splunk_metadata.csv file and set the index as required. Follow vendor configuration steps per referenced Product Manual Options \u00b6 Note RFC6587 framing is not supported over TLS at this time Variable default description SC4S_LISTEN_PULSE_CONNECT_SECURE_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers using legacy 3164 format SC4S_LISTEN_PULSE_CONNECT_SECURE_RFC6587_PORT empty string Enable a TCP using IETF Framing (RFC6587) port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_PULSE_CONNECT_SECURE no Enable archive to disk for this specific source SC4S_DEST_PULSE_CONNECT_SECURE_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 Use the following search to validate events are present index=<asconfigured> sourcetype=pulse:connectsecure* | stats count by host Verify the timestamp and host values match as expected","title":"Pulse"},{"location":"sources/Pulse/#vendor-pulse","text":"","title":"Vendor - Pulse"},{"location":"sources/Pulse/#product-secure-connect","text":"Ref Link Splunk Add-on https://splunkbase.splunk.com/app/3852/ JunOS TechLibrary https://docs.pulsesecure.net/WebHelp/Content/PCS/PCS_AdminGuide_8.2/Configuring%20Syslog.htm","title":"Product - Secure Connect"},{"location":"sources/Pulse/#sourcetypes","text":"sourcetype notes pulse:connectsecure None pulse:connectsecure:web None","title":"Sourcetypes"},{"location":"sources/Pulse/#sourcetype-and-index-configuration","text":"key sourcetype index notes pulse_connect_secure pulse:connectsecure netfw none pulse_connect_secure_web pulse:connectsecure:web netproxy none","title":"Sourcetype and Index Configuration"},{"location":"sources/Pulse/#filter-type","text":"MSG Parse: This filter parses message content","title":"Filter type"},{"location":"sources/Pulse/#setup-and-configuration","text":"Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used the addon is not required on the indexer. Review and update the splunk_metadata.csv file and set the index as required. Follow vendor configuration steps per referenced Product Manual","title":"Setup and Configuration"},{"location":"sources/Pulse/#options","text":"Note RFC6587 framing is not supported over TLS at this time Variable default description SC4S_LISTEN_PULSE_CONNECT_SECURE_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers using legacy 3164 format SC4S_LISTEN_PULSE_CONNECT_SECURE_RFC6587_PORT empty string Enable a TCP using IETF Framing (RFC6587) port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_PULSE_CONNECT_SECURE no Enable archive to disk for this specific source SC4S_DEST_PULSE_CONNECT_SECURE_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/Pulse/#verification","text":"Use the following search to validate events are present index=<asconfigured> sourcetype=pulse:connectsecure* | stats count by host Verify the timestamp and host values match as expected","title":"Verification"},{"location":"sources/Radware/","text":"Vendor - Radware \u00b6 Product - DefensePro \u00b6 Ref Link Splunk Add-on Note this add-on does not provide functional extractions https://splunkbase.splunk.com/app/4480/ Product Manual https://www.radware.com/products/defensepro/ Sourcetypes \u00b6 sourcetype notes radware:defensepro Note some events do not contain host Sourcetype and Index Configuration \u00b6 key sourcetype index notes radware_defensepro radware:defensepro netops none Filter type \u00b6 MSG Parsing Setup and Configuration \u00b6 Options \u00b6 Variable default description SC4S_LISTEN_RADWARE_DEFENSEPRO_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_RADWARE_DEFENSEPRO_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_RADWARE_DEFENSEPRO no Enable archive to disk for this specific source SC4S_DEST_RADWARE_DEFENSEPRO_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 An active proxy will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=radware:defensepro | stats count by host","title":"Radware"},{"location":"sources/Radware/#vendor-radware","text":"","title":"Vendor - Radware"},{"location":"sources/Radware/#product-defensepro","text":"Ref Link Splunk Add-on Note this add-on does not provide functional extractions https://splunkbase.splunk.com/app/4480/ Product Manual https://www.radware.com/products/defensepro/","title":"Product - DefensePro"},{"location":"sources/Radware/#sourcetypes","text":"sourcetype notes radware:defensepro Note some events do not contain host","title":"Sourcetypes"},{"location":"sources/Radware/#sourcetype-and-index-configuration","text":"key sourcetype index notes radware_defensepro radware:defensepro netops none","title":"Sourcetype and Index Configuration"},{"location":"sources/Radware/#filter-type","text":"MSG Parsing","title":"Filter type"},{"location":"sources/Radware/#setup-and-configuration","text":"","title":"Setup and Configuration"},{"location":"sources/Radware/#options","text":"Variable default description SC4S_LISTEN_RADWARE_DEFENSEPRO_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_RADWARE_DEFENSEPRO_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_RADWARE_DEFENSEPRO no Enable archive to disk for this specific source SC4S_DEST_RADWARE_DEFENSEPRO_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/Radware/#verification","text":"An active proxy will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=radware:defensepro | stats count by host","title":"Verification"},{"location":"sources/Ricoh/","text":"Vendor - Ricoh \u00b6 Product - MFP \u00b6 Ref Link Splunk Add-on None Product Manual unknown Sourcetypes \u00b6 sourcetype notes ricoh:mfp None Sourcetype and Index Configuration \u00b6 key sourcetype index notes ricoh_syslog ricoh:mfp printer none Filter type \u00b6 MSG Parsing Setup and Configuration \u00b6 Device setup unknown Options \u00b6 Variable default description SC4S_LISTEN_RICOH_SYSLOG_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_RICOH_SYSLOG_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_RICOH_SYSLOG no Enable archive to disk for this specific source SC4S_DEST_RICOH_SYSLOG_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source SC4S_SOURCE_RICOH_SYSLOG_FIXHOST yes Current firmware incorrectly sends the value of HOST in the program field if this is ever corrected this value will need to be set back to no we suggest using yes Verification \u00b6 An active device will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=alcatel:switch | stats count by host","title":"Ricoh"},{"location":"sources/Ricoh/#vendor-ricoh","text":"","title":"Vendor - Ricoh"},{"location":"sources/Ricoh/#product-mfp","text":"Ref Link Splunk Add-on None Product Manual unknown","title":"Product - MFP"},{"location":"sources/Ricoh/#sourcetypes","text":"sourcetype notes ricoh:mfp None","title":"Sourcetypes"},{"location":"sources/Ricoh/#sourcetype-and-index-configuration","text":"key sourcetype index notes ricoh_syslog ricoh:mfp printer none","title":"Sourcetype and Index Configuration"},{"location":"sources/Ricoh/#filter-type","text":"MSG Parsing","title":"Filter type"},{"location":"sources/Ricoh/#setup-and-configuration","text":"Device setup unknown","title":"Setup and Configuration"},{"location":"sources/Ricoh/#options","text":"Variable default description SC4S_LISTEN_RICOH_SYSLOG_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_RICOH_SYSLOG_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_RICOH_SYSLOG no Enable archive to disk for this specific source SC4S_DEST_RICOH_SYSLOG_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source SC4S_SOURCE_RICOH_SYSLOG_FIXHOST yes Current firmware incorrectly sends the value of HOST in the program field if this is ever corrected this value will need to be set back to no we suggest using yes","title":"Options"},{"location":"sources/Ricoh/#verification","text":"An active device will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=alcatel:switch | stats count by host","title":"Verification"},{"location":"sources/Schneider/","text":"Vendor - Schneider \u00b6 Product - APC Power systems \u00b6 Ref Link Splunk Add-on none Product Manual multiple Sourcetypes \u00b6 sourcetype notes apc:syslog None Sourcetype and Index Configuration \u00b6 key sourcetype index notes schneider_apc apc:syslog main none Filter type \u00b6 Port or IP based filter is required Setup and Configuration \u00b6 Options \u00b6 Variable default description SC4S_LISTEN_SCHNEIDER_APC_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_SCHNEIDER_APC_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_SCHNEIDER_APC no Enable archive to disk for this specific source SC4S_DEST_SCHNEIDER_APC_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 An active proxy will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=apc:syslog | stats count by host","title":"Schneider"},{"location":"sources/Schneider/#vendor-schneider","text":"","title":"Vendor - Schneider"},{"location":"sources/Schneider/#product-apc-power-systems","text":"Ref Link Splunk Add-on none Product Manual multiple","title":"Product - APC Power systems"},{"location":"sources/Schneider/#sourcetypes","text":"sourcetype notes apc:syslog None","title":"Sourcetypes"},{"location":"sources/Schneider/#sourcetype-and-index-configuration","text":"key sourcetype index notes schneider_apc apc:syslog main none","title":"Sourcetype and Index Configuration"},{"location":"sources/Schneider/#filter-type","text":"Port or IP based filter is required","title":"Filter type"},{"location":"sources/Schneider/#setup-and-configuration","text":"","title":"Setup and Configuration"},{"location":"sources/Schneider/#options","text":"Variable default description SC4S_LISTEN_SCHNEIDER_APC_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_SCHNEIDER_APC_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_SCHNEIDER_APC no Enable archive to disk for this specific source SC4S_DEST_SCHNEIDER_APC_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/Schneider/#verification","text":"An active proxy will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=apc:syslog | stats count by host","title":"Verification"},{"location":"sources/Simple/","text":"Vendor - Neutral Simple Log path by port \u00b6 Product - multiple \u00b6 The SIMPLE source configuration allows configuration of a log path for SC4S using a single port to a single index/sourcetype combination to quickly onboard new sources that have not been formally supported in the product. Source data must use RFC5424 or a common variant of RFC3164 formatting. NOTE: This is an interim step that should be used only to quickly onboard well-formatted data that is being sent over a unique port. A dedicated log path should be developed for the data source to facilitate further parsing and enrichment, as well as allowing the potential sending of this data source over the default (514) listening port. Splunk Metadata with SIMPLE events \u00b6 The keys (first column) in splunk_metadata.csv for SIMPLE data sources is a user-created key using the vendor_product convention. For example, to on-board a new product first firewall using a source type of first:firewall and index netfw , add the following two lines to the configuration file as shown: first_firewall,index,netfw first_firewall,sourcetype,first:firewall Options \u00b6 For the variables below, replace VENDOR_PRODUCT with the key (converted to upper case) used in the splunk_metadata.csv . Based on the example above, to establish a tcp listener for first firewall we would use SC4S_LISTEN_SIMPLE_FIRST_FIREWALL_TCP_PORT . Variable default description SC4S_LISTEN_SIMPLE_VENDOR_PRODUCT_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_SIMPLE_VENDOR_PRODUCT_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_SIMPLE_VENDOR_PRODUCT_TLS_PORT empty string Enable a TLS port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_SIMPLE_VENDOR_PRODUCT no Enable archive to disk for this specific source SC4S_DEST_SIMPLE_VENDOR_PRODUCT_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Important Notes \u00b6 SIMPLE data sources must use RFC5424 or a common variant of RFC3164 formatting. Each SIMPLE data source must listen on its own unique port list. Port overlap with other sources, either SIMPLE ones or those served by regular log paths, are not allowed and will cause an error at startup. The key(s) chosen for splunk_metadata.csv must be in the form vendor_product (lower case). These same keys can be used for a regular SC4S log path developed in the future. The SIMPLE environment variables must have a core of VENDOR_PRODUCT (upper case). Take care to remove the SIMPLE form of these LISTEN variables after a regular SC4S log path is developed for a given source. You can, of course, continue to listen for this source on the same unique ports after having developed the new log path, but use the SC4S_LISTEN_<VENDOR_PRODUCT>_<protocol>_PORT form of the variable to ensure the newly developed log path will listen on the specified unique ports.","title":"Simple Sources"},{"location":"sources/Simple/#vendor-neutral-simple-log-path-by-port","text":"","title":"Vendor - Neutral Simple Log path by port"},{"location":"sources/Simple/#product-multiple","text":"The SIMPLE source configuration allows configuration of a log path for SC4S using a single port to a single index/sourcetype combination to quickly onboard new sources that have not been formally supported in the product. Source data must use RFC5424 or a common variant of RFC3164 formatting. NOTE: This is an interim step that should be used only to quickly onboard well-formatted data that is being sent over a unique port. A dedicated log path should be developed for the data source to facilitate further parsing and enrichment, as well as allowing the potential sending of this data source over the default (514) listening port.","title":"Product - multiple"},{"location":"sources/Simple/#splunk-metadata-with-simple-events","text":"The keys (first column) in splunk_metadata.csv for SIMPLE data sources is a user-created key using the vendor_product convention. For example, to on-board a new product first firewall using a source type of first:firewall and index netfw , add the following two lines to the configuration file as shown: first_firewall,index,netfw first_firewall,sourcetype,first:firewall","title":"Splunk Metadata with SIMPLE events"},{"location":"sources/Simple/#options","text":"For the variables below, replace VENDOR_PRODUCT with the key (converted to upper case) used in the splunk_metadata.csv . Based on the example above, to establish a tcp listener for first firewall we would use SC4S_LISTEN_SIMPLE_FIRST_FIREWALL_TCP_PORT . Variable default description SC4S_LISTEN_SIMPLE_VENDOR_PRODUCT_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_SIMPLE_VENDOR_PRODUCT_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_SIMPLE_VENDOR_PRODUCT_TLS_PORT empty string Enable a TLS port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_SIMPLE_VENDOR_PRODUCT no Enable archive to disk for this specific source SC4S_DEST_SIMPLE_VENDOR_PRODUCT_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/Simple/#important-notes","text":"SIMPLE data sources must use RFC5424 or a common variant of RFC3164 formatting. Each SIMPLE data source must listen on its own unique port list. Port overlap with other sources, either SIMPLE ones or those served by regular log paths, are not allowed and will cause an error at startup. The key(s) chosen for splunk_metadata.csv must be in the form vendor_product (lower case). These same keys can be used for a regular SC4S log path developed in the future. The SIMPLE environment variables must have a core of VENDOR_PRODUCT (upper case). Take care to remove the SIMPLE form of these LISTEN variables after a regular SC4S log path is developed for a given source. You can, of course, continue to listen for this source on the same unique ports after having developed the new log path, but use the SC4S_LISTEN_<VENDOR_PRODUCT>_<protocol>_PORT form of the variable to ensure the newly developed log path will listen on the specified unique ports.","title":"Important Notes"},{"location":"sources/Sophos/","text":"Vendor - Sophos \u00b6 Product - Web Appliance \u00b6 Ref Link Splunk Add-on None Product Manual unknown Sourcetypes \u00b6 sourcetype notes sophos:webappliance None Sourcetype and Index Configuration \u00b6 key sourcetype index notes sophos_webappliance sophos:webappliance netproxy none Filter type \u00b6 Must use port or NETMASK/host Configure vendor_product_by_source Setup and Configuration \u00b6 Device setup unknown Options \u00b6 Variable default description SC4S_LISTEN_SOPHOS_WEBAPPLIANCE_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_SOPHOS_WEBAPPLIANCE_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_SOPHOS_WEBAPPLIANCE no Enable archive to disk for this specific source SC4S_DEST_SOPHOS_WEBAPPLIANCE_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 An active device will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=sophos:webappliance | stats count by host","title":"Sophos"},{"location":"sources/Sophos/#vendor-sophos","text":"","title":"Vendor - Sophos"},{"location":"sources/Sophos/#product-web-appliance","text":"Ref Link Splunk Add-on None Product Manual unknown","title":"Product - Web Appliance"},{"location":"sources/Sophos/#sourcetypes","text":"sourcetype notes sophos:webappliance None","title":"Sourcetypes"},{"location":"sources/Sophos/#sourcetype-and-index-configuration","text":"key sourcetype index notes sophos_webappliance sophos:webappliance netproxy none","title":"Sourcetype and Index Configuration"},{"location":"sources/Sophos/#filter-type","text":"Must use port or NETMASK/host Configure vendor_product_by_source","title":"Filter type"},{"location":"sources/Sophos/#setup-and-configuration","text":"Device setup unknown","title":"Setup and Configuration"},{"location":"sources/Sophos/#options","text":"Variable default description SC4S_LISTEN_SOPHOS_WEBAPPLIANCE_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_SOPHOS_WEBAPPLIANCE_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_SOPHOS_WEBAPPLIANCE no Enable archive to disk for this specific source SC4S_DEST_SOPHOS_WEBAPPLIANCE_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/Sophos/#verification","text":"An active device will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=sophos:webappliance | stats count by host","title":"Verification"},{"location":"sources/Spectracom/","text":"Vendor - Spectracom \u00b6 Product - NTP Appliance \u00b6 Ref Link Splunk Add-on None Product Manual unknown Sourcetypes \u00b6 sourcetype notes spectracom:ntp None nix:syslog None Sourcetype and Index Configuration \u00b6 key sourcetype index notes spectracom_ntp spectracom:ntp netops none Filter type \u00b6 Must use port or NETMASK and MSG Parsing This appliance is a general purpose linux based OS providing time services. the time server application will be source typed as above while the OS level logs will be processed as nix:syslog Setup and Configuration \u00b6 Device setup unknown Options \u00b6 Variable default description SC4S_LISTEN_SPECTRACOM_NTP_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_SPECTRACOM_NTP_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_SPECTRACOM_NTP no Enable archive to disk for this specific source SC4S_DEST_SPECTRACOM_NTP_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 An active device will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=spectracom:ntp | stats count by host","title":"Spectracom"},{"location":"sources/Spectracom/#vendor-spectracom","text":"","title":"Vendor - Spectracom"},{"location":"sources/Spectracom/#product-ntp-appliance","text":"Ref Link Splunk Add-on None Product Manual unknown","title":"Product - NTP Appliance"},{"location":"sources/Spectracom/#sourcetypes","text":"sourcetype notes spectracom:ntp None nix:syslog None","title":"Sourcetypes"},{"location":"sources/Spectracom/#sourcetype-and-index-configuration","text":"key sourcetype index notes spectracom_ntp spectracom:ntp netops none","title":"Sourcetype and Index Configuration"},{"location":"sources/Spectracom/#filter-type","text":"Must use port or NETMASK and MSG Parsing This appliance is a general purpose linux based OS providing time services. the time server application will be source typed as above while the OS level logs will be processed as nix:syslog","title":"Filter type"},{"location":"sources/Spectracom/#setup-and-configuration","text":"Device setup unknown","title":"Setup and Configuration"},{"location":"sources/Spectracom/#options","text":"Variable default description SC4S_LISTEN_SPECTRACOM_NTP_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_SPECTRACOM_NTP_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_SPECTRACOM_NTP no Enable archive to disk for this specific source SC4S_DEST_SPECTRACOM_NTP_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/Spectracom/#verification","text":"An active device will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=spectracom:ntp | stats count by host","title":"Verification"},{"location":"sources/Splunk/","text":"Vendor - Splunk \u00b6 Product - Splunk Connect for Syslog (SC4S) \u00b6 Ref Link Splunk Add-on https://splunkbase.splunk.com/app/4740/ Product Manual https://splunk-connect-for-syslog.readthedocs.io/en/latest/ Sourcetypes \u00b6 sourcetype notes sc4s:events Internal events from the SC4S container and underlying syslog-ng process sc4s:metrics syslog-ng operational metrics that will be delivered directly to a metrics index in Splunk Sourcetype and Index Configuration \u00b6 key sourcetype index notes sc4s_events all main none sc4s_metrics all em_metrics none Filter type \u00b6 SC4S events and metrics are generated automatically and no specific ports or filters need to be configured for the collection of this data. Setup and Configuration \u00b6 No specific requirements are required for the collection of sc4s internal events. Metrics data is collected by default as traditional events; use of Splunk Metrics is enabled by an opt-in set by the variable SC4S_DEST_SPLUNK_SC4S_METRICS_HEC . See the \u201cOptions\u201d section below for details. Options \u00b6 Variable default description SC4S_DEST_SPLUNK_SC4S_METRICS_HEC event event produce metrics as plain text events; single produce metrics using Splunk Enterprise 7.3 single metrics format; multi produce metrics using Splunk Enterprise 8.x multi metric format SC4S_SOURCE_MARK_MESSAGE_NULLQUEUE yes (yes Verification \u00b6 SC4S will generate versioning events at startup. These startup events can be used to validate HEC is set up properly on the Splunk side. index=<asconfigured> sourcetype=sc4s:events | stats count by host Metrics can be observed via the \u201cAnalytics\u2013>Metrics\u201d navigation in the Search and Reporting app in Splunk. * NOTE: The presentation of metrics is undergoing active development; the delivery of metrics is currently considered an experimental feature.","title":"Splunk"},{"location":"sources/Splunk/#vendor-splunk","text":"","title":"Vendor - Splunk"},{"location":"sources/Splunk/#product-splunk-connect-for-syslog-sc4s","text":"Ref Link Splunk Add-on https://splunkbase.splunk.com/app/4740/ Product Manual https://splunk-connect-for-syslog.readthedocs.io/en/latest/","title":"Product - Splunk Connect for Syslog (SC4S)"},{"location":"sources/Splunk/#sourcetypes","text":"sourcetype notes sc4s:events Internal events from the SC4S container and underlying syslog-ng process sc4s:metrics syslog-ng operational metrics that will be delivered directly to a metrics index in Splunk","title":"Sourcetypes"},{"location":"sources/Splunk/#sourcetype-and-index-configuration","text":"key sourcetype index notes sc4s_events all main none sc4s_metrics all em_metrics none","title":"Sourcetype and Index Configuration"},{"location":"sources/Splunk/#filter-type","text":"SC4S events and metrics are generated automatically and no specific ports or filters need to be configured for the collection of this data.","title":"Filter type"},{"location":"sources/Splunk/#setup-and-configuration","text":"No specific requirements are required for the collection of sc4s internal events. Metrics data is collected by default as traditional events; use of Splunk Metrics is enabled by an opt-in set by the variable SC4S_DEST_SPLUNK_SC4S_METRICS_HEC . See the \u201cOptions\u201d section below for details.","title":"Setup and Configuration"},{"location":"sources/Splunk/#options","text":"Variable default description SC4S_DEST_SPLUNK_SC4S_METRICS_HEC event event produce metrics as plain text events; single produce metrics using Splunk Enterprise 7.3 single metrics format; multi produce metrics using Splunk Enterprise 8.x multi metric format SC4S_SOURCE_MARK_MESSAGE_NULLQUEUE yes (yes","title":"Options"},{"location":"sources/Splunk/#verification","text":"SC4S will generate versioning events at startup. These startup events can be used to validate HEC is set up properly on the Splunk side. index=<asconfigured> sourcetype=sc4s:events | stats count by host Metrics can be observed via the \u201cAnalytics\u2013>Metrics\u201d navigation in the Search and Reporting app in Splunk. * NOTE: The presentation of metrics is undergoing active development; the delivery of metrics is currently considered an experimental feature.","title":"Verification"},{"location":"sources/Tanium/","text":"Vendor - Tanium \u00b6 Product - All \u00b6 This source requires a TLS connection; in most cases enabling TLS and using the default port 6514 is adequate. The source is understood to require a valid certificate. Ref Link Splunk Add-on https://splunkbase.splunk.com/app/4439/ Sourcetypes \u00b6 sourcetype notes tanium none Index Configuration \u00b6 key index notes tanium epintel none Filter type \u00b6 MSG Parse: This filter parses message content timestamp: When present the field Client-Time-UTC will be used as the time source Options \u00b6 Variable default description SC4S_ARCHIVE_TANIUM no Enable archive to disk for this specific source SC4S_DEST_TANIUM_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source SC4S_SOURCE_TLS_ENABLE no This must be set to yes so that SC4S listens for encrypted syslog from ePO Additional setup \u00b6 NOTE: Tanium requires the use of IETF framing and should be configured to use port 601 (DEFAULT) or locally configured RFC6587 port. Use of any other port configuration will cause data corruption. Verification \u00b6 An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=tanium*\")","title":"Tanium"},{"location":"sources/Tanium/#vendor-tanium","text":"","title":"Vendor - Tanium"},{"location":"sources/Tanium/#product-all","text":"This source requires a TLS connection; in most cases enabling TLS and using the default port 6514 is adequate. The source is understood to require a valid certificate. Ref Link Splunk Add-on https://splunkbase.splunk.com/app/4439/","title":"Product - All"},{"location":"sources/Tanium/#sourcetypes","text":"sourcetype notes tanium none","title":"Sourcetypes"},{"location":"sources/Tanium/#index-configuration","text":"key index notes tanium epintel none","title":"Index Configuration"},{"location":"sources/Tanium/#filter-type","text":"MSG Parse: This filter parses message content timestamp: When present the field Client-Time-UTC will be used as the time source","title":"Filter type"},{"location":"sources/Tanium/#options","text":"Variable default description SC4S_ARCHIVE_TANIUM no Enable archive to disk for this specific source SC4S_DEST_TANIUM_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source SC4S_SOURCE_TLS_ENABLE no This must be set to yes so that SC4S listens for encrypted syslog from ePO","title":"Options"},{"location":"sources/Tanium/#additional-setup","text":"NOTE: Tanium requires the use of IETF framing and should be configured to use port 601 (DEFAULT) or locally configured RFC6587 port. Use of any other port configuration will cause data corruption.","title":"Additional setup"},{"location":"sources/Tanium/#verification","text":"An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=tanium*\")","title":"Verification"},{"location":"sources/Tenable/","text":"Vendor - Tenable \u00b6 Product - Tenable.nnm \u00b6 Ref Link Splunk Add-on https://splunkbase.splunk.com/app/4060/ Product Manual https://docs.tenable.com/integrations/Splunk/Content/Splunk2/ProcessWorkflow.htm Sourcetypes \u00b6 sourcetype notes tenable:nnm:vuln None Sourcetype and Index Configuration \u00b6 key sourcetype index notes tenable_nnm tenable:nnm:vuln netfw none Filter type \u00b6 MSG Parsing Options \u00b6 Variable default description SC4S_LISTEN_TENABLE_SYSLOG_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_TENABLE_SYSLOG_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_TENABLE_SYSLOG no Enable archive to disk for this specific source SC4S_DEST_TENABLE_SYSLOG_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 An active device will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=enable:nnm:vuln | stats count by host","title":"Tenable"},{"location":"sources/Tenable/#vendor-tenable","text":"","title":"Vendor - Tenable"},{"location":"sources/Tenable/#product-tenablennm","text":"Ref Link Splunk Add-on https://splunkbase.splunk.com/app/4060/ Product Manual https://docs.tenable.com/integrations/Splunk/Content/Splunk2/ProcessWorkflow.htm","title":"Product - Tenable.nnm"},{"location":"sources/Tenable/#sourcetypes","text":"sourcetype notes tenable:nnm:vuln None","title":"Sourcetypes"},{"location":"sources/Tenable/#sourcetype-and-index-configuration","text":"key sourcetype index notes tenable_nnm tenable:nnm:vuln netfw none","title":"Sourcetype and Index Configuration"},{"location":"sources/Tenable/#filter-type","text":"MSG Parsing","title":"Filter type"},{"location":"sources/Tenable/#options","text":"Variable default description SC4S_LISTEN_TENABLE_SYSLOG_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_TENABLE_SYSLOG_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_TENABLE_SYSLOG no Enable archive to disk for this specific source SC4S_DEST_TENABLE_SYSLOG_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/Tenable/#verification","text":"An active device will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=enable:nnm:vuln | stats count by host","title":"Verification"},{"location":"sources/Thycotic/","text":"Vendor - Tenable \u00b6 Product - Tenable.nnm \u00b6 Ref Link Splunk Add-on https://splunkbase.splunk.com/app/4060/ Product Manual https://docs.tenable.com/integrations/Splunk/Content/Splunk2/ProcessWorkflow.htm Sourcetypes \u00b6 sourcetype notes thycotic:syslog None Sourcetype and Index Configuration \u00b6 key sourcetype index notes Thycotic Software_Secret Server thycotic:syslog netauth none Filter type \u00b6 CEF Options \u00b6 Variable default description Verification \u00b6 An active device will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=thycotic:syslog | stats count by host","title":"Thycotic"},{"location":"sources/Thycotic/#vendor-tenable","text":"","title":"Vendor - Tenable"},{"location":"sources/Thycotic/#product-tenablennm","text":"Ref Link Splunk Add-on https://splunkbase.splunk.com/app/4060/ Product Manual https://docs.tenable.com/integrations/Splunk/Content/Splunk2/ProcessWorkflow.htm","title":"Product - Tenable.nnm"},{"location":"sources/Thycotic/#sourcetypes","text":"sourcetype notes thycotic:syslog None","title":"Sourcetypes"},{"location":"sources/Thycotic/#sourcetype-and-index-configuration","text":"key sourcetype index notes Thycotic Software_Secret Server thycotic:syslog netauth none","title":"Sourcetype and Index Configuration"},{"location":"sources/Thycotic/#filter-type","text":"CEF","title":"Filter type"},{"location":"sources/Thycotic/#options","text":"Variable default description","title":"Options"},{"location":"sources/Thycotic/#verification","text":"An active device will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=thycotic:syslog | stats count by host","title":"Verification"},{"location":"sources/Tintri/","text":"Vendor - TINTRI \u00b6 Product - All \u00b6 This source requires a TLS connection; in most cases enabling TLS and using the default port 6514 is adequate. The source is understood to require a valid certificate. Ref Link Splunk Add-on None Sourcetypes \u00b6 sourcetype notes TINTRI none Index Configuration \u00b6 key index notes TINTRI infraops none Filter type \u00b6 MSG Parse: This filter parses message content generic linux logs will use the os:nix sourcetype Options \u00b6 Variable default description SC4S_ARCHIVE_TINTRI no Enable archive to disk for this specific source SC4S_DEST_TINTRI_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Additional setup \u00b6 NOTE: TINTRI requires the use of IETF framing and should be configured to use port 601 (DEFAULT) or locally configured RFC6587 port. Use of any other port configuration will cause data corruption. Verification \u00b6 An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=tintri*\")","title":"Tintri"},{"location":"sources/Tintri/#vendor-tintri","text":"","title":"Vendor - TINTRI"},{"location":"sources/Tintri/#product-all","text":"This source requires a TLS connection; in most cases enabling TLS and using the default port 6514 is adequate. The source is understood to require a valid certificate. Ref Link Splunk Add-on None","title":"Product - All"},{"location":"sources/Tintri/#sourcetypes","text":"sourcetype notes TINTRI none","title":"Sourcetypes"},{"location":"sources/Tintri/#index-configuration","text":"key index notes TINTRI infraops none","title":"Index Configuration"},{"location":"sources/Tintri/#filter-type","text":"MSG Parse: This filter parses message content generic linux logs will use the os:nix sourcetype","title":"Filter type"},{"location":"sources/Tintri/#options","text":"Variable default description SC4S_ARCHIVE_TINTRI no Enable archive to disk for this specific source SC4S_DEST_TINTRI_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/Tintri/#additional-setup","text":"NOTE: TINTRI requires the use of IETF framing and should be configured to use port 601 (DEFAULT) or locally configured RFC6587 port. Use of any other port configuration will cause data corruption.","title":"Additional setup"},{"location":"sources/Tintri/#verification","text":"An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=tintri*\")","title":"Verification"},{"location":"sources/Trend/","text":"Vendor - Trend Micro \u00b6 Product - Deep Security \u00b6 Ref Link Splunk Add-on CEF https://splunkbase.splunk.com/app/1936/ Sourcetypes \u00b6 sourcetype notes deepsecurity-system_events deepsecurity-intrusion_prevention deepsecurity-integrity_monitoring deepsecurity-log_inspection deepsecurity-web_reputation deepsecurity-firewall deepsecurity-antimalware deepsecurity-app_control Index Configuration \u00b6 key sourcetype index notes Trend Micro_Deep Security Agent deepsecurity epintel Used only if a correct source type is not matched Trend Micro_Deep Security Agent_intrusion prevention deepsecurity-intrusion_prevention epintel Trend Micro_Deep Security Agent_integrity monitoring deepsecurity-integrity_monitoring epintel Trend Micro_Deep Security Agent_log inspection deepsecurity-log_inspection epintel Trend Micro_Deep Security Agent_web reputation deepsecurity-web_reputation epintel Trend Micro_Deep Security Agent_firewall deepsecurity-firewall epintel Trend Micro_Deep Security Agent_antimalware deepsecurity-antimalware epintel Trend Micro_Deep Security Agent_app control deepsecurity-app_control epintel Trend Micro_Deep Security Manager deepsecurity-system_events epintel Filter type \u00b6 MSG Parse: This filter parses message content Options \u00b6 Note: listed for reference; processing utilizes the Microsoft ArcSight log path as this format is a subtype of CEF Variable default description SC4S_LISTEN_CEF_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_CEF_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_CEF no Enable archive to disk for this specific source SC4S_DEST_CEF_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source NOTE: Set only one set of CEF variables for the entire SC4S deployment, regardless of how many ports are in use by this CEF source (or any others). See the \u201cCommon Event Format\u201d source documentation for more information. Verification \u00b6 An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=\"deepsecurity*\")","title":"Trend"},{"location":"sources/Trend/#vendor-trend-micro","text":"","title":"Vendor - Trend Micro"},{"location":"sources/Trend/#product-deep-security","text":"Ref Link Splunk Add-on CEF https://splunkbase.splunk.com/app/1936/","title":"Product - Deep Security"},{"location":"sources/Trend/#sourcetypes","text":"sourcetype notes deepsecurity-system_events deepsecurity-intrusion_prevention deepsecurity-integrity_monitoring deepsecurity-log_inspection deepsecurity-web_reputation deepsecurity-firewall deepsecurity-antimalware deepsecurity-app_control","title":"Sourcetypes"},{"location":"sources/Trend/#index-configuration","text":"key sourcetype index notes Trend Micro_Deep Security Agent deepsecurity epintel Used only if a correct source type is not matched Trend Micro_Deep Security Agent_intrusion prevention deepsecurity-intrusion_prevention epintel Trend Micro_Deep Security Agent_integrity monitoring deepsecurity-integrity_monitoring epintel Trend Micro_Deep Security Agent_log inspection deepsecurity-log_inspection epintel Trend Micro_Deep Security Agent_web reputation deepsecurity-web_reputation epintel Trend Micro_Deep Security Agent_firewall deepsecurity-firewall epintel Trend Micro_Deep Security Agent_antimalware deepsecurity-antimalware epintel Trend Micro_Deep Security Agent_app control deepsecurity-app_control epintel Trend Micro_Deep Security Manager deepsecurity-system_events epintel","title":"Index Configuration"},{"location":"sources/Trend/#filter-type","text":"MSG Parse: This filter parses message content","title":"Filter type"},{"location":"sources/Trend/#options","text":"Note: listed for reference; processing utilizes the Microsoft ArcSight log path as this format is a subtype of CEF Variable default description SC4S_LISTEN_CEF_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_CEF_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_CEF no Enable archive to disk for this specific source SC4S_DEST_CEF_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source NOTE: Set only one set of CEF variables for the entire SC4S deployment, regardless of how many ports are in use by this CEF source (or any others). See the \u201cCommon Event Format\u201d source documentation for more information.","title":"Options"},{"location":"sources/Trend/#verification","text":"An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=\"deepsecurity*\")","title":"Verification"},{"location":"sources/Ubiquiti/","text":"Vendor - Ubiquiti - Unifi \u00b6 All Ubiquity Unfi firewalls, switches, and access points share a common syslog configuration via the NMS. Login to NMS Navigate to settings Navigate to Site Enable Remote syslog server Enter hostname and port Update vi /opt/sc4s/local/context/vendor_product_by_source.conf update the host or ip mask for f_ubiquiti_unifi_fw to identify USG firewalls Product - Unifi Switch and Access Points \u00b6 Unifi devices are managed using the Network Management Controller Ref Link Splunk Add-on https://splunkbase.splunk.com/app/4107/ Product Manual https://https://help.ubnt.com/ Sourcetypes \u00b6 sourcetype notes ubnt Used when no sub source type is required by add on ubnt:fw USG events ubnt:threat USG IDS events ubnt:switch Unifi Switches ubnt:wireless Access Point logs Sourcetype and Index Configuration \u00b6 key sourcetype index notes ubiquiti_unifi ubnt netops none ubiquiti_unifi_fw ubnt:fw netfw none ubiquiti_unifi_link ubnt:link netops none ubiquiti_unifi_sudo ubnt:sudo netops none ubiquiti_unifi_switch ubnt:switch netops none ubiquiti_unifi_threat ubnt:threat netids none ubiquiti_unifi_wireless ubnt:wireless netops none Filter type \u00b6 MSG Parse: This filter parses message content Setup and Configuration \u00b6 Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used the addon is not required on the indexer. Review and update the splunk_metadata.csv file and set the index and sourcetype as required for the data source. Refer to the Splunk TA documentation for the specific customer format required for proxy configuration Select TCP or SSL transport option Ensure the format of the event is customized per Splunk documentation Options \u00b6 Variable default description SC4S_LISTEN_UBIQUITI_UNIFI_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_UBIQUITI_UNIFI_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_UBIQUITI_UNIFI no Enable archive to disk for this specific source SC4S_DEST_UBIQUITI_UNIFI_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 An active proxy will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=zscalernss-* | stats count by host","title":"Ubiquiti"},{"location":"sources/Ubiquiti/#vendor-ubiquiti-unifi","text":"All Ubiquity Unfi firewalls, switches, and access points share a common syslog configuration via the NMS. Login to NMS Navigate to settings Navigate to Site Enable Remote syslog server Enter hostname and port Update vi /opt/sc4s/local/context/vendor_product_by_source.conf update the host or ip mask for f_ubiquiti_unifi_fw to identify USG firewalls","title":"Vendor - Ubiquiti - Unifi"},{"location":"sources/Ubiquiti/#product-unifi-switch-and-access-points","text":"Unifi devices are managed using the Network Management Controller Ref Link Splunk Add-on https://splunkbase.splunk.com/app/4107/ Product Manual https://https://help.ubnt.com/","title":"Product - Unifi Switch and Access Points"},{"location":"sources/Ubiquiti/#sourcetypes","text":"sourcetype notes ubnt Used when no sub source type is required by add on ubnt:fw USG events ubnt:threat USG IDS events ubnt:switch Unifi Switches ubnt:wireless Access Point logs","title":"Sourcetypes"},{"location":"sources/Ubiquiti/#sourcetype-and-index-configuration","text":"key sourcetype index notes ubiquiti_unifi ubnt netops none ubiquiti_unifi_fw ubnt:fw netfw none ubiquiti_unifi_link ubnt:link netops none ubiquiti_unifi_sudo ubnt:sudo netops none ubiquiti_unifi_switch ubnt:switch netops none ubiquiti_unifi_threat ubnt:threat netids none ubiquiti_unifi_wireless ubnt:wireless netops none","title":"Sourcetype and Index Configuration"},{"location":"sources/Ubiquiti/#filter-type","text":"MSG Parse: This filter parses message content","title":"Filter type"},{"location":"sources/Ubiquiti/#setup-and-configuration","text":"Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used the addon is not required on the indexer. Review and update the splunk_metadata.csv file and set the index and sourcetype as required for the data source. Refer to the Splunk TA documentation for the specific customer format required for proxy configuration Select TCP or SSL transport option Ensure the format of the event is customized per Splunk documentation","title":"Setup and Configuration"},{"location":"sources/Ubiquiti/#options","text":"Variable default description SC4S_LISTEN_UBIQUITI_UNIFI_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_UBIQUITI_UNIFI_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_UBIQUITI_UNIFI no Enable archive to disk for this specific source SC4S_DEST_UBIQUITI_UNIFI_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/Ubiquiti/#verification","text":"An active proxy will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=zscalernss-* | stats count by host","title":"Verification"},{"location":"sources/VMWare/","text":"Vendor - Dell - VMware \u00b6 Product - Carbon Black Protection \u00b6 Ref Link Splunk Add-on CEF none Splunk Add-on Source Specific https://bitbucket.org/SPLServices/ta-cef-imperva-incapsula/downloads/ Sourcetypes \u00b6 sourcetype notes cef Common sourcetype Source \u00b6 source notes carbonblack:protection:cef Note this method of onboarding is not recommended for a more complete experience utilize the json format supported by he product with hec or s3 Index Configuration \u00b6 key source index notes Carbon Black_Protection carbonblack:protection:cef epintel none Filter type \u00b6 MSG Parse: This filter parses message content Options \u00b6 Note listed for reference processing utilizes the Microsoft ArcSight log path as this format is a subtype of CEF Variable default description SC4S_LISTEN_CEF_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_CEF_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_CEF no Enable archive to disk for this specific source SC4S_DEST_CEF_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source NOTE: Set only one set of CEF variables for the entire SC4S deployment, regardless of how many ports are in use by this CEF source (or any others). See the \u201cCommon Event Format\u201d source documentation for more information. Verification \u00b6 An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=cef source=\"carbonblack:protection:cef\") Product - vSphere - ESX NSX (Controller, Manager, Edge) \u00b6 Ref Link Splunk Add-on None Manual https://docs.vmware.com/en/VMware-NSX-Data-Center-for-vSphere/6.4/com.vmware.nsx.logging.doc/GUID-0674A29A-9D61-4E36-A302-E4192A3DA1A5.html Sourcetypes \u00b6 sourcetype notes vmware:vsphere:nsx None vmware:vsphere:esx None vmware:vsphere:vcenter None nix:syslog When used with a default port, this will follow the generic NIX configuration. When using a dedicated port, IP or host rules events will follow the index configuration for vmware nsx Sourcetype and Index Configuration \u00b6 key sourcetype index notes vmware_esx vmware:vsphere:esx main none vmware_nsx vmware:vsphere:nsx main none vmware_vcenter vmware:vsphere:vcenter main none Filter type \u00b6 MSG Parse: This filter parses message content when using the default configuration Setup and Configuration \u00b6 Review and update the splunk_metadata.csv file and set the index and sourcetype as required for the data source. Refer to the Splunk TA documentation for the specific customer format required for proxy configuration Select TCP or SSL transport option Ensure the format of the event is customized per Splunk documentation Options \u00b6 Variable default description SC4S_LISTEN_VMWARE_VSPHERE_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_VMWARE_VSPHERE_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_VMWARE_VSPHERE_TLS_PORT empty string Enable a TLS port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_VMWARE_VSPHERE no Enable archive to disk for this specific source SC4S_DEST_VMWARE_VSPHERE_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 An active proxy will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=\"vmware:vsphere:*\" | stats count by host Vendor - Dell - VMware \u00b6 Product - Horizon View \u00b6 Ref Link Splunk Add-on None Manual unknown Sourcetypes \u00b6 sourcetype notes vmware:horizon None nix:syslog When used with a default port this will follow the generic NIX configuration when using a dedicated port, IP or host rules events will follow the index configuration for vmware nsx Sourcetype and Index Configuration \u00b6 key sourcetype index notes vmware_horizon vmware:horizon main none Filter type \u00b6 MSG Parse: This filter parses message content when using the default configuration Setup and Configuration \u00b6 Review and update the splunk_metadata.csv file and set the index and sourcetype as required for the data source. Refer to the Splunk TA documentation for the specific customer format required for proxy configuration Select TCP or SSL transport option Ensure the format of the event is customized per Splunk documentation Options \u00b6 Variable default description SC4S_LISTEN_VMWARE_VSPHERE_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_VMWARE_VSPHERE_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_VMWARE_VSPHERE_TLS_PORT empty string Enable a TLS port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_VMWARE_VSPHERE no Enable archive to disk for this specific source SC4S_DEST_VMWARE_VSPHERE_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 An active device will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=\"vmware:horizon\" | stats count by host","title":"VMware"},{"location":"sources/VMWare/#vendor-dell-vmware","text":"","title":"Vendor - Dell - VMware"},{"location":"sources/VMWare/#product-carbon-black-protection","text":"Ref Link Splunk Add-on CEF none Splunk Add-on Source Specific https://bitbucket.org/SPLServices/ta-cef-imperva-incapsula/downloads/","title":"Product - Carbon Black Protection"},{"location":"sources/VMWare/#sourcetypes","text":"sourcetype notes cef Common sourcetype","title":"Sourcetypes"},{"location":"sources/VMWare/#source","text":"source notes carbonblack:protection:cef Note this method of onboarding is not recommended for a more complete experience utilize the json format supported by he product with hec or s3","title":"Source"},{"location":"sources/VMWare/#index-configuration","text":"key source index notes Carbon Black_Protection carbonblack:protection:cef epintel none","title":"Index Configuration"},{"location":"sources/VMWare/#filter-type","text":"MSG Parse: This filter parses message content","title":"Filter type"},{"location":"sources/VMWare/#options","text":"Note listed for reference processing utilizes the Microsoft ArcSight log path as this format is a subtype of CEF Variable default description SC4S_LISTEN_CEF_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_CEF_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_CEF no Enable archive to disk for this specific source SC4S_DEST_CEF_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source NOTE: Set only one set of CEF variables for the entire SC4S deployment, regardless of how many ports are in use by this CEF source (or any others). See the \u201cCommon Event Format\u201d source documentation for more information.","title":"Options"},{"location":"sources/VMWare/#verification","text":"An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=cef source=\"carbonblack:protection:cef\")","title":"Verification"},{"location":"sources/VMWare/#product-vsphere-esx-nsx-controller-manager-edge","text":"Ref Link Splunk Add-on None Manual https://docs.vmware.com/en/VMware-NSX-Data-Center-for-vSphere/6.4/com.vmware.nsx.logging.doc/GUID-0674A29A-9D61-4E36-A302-E4192A3DA1A5.html","title":"Product - vSphere - ESX NSX (Controller, Manager, Edge)"},{"location":"sources/VMWare/#sourcetypes_1","text":"sourcetype notes vmware:vsphere:nsx None vmware:vsphere:esx None vmware:vsphere:vcenter None nix:syslog When used with a default port, this will follow the generic NIX configuration. When using a dedicated port, IP or host rules events will follow the index configuration for vmware nsx","title":"Sourcetypes"},{"location":"sources/VMWare/#sourcetype-and-index-configuration","text":"key sourcetype index notes vmware_esx vmware:vsphere:esx main none vmware_nsx vmware:vsphere:nsx main none vmware_vcenter vmware:vsphere:vcenter main none","title":"Sourcetype and Index Configuration"},{"location":"sources/VMWare/#filter-type_1","text":"MSG Parse: This filter parses message content when using the default configuration","title":"Filter type"},{"location":"sources/VMWare/#setup-and-configuration","text":"Review and update the splunk_metadata.csv file and set the index and sourcetype as required for the data source. Refer to the Splunk TA documentation for the specific customer format required for proxy configuration Select TCP or SSL transport option Ensure the format of the event is customized per Splunk documentation","title":"Setup and Configuration"},{"location":"sources/VMWare/#options_1","text":"Variable default description SC4S_LISTEN_VMWARE_VSPHERE_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_VMWARE_VSPHERE_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_VMWARE_VSPHERE_TLS_PORT empty string Enable a TLS port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_VMWARE_VSPHERE no Enable archive to disk for this specific source SC4S_DEST_VMWARE_VSPHERE_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/VMWare/#verification_1","text":"An active proxy will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=\"vmware:vsphere:*\" | stats count by host","title":"Verification"},{"location":"sources/VMWare/#vendor-dell-vmware_1","text":"","title":"Vendor - Dell - VMware"},{"location":"sources/VMWare/#product-horizon-view","text":"Ref Link Splunk Add-on None Manual unknown","title":"Product - Horizon View"},{"location":"sources/VMWare/#sourcetypes_2","text":"sourcetype notes vmware:horizon None nix:syslog When used with a default port this will follow the generic NIX configuration when using a dedicated port, IP or host rules events will follow the index configuration for vmware nsx","title":"Sourcetypes"},{"location":"sources/VMWare/#sourcetype-and-index-configuration_1","text":"key sourcetype index notes vmware_horizon vmware:horizon main none","title":"Sourcetype and Index Configuration"},{"location":"sources/VMWare/#filter-type_2","text":"MSG Parse: This filter parses message content when using the default configuration","title":"Filter type"},{"location":"sources/VMWare/#setup-and-configuration_1","text":"Review and update the splunk_metadata.csv file and set the index and sourcetype as required for the data source. Refer to the Splunk TA documentation for the specific customer format required for proxy configuration Select TCP or SSL transport option Ensure the format of the event is customized per Splunk documentation","title":"Setup and Configuration"},{"location":"sources/VMWare/#options_2","text":"Variable default description SC4S_LISTEN_VMWARE_VSPHERE_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_VMWARE_VSPHERE_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_VMWARE_VSPHERE_TLS_PORT empty string Enable a TLS port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_VMWARE_VSPHERE no Enable archive to disk for this specific source SC4S_DEST_VMWARE_VSPHERE_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/VMWare/#verification_2","text":"An active device will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=\"vmware:horizon\" | stats count by host","title":"Verification"},{"location":"sources/Varonis/","text":"Vendor - Varonis \u00b6 Product - DatAlert \u00b6 Ref Link Technology Add-On for Varonis https://splunkbase.splunk.com/app/4256/ Sourcetypes \u00b6 sourcetype notes veronis:ta Index Configuration \u00b6 key sourcetype index notes Varonis Inc._DatAdvantage varonis:ta main Filter type \u00b6 MSG Parse: This filter parses message content Options \u00b6 Note: listed for reference; processing utilizes the Microsoft ArcSight log path as this format is a subtype of CEF Variable default description SC4S_LISTEN_CEF_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_CEF_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_CEF no Enable archive to disk for this specific source SC4S_DEST_CEF_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source NOTE: Set only one set of CEF variables for the entire SC4S deployment, regardless of how many ports are in use by this CEF source (or any others). See the \u201cCommon Event Format\u201d source documentation for more information. Verification \u00b6 An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=\"deepsecurity*\")","title":"Varonis"},{"location":"sources/Varonis/#vendor-varonis","text":"","title":"Vendor - Varonis"},{"location":"sources/Varonis/#product-datalert","text":"Ref Link Technology Add-On for Varonis https://splunkbase.splunk.com/app/4256/","title":"Product - DatAlert"},{"location":"sources/Varonis/#sourcetypes","text":"sourcetype notes veronis:ta","title":"Sourcetypes"},{"location":"sources/Varonis/#index-configuration","text":"key sourcetype index notes Varonis Inc._DatAdvantage varonis:ta main","title":"Index Configuration"},{"location":"sources/Varonis/#filter-type","text":"MSG Parse: This filter parses message content","title":"Filter type"},{"location":"sources/Varonis/#options","text":"Note: listed for reference; processing utilizes the Microsoft ArcSight log path as this format is a subtype of CEF Variable default description SC4S_LISTEN_CEF_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_CEF_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_CEF no Enable archive to disk for this specific source SC4S_DEST_CEF_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source NOTE: Set only one set of CEF variables for the entire SC4S deployment, regardless of how many ports are in use by this CEF source (or any others). See the \u201cCommon Event Format\u201d source documentation for more information.","title":"Options"},{"location":"sources/Varonis/#verification","text":"An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=\"deepsecurity*\")","title":"Verification"},{"location":"sources/Vectra/","text":"Vendor - Vectra \u00b6 Product - Cognito \u00b6 Ref Link Technology Add-On for Vectra Cognito https://splunkbase.splunk.com/app/4408/ Sourcetypes \u00b6 sourcetype notes vectra:cognito:detect vectra:cognito:accountdetect vectra:cognito:accountscoring vectra:cognito:audit vectra:cognito:campaigns vectra:cognito:health vectra:cognito:hostscoring vectra:cognito:accountlockdown Index Configuration \u00b6 key sourcetype index notes Vectra Networks_X Series vectra:cognito:detect main Vectra Networks_X Series_accountdetect vectra:cognito:accountdetect main Vectra Networks_X Series_asc vectra:cognito:accountscoring main Vectra Networks_X Series_audit vectra:cognito:audit main Vectra Networks_X Series_campaigns vectra:cognito:campaigns main Vectra Networks_X Series_health vectra:cognito:health main Vectra Networks_X Series_hsc vectra:cognito:hostscoring main Vectra Networks_X Series_lockdown vectra:cognito:accountlockdown main Filter type \u00b6 MSG Parse: This filter parses message content Options \u00b6 Note: listed for reference; processing utilizes the Microsoft ArcSight log path as this format is a subtype of CEF Variable default description SC4S_LISTEN_CEF_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_CEF_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_CEF no Enable archive to disk for this specific source SC4S_DEST_CEF_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source NOTE: Set only one set of CEF variables for the entire SC4S deployment, regardless of how many ports are in use by this CEF source (or any others). See the \u201cCommon Event Format\u201d source documentation for more information. Verification \u00b6 An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=\"deepsecurity*\")","title":"Vectra"},{"location":"sources/Vectra/#vendor-vectra","text":"","title":"Vendor - Vectra"},{"location":"sources/Vectra/#product-cognito","text":"Ref Link Technology Add-On for Vectra Cognito https://splunkbase.splunk.com/app/4408/","title":"Product - Cognito"},{"location":"sources/Vectra/#sourcetypes","text":"sourcetype notes vectra:cognito:detect vectra:cognito:accountdetect vectra:cognito:accountscoring vectra:cognito:audit vectra:cognito:campaigns vectra:cognito:health vectra:cognito:hostscoring vectra:cognito:accountlockdown","title":"Sourcetypes"},{"location":"sources/Vectra/#index-configuration","text":"key sourcetype index notes Vectra Networks_X Series vectra:cognito:detect main Vectra Networks_X Series_accountdetect vectra:cognito:accountdetect main Vectra Networks_X Series_asc vectra:cognito:accountscoring main Vectra Networks_X Series_audit vectra:cognito:audit main Vectra Networks_X Series_campaigns vectra:cognito:campaigns main Vectra Networks_X Series_health vectra:cognito:health main Vectra Networks_X Series_hsc vectra:cognito:hostscoring main Vectra Networks_X Series_lockdown vectra:cognito:accountlockdown main","title":"Index Configuration"},{"location":"sources/Vectra/#filter-type","text":"MSG Parse: This filter parses message content","title":"Filter type"},{"location":"sources/Vectra/#options","text":"Note: listed for reference; processing utilizes the Microsoft ArcSight log path as this format is a subtype of CEF Variable default description SC4S_LISTEN_CEF_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_CEF_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_CEF no Enable archive to disk for this specific source SC4S_DEST_CEF_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source NOTE: Set only one set of CEF variables for the entire SC4S deployment, regardless of how many ports are in use by this CEF source (or any others). See the \u201cCommon Event Format\u201d source documentation for more information.","title":"Options"},{"location":"sources/Vectra/#verification","text":"An active site will generate frequent events use the following search to check for new events Verify timestamp, and host values match as expected index=<asconfigured> (sourcetype=\"deepsecurity*\")","title":"Verification"},{"location":"sources/Wallix/","text":"Vendor - Wallix \u00b6 Product - Bastion \u00b6 Ref Link Splunk Add-on https://splunkbase.splunk.com/app/3661/ Sourcetypes \u00b6 sourcetype notes WB:syslog note this sourcetype includes program:rdproxy all other data will be treated as nix Sourcetype and Index Configuration \u00b6 key sourcetype index notes WB:syslog infraops main none Filter type \u00b6 MSG Parse: This filter parses message content Variable default description SC4S_LISTEN_WALLIX_PROXY_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_WALLIX_PROXY_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_WALLIX_PROXY no Enable archive to disk for this specific source SC4S_DEST_WALLIX_PROXY_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 An active proxy will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=WB:* | stats count by host","title":"Wallix"},{"location":"sources/Wallix/#vendor-wallix","text":"","title":"Vendor - Wallix"},{"location":"sources/Wallix/#product-bastion","text":"Ref Link Splunk Add-on https://splunkbase.splunk.com/app/3661/","title":"Product - Bastion"},{"location":"sources/Wallix/#sourcetypes","text":"sourcetype notes WB:syslog note this sourcetype includes program:rdproxy all other data will be treated as nix","title":"Sourcetypes"},{"location":"sources/Wallix/#sourcetype-and-index-configuration","text":"key sourcetype index notes WB:syslog infraops main none","title":"Sourcetype and Index Configuration"},{"location":"sources/Wallix/#filter-type","text":"MSG Parse: This filter parses message content Variable default description SC4S_LISTEN_WALLIX_PROXY_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_WALLIX_PROXY_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_WALLIX_PROXY no Enable archive to disk for this specific source SC4S_DEST_WALLIX_PROXY_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Filter type"},{"location":"sources/Wallix/#verification","text":"An active proxy will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=WB:* | stats count by host","title":"Verification"},{"location":"sources/Zscaler/","text":"Vendor - Zscaler \u00b6 Product - ZIA \u00b6 The ZScaler product manual includes and extensive section of configuration for multiple Splunk TCP input ports around page 26. When using SC4S these ports are not required and should not be used. Simply configure all outputs from the NSS to utilize the IP or host name of the SC4S instance and port 514 Ref Link Splunk Add-on https://splunkbase.splunk.com/app/3865/ Product Manual https://community.zscaler.com/t/zscaler-splunk-app-design-and-installation-documentation/4728 Sourcetypes \u00b6 sourcetype notes zscalernss-alerts Requires format customization add \\tvendor=Zscaler\\tproduct=alerts immediately prior to the \\n in the NSS Alert Web format. See Zscaler manual for more info. zscalernss-dns Requires format customization add \\tvendor=Zscaler\\tproduct=dns immediately prior to the \\n in the NSS DNS format. See Zscaler manual for more info. zscalernss-web None zscalernss-fw Requires format customization add \\tvendor=Zscaler\\tproduct=fw immediately prior to the \\n in the Firewall format. See Zscaler manual for more info. Sourcetype and Index Configuration \u00b6 key sourcetype index notes zscaler_alerts zscalernss-alerts main none zscaler_dns zscalernss-dns netdns none zscaler_fw zscalernss-fw netfw none zscaler_web zscalernss-web netproxy none zscaler_zia_audit zscalernss-zia-audit netops none zscaler_zia_sandbox zscalernss-zia-sandbox main none Filter type \u00b6 MSG Parse: This filter parses message content Setup and Configuration \u00b6 Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used the addon is not required on the indexer. Review and update the splunk_metadata.csv file and set the index and sourcetype as required for the data source. Refer to the Splunk TA documentation for the specific customer format required for proxy configuration Select TCP or SSL transport option Ensure the format of the event is customized per Splunk documentation Options \u00b6 Variable default description SC4S_LISTEN_ZSCALER_NSS_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_ZSCALER_NSS_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_ZSCALER_NSS no Enable archive to disk for this specific source SC4S_DEST_ZSCALER_NSS_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 An active proxy will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=zscalernss-* | stats count by host Product - LSS \u00b6 The ZScaler product manual includes and extensive section of configuration for multiple Splunk TCP input ports around page 26. When using SC4S these ports are not required and should not be used. Simply configure all outputs from the LSS to utilize the IP or host name of the SC4S instance and port 514 Ref Link Splunk Add-on https://splunkbase.splunk.com/app/3865/ Product Manual https://community.zscaler.com/t/zscaler-splunk-app-design-and-installation-documentation/4728 Sourcetypes \u00b6 sourcetype notes zscalerlss-zpa-app None zscalerlss-zpa-auth None zscalerlss-zpa-bba None zscalerlss-zpa-connector None Sourcetype and Index Configuration \u00b6 key sourcetype index notes zscaler_lss zscalerlss_zpa-app netproxy none zscaler_lss zscalerlss_zpa_auth netproxy none zscaler_lss zscalerlss_zpa_auth netproxy none zscaler_lss zscalerlss_zpa_connector netproxy none Filter type \u00b6 MSG Parse: This filter parses message content Setup and Configuration \u00b6 Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used the addon is not required on the indexer. Review and update the splunk_metadata.csv file and set the index and sourcetype as required for the data source. Refer to the Splunk TA documentation for the specific customer format required for proxy configuration Select TCP or SSL transport option Ensure the format of the event is customized per Splunk documentation Options \u00b6 Variable default description SC4S_LISTEN_ZSCALER_LSS_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_ZSCALER_LSS_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_ZSCALER_LSS no Enable archive to disk for this specific source SC4S_DEST_ZSCALER_LSS_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 An active proxy will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=zscalernss-* | stats count by host","title":"Zscaler"},{"location":"sources/Zscaler/#vendor-zscaler","text":"","title":"Vendor - Zscaler"},{"location":"sources/Zscaler/#product-zia","text":"The ZScaler product manual includes and extensive section of configuration for multiple Splunk TCP input ports around page 26. When using SC4S these ports are not required and should not be used. Simply configure all outputs from the NSS to utilize the IP or host name of the SC4S instance and port 514 Ref Link Splunk Add-on https://splunkbase.splunk.com/app/3865/ Product Manual https://community.zscaler.com/t/zscaler-splunk-app-design-and-installation-documentation/4728","title":"Product - ZIA"},{"location":"sources/Zscaler/#sourcetypes","text":"sourcetype notes zscalernss-alerts Requires format customization add \\tvendor=Zscaler\\tproduct=alerts immediately prior to the \\n in the NSS Alert Web format. See Zscaler manual for more info. zscalernss-dns Requires format customization add \\tvendor=Zscaler\\tproduct=dns immediately prior to the \\n in the NSS DNS format. See Zscaler manual for more info. zscalernss-web None zscalernss-fw Requires format customization add \\tvendor=Zscaler\\tproduct=fw immediately prior to the \\n in the Firewall format. See Zscaler manual for more info.","title":"Sourcetypes"},{"location":"sources/Zscaler/#sourcetype-and-index-configuration","text":"key sourcetype index notes zscaler_alerts zscalernss-alerts main none zscaler_dns zscalernss-dns netdns none zscaler_fw zscalernss-fw netfw none zscaler_web zscalernss-web netproxy none zscaler_zia_audit zscalernss-zia-audit netops none zscaler_zia_sandbox zscalernss-zia-sandbox main none","title":"Sourcetype and Index Configuration"},{"location":"sources/Zscaler/#filter-type","text":"MSG Parse: This filter parses message content","title":"Filter type"},{"location":"sources/Zscaler/#setup-and-configuration","text":"Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used the addon is not required on the indexer. Review and update the splunk_metadata.csv file and set the index and sourcetype as required for the data source. Refer to the Splunk TA documentation for the specific customer format required for proxy configuration Select TCP or SSL transport option Ensure the format of the event is customized per Splunk documentation","title":"Setup and Configuration"},{"location":"sources/Zscaler/#options","text":"Variable default description SC4S_LISTEN_ZSCALER_NSS_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_ZSCALER_NSS_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_ZSCALER_NSS no Enable archive to disk for this specific source SC4S_DEST_ZSCALER_NSS_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/Zscaler/#verification","text":"An active proxy will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=zscalernss-* | stats count by host","title":"Verification"},{"location":"sources/Zscaler/#product-lss","text":"The ZScaler product manual includes and extensive section of configuration for multiple Splunk TCP input ports around page 26. When using SC4S these ports are not required and should not be used. Simply configure all outputs from the LSS to utilize the IP or host name of the SC4S instance and port 514 Ref Link Splunk Add-on https://splunkbase.splunk.com/app/3865/ Product Manual https://community.zscaler.com/t/zscaler-splunk-app-design-and-installation-documentation/4728","title":"Product - LSS"},{"location":"sources/Zscaler/#sourcetypes_1","text":"sourcetype notes zscalerlss-zpa-app None zscalerlss-zpa-auth None zscalerlss-zpa-bba None zscalerlss-zpa-connector None","title":"Sourcetypes"},{"location":"sources/Zscaler/#sourcetype-and-index-configuration_1","text":"key sourcetype index notes zscaler_lss zscalerlss_zpa-app netproxy none zscaler_lss zscalerlss_zpa_auth netproxy none zscaler_lss zscalerlss_zpa_auth netproxy none zscaler_lss zscalerlss_zpa_connector netproxy none","title":"Sourcetype and Index Configuration"},{"location":"sources/Zscaler/#filter-type_1","text":"MSG Parse: This filter parses message content","title":"Filter type"},{"location":"sources/Zscaler/#setup-and-configuration_1","text":"Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used the addon is not required on the indexer. Review and update the splunk_metadata.csv file and set the index and sourcetype as required for the data source. Refer to the Splunk TA documentation for the specific customer format required for proxy configuration Select TCP or SSL transport option Ensure the format of the event is customized per Splunk documentation","title":"Setup and Configuration"},{"location":"sources/Zscaler/#options_1","text":"Variable default description SC4S_LISTEN_ZSCALER_LSS_TCP_PORT empty string Enable a TCP port for this specific vendor product using a comma-separated list of port numbers SC4S_LISTEN_ZSCALER_LSS_UDP_PORT empty string Enable a UDP port for this specific vendor product using a comma-separated list of port numbers SC4S_ARCHIVE_ZSCALER_LSS no Enable archive to disk for this specific source SC4S_DEST_ZSCALER_LSS_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/Zscaler/#verification_1","text":"An active proxy will generate frequent events. Use the following search to validate events are present per source device index=<asconfigured> sourcetype=zscalernss-* | stats count by host","title":"Verification"},{"location":"sources/nix/","text":"Vendor - Nix Generic \u00b6 Product - All Products \u00b6 Many appliance vendor utilize Linux and BSD distributions as the foundation of the solution. When configured to log via syslog, these devices\u2019 OS logs (from a security perspective) can be monitored using the common Splunk Nix TA. Note: This is NOT a replacement for or alternative to the Splunk Universal forwarder on Linux and Unix. For general-purpose server applications, the Universal Forwarder offers more comprehensive collection of events and metrics appropriate for both security and operations use cases. Ref Link Splunk Add-on https://splunkbase.splunk.com/app/833/ Sourcetypes \u00b6 sourcetype notes nix:syslog None Sourcetype and Index Configuration \u00b6 key sourcetype index notes nix_syslog nix:syslog osnix none Filter type \u00b6 MSG Parse: This filter parses message content Setup and Configuration \u00b6 Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used the addon is not required on the indexer. Review and update the splunk_metadata.csv file and set the index and sourcetype as required for the data source. Options \u00b6 Variable default description SC4S_ARCHIVE_NIX_SYSLOG no Enable archive to disk for this specific source SC4S_DEST_NIX_SYSLOG_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source Verification \u00b6 An active proxy will generate frequent events. Use the following search to validate events are present per source device index=osnix sourcetype=nix:syslog | stats count by host","title":"Nix"},{"location":"sources/nix/#vendor-nix-generic","text":"","title":"Vendor - Nix Generic"},{"location":"sources/nix/#product-all-products","text":"Many appliance vendor utilize Linux and BSD distributions as the foundation of the solution. When configured to log via syslog, these devices\u2019 OS logs (from a security perspective) can be monitored using the common Splunk Nix TA. Note: This is NOT a replacement for or alternative to the Splunk Universal forwarder on Linux and Unix. For general-purpose server applications, the Universal Forwarder offers more comprehensive collection of events and metrics appropriate for both security and operations use cases. Ref Link Splunk Add-on https://splunkbase.splunk.com/app/833/","title":"Product - All Products"},{"location":"sources/nix/#sourcetypes","text":"sourcetype notes nix:syslog None","title":"Sourcetypes"},{"location":"sources/nix/#sourcetype-and-index-configuration","text":"key sourcetype index notes nix_syslog nix:syslog osnix none","title":"Sourcetype and Index Configuration"},{"location":"sources/nix/#filter-type","text":"MSG Parse: This filter parses message content","title":"Filter type"},{"location":"sources/nix/#setup-and-configuration","text":"Install the Splunk Add-on on the search head(s) for the user communities interested in this data source. If SC4S is exclusively used the addon is not required on the indexer. Review and update the splunk_metadata.csv file and set the index and sourcetype as required for the data source.","title":"Setup and Configuration"},{"location":"sources/nix/#options","text":"Variable default description SC4S_ARCHIVE_NIX_SYSLOG no Enable archive to disk for this specific source SC4S_DEST_NIX_SYSLOG_HEC no When Splunk HEC is disabled globally set to yes to enable this specific source","title":"Options"},{"location":"sources/nix/#verification","text":"An active proxy will generate frequent events. Use the following search to validate events are present per source device index=osnix sourcetype=nix:syslog | stats count by host","title":"Verification"},{"location":"troubleshooting/troubleshoot_SC4S_server/","text":"SC4S Server Startup and Operational Validation \u00b6 The following sections will guide the administrator to the most commons solutions to startup and operational issues with SC4S. In general, if you are just starting out with SC4S and wish to simply run with the \u201cstock\u201d configuration, startup out of systemd is recommended. If, on the other hand, you are in the depths of a custom configuration of SC4S with significant modifications (such as multiple unique ports for sources, hostname/CIDR block configuration for sources, new log paths, etc.) then it is best to start SC4S with the container runtime command ( podman or docker ) directly from the command line (below). When you are satisfied with the operation, a transition to systemd can then be made. systemd Errors During SC4S Startup \u00b6 Most issues that occur with startup and operation of sc4s typically involve syntax errors or duplicate listening ports. If you are running out of systemd, you may see this at startup: [ root@sc4s syslog-ng ] # systemctl start sc4s Job for sc4s.service failed because the control process exited with error code. See \"systemctl status sc4s.service\" and \"journalctl -xe\" for details. Follow the checks below to resolve the issue: Is the SC4S container running? \u00b6 There may be nothing untoward after starting with systemd, but the container is not running at all after checking with podman logs SC4S or podman ps . A more informative command than journalctl -xe is the following, journalctl -b -u sc4s | tail -100 which will print the last 100 lines of the system journal in far more detail, which should be sufficient to see the specific failure (syntax or runtime) and guide you in troubleshooting why the container exited unexpectedly. Does the SC4S container start (and run) properly outside of the systemd service environment? \u00b6 As an alternative to launching via systemd during the initial installation phase, you may wish to test the container startup outside of the systemd startup environment. This alternative should be considered required when undergoing heavy troubleshooting or log path development (e.g. when SC4S_DEBUG_CONTAINER is set to \u201cyes\u201d). The following command will launch the container directly from the CLI. This command assumes the local mounted directories are set up as shown in the \u201cgetting started\u201d examples; adjust for your local requirements: /usr/bin/podman run \\ -v splunk-sc4s-var:/var/lib/syslog-ng \\ -v /opt/sc4s/local:/etc/syslog-ng/conf.d/local:z \\ -v /opt/sc4s/archive:/var/lib/syslog-ng/archive:z \\ -v /opt/sc4s/tls:/etc/syslog-ng/tls:z \\ --env-file = /opt/sc4s/env_file \\ --network host \\ --name SC4S \\ --rm splunk/scs:latest If you are using docker, substitute \u201cdocker\u201d for \u201cpodman\u201d for the container runtime command above. Is the container still running (when systemd thinks it\u2019s not)? \u00b6 In some instances, (particularly when SC4S_DEBUG_CONTAINER=yes ) an SC4S container might not shut down completely when starting/stopping out of systemd, and systemd will attempt to start a new container when one is already running with the SC4S name. You will see this type of output when viewing the journal after a failed start caused by this condition, or a similar message when the container is run directly from the CLI: Jul 15 18:45:20 sra-sc4s-alln01-02 podman[11187]: Error: error creating container storage: the container name \"SC4S\" is already in use by \"894357502b2a7142d097ea3ca1468d1cb4fbc69959a9817a1bbe145a09d37fb9\". You have to remove that container... Jul 15 18:45:20 sra-sc4s-alln01-02 systemd[1]: sc4s.service: Main process exited, code=exited, status=125/n/a To rectify this, simply execute podman rm -f SC4S SC4S should then start normally. NOTE: This symptom will recur if SC4S_DEBUG_CONTAINER is set to \u201cyes\u201d. Do not attempt to use systemd when this variable is set; use the CLI podman or docker commands directly to start/stop SC4S. HEC/token connection errors (AKA \u201cNo data in Splunk\u201d) \u00b6 SC4S performs basic HEC connectivity and index checks at startup. These indicate general connection issues and indexes that may not be accessible and/or configured on the Splunk side. To check the container logs which contain the results of these tests, run: /usr/bin/<podman | docker> logs SC4S and note the output. You will see entries similar to these: SC4S_ENV_CHECK_HEC : Splunk HEC connection test successful ; checking indexes ... SC4S_ENV_CHECK_INDEX : Checking email { \"text\" : \"Incorrect index\" , \"code\" : 7 , \"invalid-event-number\" : 1 } SC4S_ENV_CHECK_INDEX : Checking epav { \"text\" : \"Incorrect index\" , \"code\" : 7 , \"invalid-event-number\" : 1 } SC4S_ENV_CHECK_INDEX : Checking main { \"text\" : \"Success\" , \"code\" : 0 } Note the specifics of the indexes that are not configured correctly, and rectify in the Splunk configuration. If this is not addressed properly, you may see output similar to the below when data flows into sc4s: Mar 16 19 : 00 : 06 b817af4e89da syslog-ng [ 1 ] : Server returned with a 4XX ( client errors ) status code , which means we are not authorized or the URL is not found .; url = 'https://splunk-instance.com:8088/services/collector/event' , status_code = '400' , driver = 'd_hec#0' , location = '/opt/syslog-ng/etc/conf.d/destinations/splunk_hec.conf:2:5' Mar 16 19 : 00 : 06 b817af4e89da syslog-ng [ 1 ] : Server disconnected while preparing messages for sending , trying again ; driver = 'd_hec#0' , location = '/opt/syslog-ng/etc/conf.d/destinations/splunk_hec.conf:2:5' , worker_index = '4' , time_reopen = '10' , batch_size = '1000' This is an indication that the standard d_hec destination in syslog-ng (which is the route to Splunk) is being rejected by the HEC endpoint. A 400 error (not 404) is normally caused by an index that has not been created on the Splunk side. This can present a serious problem, as just one bad index will \u201ctaint\u201d the entire batch (in this case, 1000 events) and prevent any of them from being sent to Splunk. It is imperative that the container logs be free of these kinds of errors in production. You can use the alternate HEC debug destination (below) to help debug this condition by sending direct \u201ccurl\u201d commands to the HEC endpoint outside of the SC4S setting. Enabling the Alternate HEC Debug Destination \u00b6 To help debug why these 4xx errors are occurring, it is helpful to enable an alternate destination for syslog traffic that will write the contents of the full JSON payload that is intended to be sent to Splunk via HEC. This destination will contain each event, repackaged as a curl command that can be run directly on the command line to see what the response from the HEC endpoint is. To do this, set SC4S_DEST_GLOBAL_ALTERNATES=d_hec_debug in the env_file and restart sc4s. When set, all data destined for Splunk will also be written to /opt/sc4s/archive/debug , and will be further categorized in subdirectories by sourcetype. Here are the things to check: In /opt/sc4s/archive/debug , you will see directories for each sourcetype that sc4s has collected. If you recognize any that you don\u2019t expect, check to see that the index is created in Splunk, or that a lastChanceIndex is created and enabled. This is the cause for almost all 400 errors. If you continue to the individual log entries in these directories, you will see entries of the form curl -k -u \"sc4s HEC debug:a778f63a-5dff-4e3c-a72c-a03183659e94\" \"https://splunk.smg.aws:8088/services/collector/event\" -d '{\"time\":\"1584556114.271\",\"sourcetype\":\"sc4s:events\",\"source\":\"SC4S:s_internal\",\"index\":\"main\",\"host\":\"e3563b0ea5d8\",\"fields\":{\"sc4s_syslog_severity\":\"notice\",\"sc4s_syslog_facility\":\"syslog\",\"sc4s_loghost\":\"e3563b0ea5d8\",\"sc4s_fromhostip\":\"127.0.0.1\"},\"event\":\"syslog-ng starting up; version=' 3 .28.1 '\"}' These commands, with minimal modifications (e.g. multiple URLs specified or elements that needs shell escapes) can be run directly on the command line to determine what, exactly, the HEC endpoint is returning. This can be used to refine the index or other parameter to correct the problem. SC4S Local Disk Resource Considerations \u00b6 Check the HEC connection to Splunk. If the connection is down for a long period of time, the local disk buffer used for backup will exhaust local disk resources. The size of the local disk buffer is configured in the env_file: Disk buffer configuration Check the env_file to see if SC4S_DEST_GLOBAL_ALTERNATES is set to d_hec_debug , d_archive or other file-based destination; all of these will consume significant local disk space. d_hec_debug and d_archive are organized by sourcetype; the du -sh * command can be used in each subdirectory to find the culprit. Try rebuilding sc4s volume podman volume rm splunk - sc4s - var podman volume create splunk - sc4s - var Try pruning containers podman system prune [--all] SC4S/kernel UDP Input Buffer Settings \u00b6 SC4S has a setting that requests a certain buffer size when configuring the UDP sockets. The kernel must have its parameters set to at least the same size (or greater) than the syslog-ng config is requesting, or the following will occur in the SC4S logs: /usr/bin/<podman | docker> logs SC4S Note the output. The following warning message is not a failure condition unless we are reaching the upper limit of hardware performance. The kernel refused to set the receive buffer (SO_RCVBUF) to the requested size, you probably need to adjust buffer related kernel parameters; so_rcvbuf='1703936', so_rcvbuf_set='425984' Make changes to /etc/sysctl.conf. Changing receive buffer values here to 16 MB: net.core.rmem_default = 17039360 net.core.rmem_max = 17039360 Run following commands for changes to be affected. sysctl -p restart SC4S SC4S TLS Listener Validation \u00b6 To verify the correct configuration of the TLS server use the following command. Replace the IP, FQDN, and port as appropriate: <podman | docker> run -ti drwetter/testssl.sh --severity MEDIUM --ip 127 .0.0.1 selfsigned.example.com:6510 Timezone mismatch in events \u00b6 By default, SC4S resolves the timezone to GMT. If customer have a preference to use local TZ then set the user TZ preference in Splunk during search time rather than at index time. Timezone config documentation Dealing with non RFC-5424 compliant sources \u00b6 If a data source you are trying to ingest claims it is RFC-5424 compliant but you are getting an \u201cError processing log message:\u201d from SC4S, the message violates the standard in some way. Unfortunately multiple vendors claim RFC-5424 compliance without fully testing that they are. In this case, the underlying syslog-ng process will send an error event, with the location of the error in the original event highlighted with >@< to indicate where the error occurred. Here is an example error message: { [ - ] ISODATE : 2020 -05-04 T21 : 21 : 59.001 + 00 : 00 MESSAGE : Error processing log message : < 14 > 1 2020 -05-04 T21 : 21 : 58.117351 + 00 : 00 arcata - pks - cluster -1 pod . log / cf - workloads / logspinner - testing -6446 b8ef - - [ kubernetes @47450 cloudfoundry . org / process_type = \"web\" cloudfoundry . org / rootfs - version = \"v75.0.0\" cloudfoundry . org / version = \"eae53cc3-148d-4395-985c-8fef0606b9e3\" controller - revision - hash = \"logspinner-testing-6446b8ef05-7db777754c\" cloudfoundry . org / app_guid = \"f71634fe-34a4-4f89-adac-3e523f61a401\" cloudfoundry . org / source_type = \"APP\" security . istio . io / tlsMode = \"istio\" statefulset . kubernetes . io / pod - n > @ < ame = \"logspinner-testing-6446b8ef05-0\" cloudfoundry . org / guid = \"f71634fe-34a4-4f89-adac-3e523f61a401\" namespace_name = \"cf-workloads\" object_name = \"logspinner-testing-6446b8ef05-0\" container_name = \"opi\" vm_id = \"vm-e34452a3-771e-4994-666e-bfbc7eb77489\" ] Duration 10.00299412 s TotalSent 10 Rate 0.999701 PID : 33 PRI : < 43 > PROGRAM : syslog - ng } In this example the error can be seen in the snippet statefulset.kubernetes.io/pod-n>@<ame . Looking at the spec for RFC5424, it states that the \u201cSD-NAME\u201d (the left-hand side of the name=value pairs) cannot be longer than 32 printable ASCII characters. In this message, the indicated name exceeds that. Unfortunately, this is a spec violation on the part of the vendor. Ideally the vendor would address this violation so their logs would be RFC-5424 compliant. Alternatively, an exception could be added to the SC4S filter log path (or an alternative (workaround) log path created) for the data source if the vendor can\u2019t/won\u2019t fix the defect. In this example, the reason RAWMSG is not shown in the fields above is because this error message is coming from syslog-ng itself \u2013 not the filter/log path. In messages of the type Error processing log message: where the PROGRAM is shown as syslog-ng , that is the clue your incoming message is not RFC-5424 compliant (though it\u2019s often close, as is the case here).","title":"SC4S Startup and Validation"},{"location":"troubleshooting/troubleshoot_SC4S_server/#sc4s-server-startup-and-operational-validation","text":"The following sections will guide the administrator to the most commons solutions to startup and operational issues with SC4S. In general, if you are just starting out with SC4S and wish to simply run with the \u201cstock\u201d configuration, startup out of systemd is recommended. If, on the other hand, you are in the depths of a custom configuration of SC4S with significant modifications (such as multiple unique ports for sources, hostname/CIDR block configuration for sources, new log paths, etc.) then it is best to start SC4S with the container runtime command ( podman or docker ) directly from the command line (below). When you are satisfied with the operation, a transition to systemd can then be made.","title":"SC4S Server Startup and Operational Validation"},{"location":"troubleshooting/troubleshoot_SC4S_server/#systemd-errors-during-sc4s-startup","text":"Most issues that occur with startup and operation of sc4s typically involve syntax errors or duplicate listening ports. If you are running out of systemd, you may see this at startup: [ root@sc4s syslog-ng ] # systemctl start sc4s Job for sc4s.service failed because the control process exited with error code. See \"systemctl status sc4s.service\" and \"journalctl -xe\" for details. Follow the checks below to resolve the issue:","title":"systemd Errors During SC4S Startup"},{"location":"troubleshooting/troubleshoot_SC4S_server/#is-the-sc4s-container-running","text":"There may be nothing untoward after starting with systemd, but the container is not running at all after checking with podman logs SC4S or podman ps . A more informative command than journalctl -xe is the following, journalctl -b -u sc4s | tail -100 which will print the last 100 lines of the system journal in far more detail, which should be sufficient to see the specific failure (syntax or runtime) and guide you in troubleshooting why the container exited unexpectedly.","title":"Is the SC4S container running?"},{"location":"troubleshooting/troubleshoot_SC4S_server/#does-the-sc4s-container-start-and-run-properly-outside-of-the-systemd-service-environment","text":"As an alternative to launching via systemd during the initial installation phase, you may wish to test the container startup outside of the systemd startup environment. This alternative should be considered required when undergoing heavy troubleshooting or log path development (e.g. when SC4S_DEBUG_CONTAINER is set to \u201cyes\u201d). The following command will launch the container directly from the CLI. This command assumes the local mounted directories are set up as shown in the \u201cgetting started\u201d examples; adjust for your local requirements: /usr/bin/podman run \\ -v splunk-sc4s-var:/var/lib/syslog-ng \\ -v /opt/sc4s/local:/etc/syslog-ng/conf.d/local:z \\ -v /opt/sc4s/archive:/var/lib/syslog-ng/archive:z \\ -v /opt/sc4s/tls:/etc/syslog-ng/tls:z \\ --env-file = /opt/sc4s/env_file \\ --network host \\ --name SC4S \\ --rm splunk/scs:latest If you are using docker, substitute \u201cdocker\u201d for \u201cpodman\u201d for the container runtime command above.","title":"Does the SC4S container start (and run) properly outside of the systemd service environment?"},{"location":"troubleshooting/troubleshoot_SC4S_server/#is-the-container-still-running-when-systemd-thinks-its-not","text":"In some instances, (particularly when SC4S_DEBUG_CONTAINER=yes ) an SC4S container might not shut down completely when starting/stopping out of systemd, and systemd will attempt to start a new container when one is already running with the SC4S name. You will see this type of output when viewing the journal after a failed start caused by this condition, or a similar message when the container is run directly from the CLI: Jul 15 18:45:20 sra-sc4s-alln01-02 podman[11187]: Error: error creating container storage: the container name \"SC4S\" is already in use by \"894357502b2a7142d097ea3ca1468d1cb4fbc69959a9817a1bbe145a09d37fb9\". You have to remove that container... Jul 15 18:45:20 sra-sc4s-alln01-02 systemd[1]: sc4s.service: Main process exited, code=exited, status=125/n/a To rectify this, simply execute podman rm -f SC4S SC4S should then start normally. NOTE: This symptom will recur if SC4S_DEBUG_CONTAINER is set to \u201cyes\u201d. Do not attempt to use systemd when this variable is set; use the CLI podman or docker commands directly to start/stop SC4S.","title":"Is the container still running (when systemd thinks it's not)?"},{"location":"troubleshooting/troubleshoot_SC4S_server/#hectoken-connection-errors-aka-no-data-in-splunk","text":"SC4S performs basic HEC connectivity and index checks at startup. These indicate general connection issues and indexes that may not be accessible and/or configured on the Splunk side. To check the container logs which contain the results of these tests, run: /usr/bin/<podman | docker> logs SC4S and note the output. You will see entries similar to these: SC4S_ENV_CHECK_HEC : Splunk HEC connection test successful ; checking indexes ... SC4S_ENV_CHECK_INDEX : Checking email { \"text\" : \"Incorrect index\" , \"code\" : 7 , \"invalid-event-number\" : 1 } SC4S_ENV_CHECK_INDEX : Checking epav { \"text\" : \"Incorrect index\" , \"code\" : 7 , \"invalid-event-number\" : 1 } SC4S_ENV_CHECK_INDEX : Checking main { \"text\" : \"Success\" , \"code\" : 0 } Note the specifics of the indexes that are not configured correctly, and rectify in the Splunk configuration. If this is not addressed properly, you may see output similar to the below when data flows into sc4s: Mar 16 19 : 00 : 06 b817af4e89da syslog-ng [ 1 ] : Server returned with a 4XX ( client errors ) status code , which means we are not authorized or the URL is not found .; url = 'https://splunk-instance.com:8088/services/collector/event' , status_code = '400' , driver = 'd_hec#0' , location = '/opt/syslog-ng/etc/conf.d/destinations/splunk_hec.conf:2:5' Mar 16 19 : 00 : 06 b817af4e89da syslog-ng [ 1 ] : Server disconnected while preparing messages for sending , trying again ; driver = 'd_hec#0' , location = '/opt/syslog-ng/etc/conf.d/destinations/splunk_hec.conf:2:5' , worker_index = '4' , time_reopen = '10' , batch_size = '1000' This is an indication that the standard d_hec destination in syslog-ng (which is the route to Splunk) is being rejected by the HEC endpoint. A 400 error (not 404) is normally caused by an index that has not been created on the Splunk side. This can present a serious problem, as just one bad index will \u201ctaint\u201d the entire batch (in this case, 1000 events) and prevent any of them from being sent to Splunk. It is imperative that the container logs be free of these kinds of errors in production. You can use the alternate HEC debug destination (below) to help debug this condition by sending direct \u201ccurl\u201d commands to the HEC endpoint outside of the SC4S setting.","title":"HEC/token connection errors (AKA \u201cNo data in Splunk\u201d)"},{"location":"troubleshooting/troubleshoot_SC4S_server/#enabling-the-alternate-hec-debug-destination","text":"To help debug why these 4xx errors are occurring, it is helpful to enable an alternate destination for syslog traffic that will write the contents of the full JSON payload that is intended to be sent to Splunk via HEC. This destination will contain each event, repackaged as a curl command that can be run directly on the command line to see what the response from the HEC endpoint is. To do this, set SC4S_DEST_GLOBAL_ALTERNATES=d_hec_debug in the env_file and restart sc4s. When set, all data destined for Splunk will also be written to /opt/sc4s/archive/debug , and will be further categorized in subdirectories by sourcetype. Here are the things to check: In /opt/sc4s/archive/debug , you will see directories for each sourcetype that sc4s has collected. If you recognize any that you don\u2019t expect, check to see that the index is created in Splunk, or that a lastChanceIndex is created and enabled. This is the cause for almost all 400 errors. If you continue to the individual log entries in these directories, you will see entries of the form curl -k -u \"sc4s HEC debug:a778f63a-5dff-4e3c-a72c-a03183659e94\" \"https://splunk.smg.aws:8088/services/collector/event\" -d '{\"time\":\"1584556114.271\",\"sourcetype\":\"sc4s:events\",\"source\":\"SC4S:s_internal\",\"index\":\"main\",\"host\":\"e3563b0ea5d8\",\"fields\":{\"sc4s_syslog_severity\":\"notice\",\"sc4s_syslog_facility\":\"syslog\",\"sc4s_loghost\":\"e3563b0ea5d8\",\"sc4s_fromhostip\":\"127.0.0.1\"},\"event\":\"syslog-ng starting up; version=' 3 .28.1 '\"}' These commands, with minimal modifications (e.g. multiple URLs specified or elements that needs shell escapes) can be run directly on the command line to determine what, exactly, the HEC endpoint is returning. This can be used to refine the index or other parameter to correct the problem.","title":"Enabling the Alternate HEC Debug Destination"},{"location":"troubleshooting/troubleshoot_SC4S_server/#sc4s-local-disk-resource-considerations","text":"Check the HEC connection to Splunk. If the connection is down for a long period of time, the local disk buffer used for backup will exhaust local disk resources. The size of the local disk buffer is configured in the env_file: Disk buffer configuration Check the env_file to see if SC4S_DEST_GLOBAL_ALTERNATES is set to d_hec_debug , d_archive or other file-based destination; all of these will consume significant local disk space. d_hec_debug and d_archive are organized by sourcetype; the du -sh * command can be used in each subdirectory to find the culprit. Try rebuilding sc4s volume podman volume rm splunk - sc4s - var podman volume create splunk - sc4s - var Try pruning containers podman system prune [--all]","title":"SC4S Local Disk Resource Considerations"},{"location":"troubleshooting/troubleshoot_SC4S_server/#sc4skernel-udp-input-buffer-settings","text":"SC4S has a setting that requests a certain buffer size when configuring the UDP sockets. The kernel must have its parameters set to at least the same size (or greater) than the syslog-ng config is requesting, or the following will occur in the SC4S logs: /usr/bin/<podman | docker> logs SC4S Note the output. The following warning message is not a failure condition unless we are reaching the upper limit of hardware performance. The kernel refused to set the receive buffer (SO_RCVBUF) to the requested size, you probably need to adjust buffer related kernel parameters; so_rcvbuf='1703936', so_rcvbuf_set='425984' Make changes to /etc/sysctl.conf. Changing receive buffer values here to 16 MB: net.core.rmem_default = 17039360 net.core.rmem_max = 17039360 Run following commands for changes to be affected. sysctl -p restart SC4S","title":"SC4S/kernel UDP Input Buffer Settings"},{"location":"troubleshooting/troubleshoot_SC4S_server/#sc4s-tls-listener-validation","text":"To verify the correct configuration of the TLS server use the following command. Replace the IP, FQDN, and port as appropriate: <podman | docker> run -ti drwetter/testssl.sh --severity MEDIUM --ip 127 .0.0.1 selfsigned.example.com:6510","title":"SC4S TLS Listener Validation"},{"location":"troubleshooting/troubleshoot_SC4S_server/#timezone-mismatch-in-events","text":"By default, SC4S resolves the timezone to GMT. If customer have a preference to use local TZ then set the user TZ preference in Splunk during search time rather than at index time. Timezone config documentation","title":"Timezone mismatch in events"},{"location":"troubleshooting/troubleshoot_SC4S_server/#dealing-with-non-rfc-5424-compliant-sources","text":"If a data source you are trying to ingest claims it is RFC-5424 compliant but you are getting an \u201cError processing log message:\u201d from SC4S, the message violates the standard in some way. Unfortunately multiple vendors claim RFC-5424 compliance without fully testing that they are. In this case, the underlying syslog-ng process will send an error event, with the location of the error in the original event highlighted with >@< to indicate where the error occurred. Here is an example error message: { [ - ] ISODATE : 2020 -05-04 T21 : 21 : 59.001 + 00 : 00 MESSAGE : Error processing log message : < 14 > 1 2020 -05-04 T21 : 21 : 58.117351 + 00 : 00 arcata - pks - cluster -1 pod . log / cf - workloads / logspinner - testing -6446 b8ef - - [ kubernetes @47450 cloudfoundry . org / process_type = \"web\" cloudfoundry . org / rootfs - version = \"v75.0.0\" cloudfoundry . org / version = \"eae53cc3-148d-4395-985c-8fef0606b9e3\" controller - revision - hash = \"logspinner-testing-6446b8ef05-7db777754c\" cloudfoundry . org / app_guid = \"f71634fe-34a4-4f89-adac-3e523f61a401\" cloudfoundry . org / source_type = \"APP\" security . istio . io / tlsMode = \"istio\" statefulset . kubernetes . io / pod - n > @ < ame = \"logspinner-testing-6446b8ef05-0\" cloudfoundry . org / guid = \"f71634fe-34a4-4f89-adac-3e523f61a401\" namespace_name = \"cf-workloads\" object_name = \"logspinner-testing-6446b8ef05-0\" container_name = \"opi\" vm_id = \"vm-e34452a3-771e-4994-666e-bfbc7eb77489\" ] Duration 10.00299412 s TotalSent 10 Rate 0.999701 PID : 33 PRI : < 43 > PROGRAM : syslog - ng } In this example the error can be seen in the snippet statefulset.kubernetes.io/pod-n>@<ame . Looking at the spec for RFC5424, it states that the \u201cSD-NAME\u201d (the left-hand side of the name=value pairs) cannot be longer than 32 printable ASCII characters. In this message, the indicated name exceeds that. Unfortunately, this is a spec violation on the part of the vendor. Ideally the vendor would address this violation so their logs would be RFC-5424 compliant. Alternatively, an exception could be added to the SC4S filter log path (or an alternative (workaround) log path created) for the data source if the vendor can\u2019t/won\u2019t fix the defect. In this example, the reason RAWMSG is not shown in the fields above is because this error message is coming from syslog-ng itself \u2013 not the filter/log path. In messages of the type Error processing log message: where the PROGRAM is shown as syslog-ng , that is the clue your incoming message is not RFC-5424 compliant (though it\u2019s often close, as is the case here).","title":"Dealing with non RFC-5424 compliant sources"},{"location":"troubleshooting/troubleshoot_resources/","text":"SC4S Logging and Troubleshooting Resources \u00b6 Helpful Linux and Container Commands \u00b6 Linux service (systemd) commands \u00b6 Check service status systemctl status sc4s Start service systemctl start service Stop service systemctl stop service Restart service systemctl restart service Enabling service at boot systemctl enable sc4s Query the system journal journalctl -b -u sc4s Container Commands \u00b6 NOTE: All container commands below can be run with either runtime ( podman or docker ). Container logs sudo podman> logs SC4S Exec into SC4S container podman exec -it SC4S bash Rebuilding SC4S volume podman volume rm splunk - sc4s - var podman volume create splunk - sc4s - var Pull an image or a repository from a registry podman pull splunk:scs:latest Remove unused data podman system prune Load an image from a tar archive or STDIN podman load <tar> Obtaining \u201cOn-the-wire\u201d Raw Events \u00b6 In almost all cases during development or troubleshooting, you will need to obtain samples of the messages exactly as they are received by SC4S. These \u201craw\u201d events contain the full syslog message (including the <PRI> preamble) and differs from those that appear in Splunk after processing by sc4s and/or Splunk. This is the only way to determine if SC4S parsers and filters are operating correctly, as raw messages are needed for \u201cplayback\u201d when testing. In addition, the community supporting SC4S will always first ask for raw samples (kind of like the way Splunk support always asks for \u201cdiags\u201d) before any development or troubleshooting exercise. Here are some options for obtaining raw logs for one or more sourcetypes: Run tcpdump on the collection interface and display the results in ASCII. You will see events of the form < 165 > 1 2007 -02 -15 T09 : 17 : 15.719 Z router1 mgd 3046 UI_DBASE_LOGOUT_EVENT [ junos @2636.1.1.1.2.18 username = \"user\" ] User ' user ' exiting configuration mode buried in the packet contents. Set the variable SC4S_SOURCE_STORE_RAWMSG=yes in env_file and restart sc4s. This will store the raw message in a syslog-ng macro called RAWMSG and will be displayed in Splunk for all fallback messages. For most other sourcetypes, the RAWMSG is not displayed, but can be surfaced by changing the output template to one of the JSON variants (t_JSON_3164 or t_JSON_5424 depending on RFC message type). See SC4S metadata configuration for more details. ** IMPORTANT! Be sure to turn off the RAWMSG variable when you are finished, as it doubles the memory and disk requirements of sc4s. Do not use RAWMSG in production! Lastly, you can enable the alternate destination d_rawmsg for one or more sourcetypes. This destination will write the raw messages to the container directory /var/syslog-ng/archive/rawmsg/<sourcetype> (which is typically mapped locally to /opt/sc4s/archive ). Within this directory, the logs are organized by host and time. This method can be useful when raw samples are needed for events that partially parse (or parse into the wrong sourcetype) and the output template is not JSON (see above). \u201cexec\u201d into the container (advanced) \u00b6 You can confirm how the templating process created the actual syslog-ng config files that are in use by \u201cexec\u2019ing in\u201d to the container and navigating the syslog-ng config filesystem directly. To do this, run /usr/bin/podman exec -it SC4S /bin/bash and navigate to /opt/syslog-ng/etc/ to see the actual config files in use. If you are adept with container operations and syslog-ng itself, you can modify files directly and reload syslog-ng with the command kill -1 1 in the container. You can also run the /entrypoint.sh script by hand (or a subset of it, such as everything but syslog-ng) and have complete control over the templating and underlying syslog-ng process. This is an advanced topic and futher help can be obtained via the github issue tracker and Slack channels. Keeping a failed container running (even more advanced) \u00b6 When debugging a configuration syntax issue at startup, it is often helpful to keep the container running after a syslog-ng startup failure. In order to facilitate troubleshooting and make \u201con the fly\u201d syslog-ng configuration changes from within a running container, the container can be forced to remain running when syslog-ng fails to start (which normally terminates the container). This can be enabled by adding SC4S_DEBUG_CONTAINER=yes to the env_file . Use this capability in conjunction with \u201cexec-ing\u201d into the container described above. NOTE: Do not attempt to enable the debug container mode while running out of systemd. Run the container manually from the CLI, as podman or docker commands will be required to start, stop, and optionally clean up cruft left behind by the debug process. Only when SC4S_DEBUG_CONTAINER is set to \u201cno\u201d (or completely unset) should systemd startup processing resume.","title":"SC4S Logging and Troubleshooting Resources"},{"location":"troubleshooting/troubleshoot_resources/#sc4s-logging-and-troubleshooting-resources","text":"","title":"SC4S Logging and Troubleshooting Resources"},{"location":"troubleshooting/troubleshoot_resources/#helpful-linux-and-container-commands","text":"","title":"Helpful Linux and Container Commands"},{"location":"troubleshooting/troubleshoot_resources/#linux-service-systemd-commands","text":"Check service status systemctl status sc4s Start service systemctl start service Stop service systemctl stop service Restart service systemctl restart service Enabling service at boot systemctl enable sc4s Query the system journal journalctl -b -u sc4s","title":"Linux service (systemd) commands"},{"location":"troubleshooting/troubleshoot_resources/#container-commands","text":"NOTE: All container commands below can be run with either runtime ( podman or docker ). Container logs sudo podman> logs SC4S Exec into SC4S container podman exec -it SC4S bash Rebuilding SC4S volume podman volume rm splunk - sc4s - var podman volume create splunk - sc4s - var Pull an image or a repository from a registry podman pull splunk:scs:latest Remove unused data podman system prune Load an image from a tar archive or STDIN podman load <tar>","title":"Container Commands"},{"location":"troubleshooting/troubleshoot_resources/#obtaining-on-the-wire-raw-events","text":"In almost all cases during development or troubleshooting, you will need to obtain samples of the messages exactly as they are received by SC4S. These \u201craw\u201d events contain the full syslog message (including the <PRI> preamble) and differs from those that appear in Splunk after processing by sc4s and/or Splunk. This is the only way to determine if SC4S parsers and filters are operating correctly, as raw messages are needed for \u201cplayback\u201d when testing. In addition, the community supporting SC4S will always first ask for raw samples (kind of like the way Splunk support always asks for \u201cdiags\u201d) before any development or troubleshooting exercise. Here are some options for obtaining raw logs for one or more sourcetypes: Run tcpdump on the collection interface and display the results in ASCII. You will see events of the form < 165 > 1 2007 -02 -15 T09 : 17 : 15.719 Z router1 mgd 3046 UI_DBASE_LOGOUT_EVENT [ junos @2636.1.1.1.2.18 username = \"user\" ] User ' user ' exiting configuration mode buried in the packet contents. Set the variable SC4S_SOURCE_STORE_RAWMSG=yes in env_file and restart sc4s. This will store the raw message in a syslog-ng macro called RAWMSG and will be displayed in Splunk for all fallback messages. For most other sourcetypes, the RAWMSG is not displayed, but can be surfaced by changing the output template to one of the JSON variants (t_JSON_3164 or t_JSON_5424 depending on RFC message type). See SC4S metadata configuration for more details. ** IMPORTANT! Be sure to turn off the RAWMSG variable when you are finished, as it doubles the memory and disk requirements of sc4s. Do not use RAWMSG in production! Lastly, you can enable the alternate destination d_rawmsg for one or more sourcetypes. This destination will write the raw messages to the container directory /var/syslog-ng/archive/rawmsg/<sourcetype> (which is typically mapped locally to /opt/sc4s/archive ). Within this directory, the logs are organized by host and time. This method can be useful when raw samples are needed for events that partially parse (or parse into the wrong sourcetype) and the output template is not JSON (see above).","title":"Obtaining \"On-the-wire\" Raw Events"},{"location":"troubleshooting/troubleshoot_resources/#exec-into-the-container-advanced","text":"You can confirm how the templating process created the actual syslog-ng config files that are in use by \u201cexec\u2019ing in\u201d to the container and navigating the syslog-ng config filesystem directly. To do this, run /usr/bin/podman exec -it SC4S /bin/bash and navigate to /opt/syslog-ng/etc/ to see the actual config files in use. If you are adept with container operations and syslog-ng itself, you can modify files directly and reload syslog-ng with the command kill -1 1 in the container. You can also run the /entrypoint.sh script by hand (or a subset of it, such as everything but syslog-ng) and have complete control over the templating and underlying syslog-ng process. This is an advanced topic and futher help can be obtained via the github issue tracker and Slack channels.","title":"\"exec\" into the container (advanced)"},{"location":"troubleshooting/troubleshoot_resources/#keeping-a-failed-container-running-even-more-advanced","text":"When debugging a configuration syntax issue at startup, it is often helpful to keep the container running after a syslog-ng startup failure. In order to facilitate troubleshooting and make \u201con the fly\u201d syslog-ng configuration changes from within a running container, the container can be forced to remain running when syslog-ng fails to start (which normally terminates the container). This can be enabled by adding SC4S_DEBUG_CONTAINER=yes to the env_file . Use this capability in conjunction with \u201cexec-ing\u201d into the container described above. NOTE: Do not attempt to enable the debug container mode while running out of systemd. Run the container manually from the CLI, as podman or docker commands will be required to start, stop, and optionally clean up cruft left behind by the debug process. Only when SC4S_DEBUG_CONTAINER is set to \u201cno\u201d (or completely unset) should systemd startup processing resume.","title":"Keeping a failed container running (even more advanced)"}]}